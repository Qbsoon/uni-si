{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/SI/si/lib/python3.11/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "#Importy do całego kodu\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from IPython.display import clear_output\n",
    "from ignite.handlers import FastaiLRFinder\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się kod na wczytanie plików dźwiękowych, przetworzenie ich i zapisanie przetworzonych danych do dalszego użycia.\n",
    "Kod bazuje na kodzie z przykładu, ale przy pętli, która przeszukuje foldery dodałem algorytm sprawdzający, czy to rzeczywiście folder, bo w tej ścieżce znajdują się również pliki. Tak samo potem sprawdzam, czy pliki to .wav, bo pojawiały się też inne pliki. Ustawiłem dtype na float32, bo domyślnie był to float64 i logfbank_feats zajmował około 20GB, przejście na float32 ścieło rozmiar o około połowę. Inną opcją było zmniejszenie ilości plików z każdego folderu do na przykład 200 zamiast 300, ale nie chciałem mieć mniej obiektów do szkolenia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "labels_categorical = []\n",
    "root = 'SpeechDataset/'\n",
    "\n",
    "# Iteracja przez katalogi w folderze głównym\n",
    "for ind, subdir in enumerate(os.listdir(root)):\n",
    "    subdir_path = os.path.join(root, subdir)\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "    for file in os.listdir(os.path.join(root, subdir))[:300]:\n",
    "        filepath = os.path.join(root, subdir, file)\n",
    "        if not filepath.endswith('.wav'):\n",
    "            continue\n",
    "        paths.append(filepath)\n",
    "        labels.append(ind)\n",
    "        labels_categorical.append(subdir)\n",
    "\n",
    "print(f\"Found {len(paths)} WAV files\")\n",
    "\n",
    "# Obliczanie cech logfbank dla każdego sygnału\n",
    "logfbank_feats = []\n",
    "for signal_path in paths:\n",
    "    fs, sig = wav.read(signal_path)\n",
    "    fbank_feat = logfbank(sig, samplerate=fs)\n",
    "    logfbank_feats.append(fbank_feat)\n",
    "\n",
    "# Ustalenie maksymalnej długości sygnału i wyrównanie długości\n",
    "lengths = [i.shape[0] for i in logfbank_feats]\n",
    "max_len = np.max(lengths)\n",
    "print(f\"Max length: {max_len}\")\n",
    "\n",
    "# Tworzenie macierzy o ustalonej maksymalnej długości\n",
    "padded_feats = np.zeros((len(lengths), max_len, logfbank_feats[0].shape[1]), dtype=np.float32)\n",
    "for i, feats in enumerate(logfbank_feats):\n",
    "    padded_feats[i, :, :] = np.pad(feats, \n",
    "                                    ((int(np.floor((max_len - feats.shape[0]) / 2)),\n",
    "                                      int(np.ceil((max_len - feats.shape[0]) / 2))),\n",
    "                                     (0, 0)))\n",
    "\n",
    "print(f\"padded_feats shape: {padded_feats.shape}, dtype: {padded_feats.dtype}\")\n",
    "\n",
    "# Zapisanie wyników do plików\n",
    "np.save('logfbank_feats.npy', padded_feats)\n",
    "np.save('labels.npy', labels)\n",
    "np.save('labels_categorical.npy', labels_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie zapisanych plików oraz podział zbiorów.\n",
    "Wczytuję pliki z przedrostkiem \"t_\", ponieważ Pani Tośka uzyskała z jakiegoś powodu pliki idealne, które zajmują tylko około 116MB i przetważają się dużo szybciej (moje około 8 minut przy 150 epokach, a tutaj to kwestia sekund). Mają też o wiele mniej wierszy, ale to właśnie taki wymiar, do jakiego dostosowany jest kod z przykładu (z jakiegoś powodu ja, Łukasz, Alina i Jan otrzymywaliśmy 100 razy więcej wierszy w danych, stąd 20GB). Dodam, że Pani Tośka korzystała z identycznego kodu na wygenerowanie tych plików jak ja. Jedyna różnica polega na tym, że zrobiła to na colabie, ale potem wykonała kod w vscode i uzyskała jeszcze 2x mniejszy plik od tych idealnych.\n",
    "Różnica w wynikach nie była aż tak wielokrotna, przejście na pliki Pani Tośku pozwoliło mi uzyskać o 10% większe accuracy. \n",
    "Aktualizacja: Dopiero podczas opisywania dalszej części kodu zauważyłem, że pliki te mają tylko 21 klas, podczas gdy moje pliki miały zawsze 42 klasy, a pliki Pana Łukasza 36 klas (36 to wartość, która pojawiała się również w przykładach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Załadowanie danych\n",
    "feats = np.load('t_logfbank_feats.npy')\n",
    "labels = np.load('t_labels.npy')\n",
    "\n",
    "# Przekształcenie danych\n",
    "feats = feats.reshape(feats.shape[0], -1)\n",
    "feats = feats.astype(np.float32)\n",
    "\n",
    "# Podział na zbiory uczący, walidacyjny i testowy\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(    \n",
    "    feats,\n",
    "    labels,\n",
    "    random_state=1,\n",
    "    stratify=labels,\n",
    "    train_size=0.8\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test,\n",
    "    y_val_test,\n",
    "    random_state=1,\n",
    "    stratify=y_val_test,\n",
    "    train_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetworzenie danych z formatu numpy na tensory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "valset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "testset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=256)\n",
    "val_loader = DataLoader(valset, batch_size=256)\n",
    "test_loader = DataLoader(testset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicja modelu sieci z dropout, wraz z definicjami kryterium oceny, optymalizatora i trenera.\n",
    "Przekazuję input_size zmienną ze względu na to, że zmieniałem parametry w pierwszej komórce na różne przed przejściem na pliki Pani Tośki, zmieniał się też wtedy czasem input_size\n",
    "Opisuję to wszystko w niedzielę, podczas gdy kod tworzyłem tydzień wcześniej, więc nie wszystkie zmiany pamietam, ale wydaje mi się, że ustawiłem inne wartości dropout, dodałem dwie warstwy i zmieniłem optymalizator na Adam oraz zmniejszyłem lr z 3e-3 na 3e-4 w odniesieniu do kodu z przykładu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/SI/si/lib/python3.11/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)  # Pierwsza warstwa gęsta\n",
    "        self.fc2 = nn.Linear(256, 128)   # Druga warstwa gęsta\n",
    "        self.fc3 = nn.Linear(128, 64)   # Trzecia warstwa gęsta\n",
    "        self.fc4 = nn.Linear(64, 21)    # Czwarta warstwa gęsta\n",
    "        self.dropout1 = nn.Dropout(p = 0.5)  # Pierwsza warstwa dropout (50% prawdopodobieństwo wyłączenia neuronów)\n",
    "        self.dropout2 = nn.Dropout(p = 0.35)  # Druga warstwa dropout (35% prawdopodobieństwo wyłączenia neuronów)\n",
    "        self.dropout3 = nn.Dropout(p = 0.2) # Trzecia warstwa dropout (20% prawdopodobieństwo wyłączenia neuronów)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Przechodzimy przez pierwszą warstwę\n",
    "        x = self.dropout1(x)  # Zastosowanie dropout po pierwszej warstwie\n",
    "        x = self.fc2(x)  # Przechodzimy przez drugą warstwę\n",
    "        x = self.dropout2(x)  # Zastosowanie dropout po drugiej warstwie\n",
    "        x = self.fc3(x)  # Przechodzimy przez trzecią warstwę\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim = 1)  # Zastosowanie logarytmu softmax na wyjściu\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Sprawdza, czy dostępna jest karta graficzna (GPU), jeśli nie, używa CPU\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.NLLLoss()  # Definiuje funkcję strat (strata logarytmiczna z prawdopodobieństw)\n",
    "# device='cpu'\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)  # Inicjalizuje model sieci neuronowej\n",
    "model.to(device)  # Przenosi model na odpowiednie urządzenie (GPU lub CPU)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))  # Definiuje optymalizator SGD z określoną szybkością uczenia i momentem\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "# Tworzymy obiekt trenera\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "\n",
    "# Tworzymy obiekt ewaluatora\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.NLLLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "# Dodajemy pasek postępu do trenera\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenowanie i ocena modelu\n",
    "W odniesieniu do kodu z przykładu dodałem clear_output dla wygody w przeglądaniu notatnika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.4186851211072664, 'loss': 1.903396342452422}\n"
     ]
    }
   ],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "# Walidacja ma być przeprowadzona po zakończeniu każdej epoki\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "# Trening modelu przez 150 epok\n",
    "trainer.run(train_loader, max_epochs=100)\n",
    "\n",
    "# Ewaluacja modelu na zbiorze testowym\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejście na AdamW, zmniejszenie szans na deaktywację w dropout, zastosowanie funkcji aktywacji relu, zmiana straty na crossentropy (wybór ze względu na obecność wielu klas na wyjściu).\n",
    "Zmiany te pozwoliły na zwiększenie accuracy o około 20%.\n",
    "Dodam, że x pierwszych modeli było początkowo wykonywanych na moich plikach zamiast plikach t_, ale ponieważ kolejne były wykonywane na plikach t_, to wykonałem ponownie te kody na plikach t_ dla lepszego odniesienia. Wyniki na moich plikach były około 10-15% gorsze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6141868512110726, 'loss': 1.3253483227792495}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 21)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szczerze pryznaję, że nie wiem, co zmieniłem w poniższym kodzie w porównaniu do powyższego, ale za każdym razem mam 1-3% większy wynik accuracy z poniższego kodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6470588235294118, 'loss': 1.234823787913603}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 21)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej nastąpiła próba dodania informacji zwrotnych w warstwach, aczkolwiek nie byłem jeszcze świadom, że robię to niepoprawnie, bo w jednym wykonaniu dwa razy przechodzę przez 2 i 3 warstwę, zamiast informować warstwę w przyszłych wykonaniach o wynikach z poprzednich. Wyniki porównywalne do powyższego kodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6470588235294118, 'loss': 1.292795253872459}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 21)\n",
    "        self.fc_feedback1 = nn.Linear(64, 256)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x1 = self.dropout1(x1)\n",
    "        x2 = F.relu(self.fc2(x1))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x3 = F.relu(self.fc3(x2))\n",
    "        x3 = self.dropout3(x3)\n",
    "        x2_feedback = F.relu(self.fc_feedback1(x3)) \n",
    "        x2 = F.relu(self.fc2(x2_feedback+x1))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x3 = F.relu(self.fc3(x2))\n",
    "        x3 = self.dropout3(x3)\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponownie myślałem, że dobrze zaimplementowałem, ale przecież przy każdym wywołaniu forward zmienne będą resetowane do zera, więc nadal jest źle, aczkolwiek wynik z jakiegoś powodu jest o 3% większy. Zauważyłem ten błąd myśląc o kodzie zaraz po ostatnich zajęciach, ale potem o tym zapomniałem i przypomniałem sobie o tym dopiero teraz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6730103806228374, 'loss': 1.1217377870553094}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 21)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x2 = F.relu(self.fc2(x1+x2_temp))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.relu(self.fc3(x2+x3_temp))\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod wydaje mi się, że powinien być odpowiedni, ale z nieznanego mi powodu otrzymuję błędy. Github Copilot nie był w stanie mi pomóc z tym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd0ce1a60f845719f5233bcdffc34bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/19]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current run is terminating due to exception: The size of tensor a (16) must match the size of tensor b (256) at non-singleton dimension 0\n",
      "Engine run is terminating due to exception: The size of tensor a (16) must match the size of tensor b (256) at non-singleton dimension 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (256) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Results - Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Avg accuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m Avg loss: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     55\u001b[0m         trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch, metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m], metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mrun(test_loader)\n\u001b[1;32m     60\u001b[0m clear_output()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:1096\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:1077\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/__init__.py:114\u001b[0m, in \u001b[0;36msupervised_training_step.<locals>.update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m    112\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    113\u001b[0m x, y \u001b[38;5;241m=\u001b[39m prepare_batch(batch, device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[0;32m--> 114\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_transform(output)\n\u001b[1;32m    116\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/__init__.py:439\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m amp_mode, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_supervised_trainer\u001b[39m(\n\u001b[1;32m    427\u001b[0m     model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m    428\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m    429\u001b[0m     loss_fn: Union[Callable[[Any, Any], torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule],\n\u001b[1;32m    430\u001b[0m     device: Optional[Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    431\u001b[0m     non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    432\u001b[0m     prepare_batch: Callable \u001b[38;5;241m=\u001b[39m _prepare_batch,\n\u001b[1;32m    433\u001b[0m     model_transform: Callable[[Any], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m output: output,\n\u001b[1;32m    434\u001b[0m     output_transform: Callable[[Any, Any, Any, torch\u001b[38;5;241m.\u001b[39mTensor], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y, y_pred, loss: loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    435\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    436\u001b[0m     amp_mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    437\u001b[0m     scaler: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.GradScaler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    438\u001b[0m     gradient_accumulation_steps: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m--> 439\u001b[0m     model_fn: Callable[[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, Any], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m model, x: \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Engine:\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Factory function for creating a trainer for supervised models.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m        Added support for ``mps`` device\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     device_type \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01melse\u001b[39;00m device\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[33], line 18\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     17\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m---> 18\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(\u001b[43mx1\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx2_temp\u001b[49m))\n\u001b[1;32m     19\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x2)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx2_temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeedback1(x2)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (256) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 21)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "        self.feedback1 = nn.Linear(128, 256)\n",
    "        self.feedback2 = nn.Linear(64, 128)\n",
    "        self.x2_temp = 0\n",
    "        self.x3_temp = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x2 = F.relu(self.fc2(x1+self.x2_temp))\n",
    "        x2 = self.dropout2(x2)\n",
    "        self.x2_temp = self.feedback1(x2).detach()\n",
    "        x3 = F.relu(self.fc3(x2+self.x3_temp))\n",
    "        x3 = self.dropout3(x3)\n",
    "        self.x3_temp = self.feedback2(x3).detach()\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejście do porównywania różnych funkcji aktywacji.\n",
    "Najpierw przedstawienie ich różnic na wykresach plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "ReLU",
         "type": "scatter",
         "x": [
          -5,
          -3.333333333333333,
          -1.6666666666666665,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          0,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Sigmoid",
         "type": "scatter",
         "x": [
          -5,
          -3.333333333333333,
          -1.6666666666666665,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "xaxis": "x2",
         "y": [
          0.0066928509242848554,
          0.03444519566621118,
          0.15886910488091516,
          0.5,
          0.8411308951190849,
          0.9655548043337889,
          0.9933071490757153,
          0.9987289837369187,
          0.9997596882871811,
          0.9999546021312976
         ],
         "yaxis": "y2"
        },
        {
         "mode": "lines",
         "name": "Tanh",
         "type": "scatter",
         "x": [
          -5,
          -3.333333333333333,
          -1.6666666666666665,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "xaxis": "x3",
         "y": [
          -0.9999092042625951,
          -0.9974579674738373,
          -0.9311096086675776,
          0,
          0.9311096086675777,
          0.9974579674738373,
          0.9999092042625951,
          0.9999967608116616,
          0.9999998844450363,
          0.9999999958776927
         ],
         "yaxis": "y3"
        },
        {
         "mode": "lines",
         "name": "Leaky ReLU",
         "type": "scatter",
         "x": [
          -5,
          -3.333333333333333,
          -1.6666666666666665,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "xaxis": "x4",
         "y": [
          -0.05,
          -0.03333333333333333,
          -0.016666666666666666,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "yaxis": "y4"
        },
        {
         "mode": "lines",
         "name": "Softmax",
         "type": "scatter",
         "x": [
          -5,
          -3.333333333333333,
          -1.6666666666666665,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "xaxis": "x5",
         "y": [
          2.481248496436642e-7,
          0.0000013136945477127537,
          0.000006955342712221896,
          0.00003682499278746804,
          0.00019496955792188032,
          0.0010322643845619348,
          0.005465313513517729,
          0.028936048020019044,
          0.15320161834191376,
          0.8111244440271687
         ],
         "yaxis": "y5"
        },
        {
         "mode": "lines",
         "name": "Log Softmax",
         "type": "scatter",
         "x": [
          -5,
          -3.333333333333333,
          -1.6666666666666665,
          0,
          1.666666666666667,
          3.333333333333334,
          5,
          6.666666666666668,
          8.333333333333334,
          10
         ],
         "xaxis": "x6",
         "y": [
          -15.20933379147526,
          -13.542667124808592,
          -11.876000458141926,
          -10.20933379147526,
          -8.542667124808592,
          -6.876000458141925,
          -5.209333791475259,
          -3.5426671248085913,
          -1.876000458141925,
          -0.20933379147525893
         ],
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ReLU",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Sigmoid",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Tanh",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Leaky ReLU",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Softmax",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Log Softmax",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Funkcje Aktywacji"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2888888888888889
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.7111111111111111,
          1
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0,
          0.2888888888888889
         ]
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ],
         "range": [
          -5,
          10
         ]
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.7111111111111111,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "range": [
          -0.1,
          10
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ],
         "range": [
          0,
          1.2
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.625,
          1
         ],
         "range": [
          -1.5,
          1.5
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ],
         "range": [
          -1,
          1
         ]
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.375
         ],
         "range": [
          -0.1,
          2
         ]
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.375
         ],
         "range": [
          -15,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"135aebca-b0f6-49d5-998b-89ae92c7900a\" class=\"plotly-graph-div\" style=\"height:600px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"135aebca-b0f6-49d5-998b-89ae92c7900a\")) {                    Plotly.newPlot(                        \"135aebca-b0f6-49d5-998b-89ae92c7900a\",                        [{\"mode\":\"lines\",\"name\":\"ReLU\",\"x\":[-5.0,-3.333333333333333,-1.6666666666666665,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"y\":[0.0,0.0,0.0,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Sigmoid\",\"x\":[-5.0,-3.333333333333333,-1.6666666666666665,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"y\":[0.0066928509242848554,0.03444519566621118,0.15886910488091516,0.5,0.8411308951190849,0.9655548043337889,0.9933071490757153,0.9987289837369187,0.9997596882871811,0.9999546021312976],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Tanh\",\"x\":[-5.0,-3.333333333333333,-1.6666666666666665,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"y\":[-0.9999092042625951,-0.9974579674738373,-0.9311096086675776,0.0,0.9311096086675777,0.9974579674738373,0.9999092042625951,0.9999967608116616,0.9999998844450363,0.9999999958776927],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines\",\"name\":\"Leaky ReLU\",\"x\":[-5.0,-3.333333333333333,-1.6666666666666665,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"y\":[-0.05,-0.03333333333333333,-0.016666666666666666,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"mode\":\"lines\",\"name\":\"Softmax\",\"x\":[-5.0,-3.333333333333333,-1.6666666666666665,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"y\":[2.481248496436642e-07,1.3136945477127537e-06,6.955342712221896e-06,3.682499278746804e-05,0.00019496955792188032,0.0010322643845619348,0.005465313513517729,0.028936048020019044,0.15320161834191376,0.8111244440271687],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"mode\":\"lines\",\"name\":\"Log Softmax\",\"x\":[-5.0,-3.333333333333333,-1.6666666666666665,0.0,1.666666666666667,3.333333333333334,5.0,6.666666666666668,8.333333333333334,10.0],\"y\":[-15.20933379147526,-13.542667124808592,-11.876000458141926,-10.20933379147526,-8.542667124808592,-6.876000458141925,-5.209333791475259,-3.5426671248085913,-1.876000458141925,-0.20933379147525893],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"range\":[-0.1,10]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"range\":[0,1.2]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.7111111111111111,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.625,1.0],\"range\":[-1.5,1.5]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,0.2888888888888889]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"range\":[-1,1]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.35555555555555557,0.6444444444444445],\"range\":[-5,10]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.375],\"range\":[-0.1,2]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.7111111111111111,1.0]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.375],\"range\":[-15,1]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"ReLU\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Sigmoid\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Tanh\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Leaky ReLU\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Softmax\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Log Softmax\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Funkcje Aktywacji\"},\"height\":600,\"width\":900,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('135aebca-b0f6-49d5-998b-89ae92c7900a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zakres wartości wejściowych\n",
    "x = np.linspace(-5.0, 10.0, 10)\n",
    "\n",
    "# Funkcje aktywacji\n",
    "relu = F.relu(torch.tensor(x)).numpy()\n",
    "sigmoid = torch.sigmoid(torch.tensor(x)).numpy()\n",
    "tanh = torch.tanh(torch.tensor(x)).numpy()\n",
    "leaky_relu = F.leaky_relu(torch.tensor(x), negative_slope=0.01).numpy()\n",
    "softmax = F.softmax(torch.tensor(x), dim=0).numpy()\n",
    "log_softmax = F.log_softmax(torch.tensor(x), dim=0).numpy()\n",
    "\n",
    "fig = make_subplots(rows=2, cols=3, subplot_titles=(\"ReLU\", \"Sigmoid\", \"Tanh\", \"Leaky ReLU\", \"Softmax\", \"Log Softmax\"))\n",
    "\n",
    "# Dodawanie wykresów\n",
    "fig.add_trace(go.Scatter(x=x, y=relu, mode='lines', name='ReLU'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=x, y=sigmoid, mode='lines', name='Sigmoid'), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=x, y=tanh, mode='lines', name='Tanh'), row=1, col=3)\n",
    "fig.add_trace(go.Scatter(x=x, y=leaky_relu, mode='lines', name='Leaky ReLU'), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=x, y=softmax, mode='lines', name='Softmax'), row=2, col=2)\n",
    "fig.add_trace(go.Scatter(x=x, y=log_softmax, mode='lines', name='Log Softmax'), row=2, col=3)\n",
    "\n",
    "# Aktualizacja układu\n",
    "fig.update_layout(height=600, width=900, title_text=\"Funkcje Aktywacji\", showlegend=False,\n",
    "                  yaxis1=dict(range=[-0.1,10]),\n",
    "                  yaxis2=dict(range=[0,1.2]),\n",
    "                  yaxis3=dict(range=[-1.5,1.5]),\n",
    "                    yaxis4=dict(range=[-1,1]),\n",
    "                    yaxis5=dict(range=[-0.1,2]),\n",
    "                    xaxis5=dict(range=[-5,10]),\n",
    "                    yaxis6=dict(range=[-15,1]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie miały gorsze wyniki od relu i leaky_relu.\n",
    "ReLU zwraca wejścia, jeśli jest dodatnie, a w przeciwnym wypadku zero\n",
    "\n",
    "Softmax przekształca wektor wartości w rozkład prawdopodobieństwa sumujący się do 1\n",
    "\n",
    "Softmax 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.05190311418685121, 'loss': 3.367358778587262}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.softmax(self.fc1(x))\n",
    "        x2 = F.softmax(self.fc2(x1+x2_temp))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.softmax(self.fc3(x2+x3_temp))\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid przekształca wejście w wartość z przedziału (0,1)\n",
    "\n",
    "Sigmoid 24%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.2491349480968858, 'loss': 2.3500845622026385}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = torch.sigmoid(self.fc1(x))\n",
    "        x2 = torch.sigmoid(self.fc2(x1+x2_temp))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = torch.sigmoid(self.fc3(x2+x3_temp))\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh przekształca wejście w wartość z przedziału (-1, 1), centralizując dane wokół zera\n",
    "\n",
    "Tanh 44%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.4411764705882353, 'loss': 1.7960610571204585}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = torch.tanh(self.fc1(x))\n",
    "        x2 = torch.tanh(self.fc2(x1+x2_temp))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = torch.tanh(self.fc3(x2+x3_temp))\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky ReLU zwraca wejście, jeśli jest dodatnie, w przeciwnym razie zwraca małą ujemną wartość proporcjonalną do wejścia.\n",
    "\n",
    "Leaky_relu, jak wspomniałem daje rozsądne wyniki, 66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6660899653979239, 'loss': 1.1511010826665224}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.01)\n",
    "        x2 = F.leaky_relu(self.fc2(x1+x2_temp), negative_slope=0.01)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.leaky_relu(self.fc3(x2+x3_temp), negative_slope=0.01)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.8, 0.888))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossEntropyLoss łączy LogSoftmax i NLLLoss, karząc większe różnice między przewidywanymi a rzeczywistymi klasami\n",
    "\n",
    "NLLoss oblicza negatywną logarytmiczną wartość prawdopodobieństwa dla przewidywanych klas\n",
    "\n",
    "Powrót do straty NLLLoss, o dziwo lepsze wyniki od CrossEntropy, wydawało mi się, że na zajeciach były gorsze, ale też tutaj leaky_relu, a powyżej gdzie zmieniałem na crossentropy i miałem z tego korzyść miałem relu. Miałem tutaj wyniki takie jak 68% i 69%, ale wykonałem kolejny raz i zmieniło się na 66% i nie byłem w stanie ich odtworzyć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6539792387543253, 'loss': 1.1723927428565635}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.01)\n",
    "        x2 = F.leaky_relu(self.fc2(x1+x2_temp), negative_slope=0.01)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.leaky_relu(self.fc3(x2+x3_temp), negative_slope=0.01)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.NLLLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLLLoss2d odmiana NLLLoss dla danych 2d\n",
    "\n",
    "NLLLoss2d, 64%, z jakiegoś powodu nazwa w kodzie jest przekreślona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6401384083044983, 'loss': 1.1655193183661332}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.01)\n",
    "        x2 = F.leaky_relu(self.fc2(x1+x2_temp), negative_slope=0.01)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.leaky_relu(self.fc3(x2+x3_temp), negative_slope=0.01)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.NLLLoss2d()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.NLLLoss2d())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiMarginLoss oblicza stratę na podstawie marginesów między klasami\n",
    "\n",
    "MultiMarginLoss, 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6366782006920415, 'loss': 0.08644909842204057}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.01)\n",
    "        x2 = F.leaky_relu(self.fc2(x1+x2_temp), negative_slope=0.01)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.leaky_relu(self.fc3(x2+x3_temp), negative_slope=0.01)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.MultiMarginLoss()\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.MultiMarginLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FocalLoss modyfikuje CrossEntropyLoss, aby skupić się na trudniejszych do sklasyfikowania przykładach, zmniejszając wpływ łatwych przykładów\n",
    "\n",
    "FocalLoss, 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6539792387543253, 'loss': 0.8594459612889274}\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.01)\n",
    "        x2 = F.leaky_relu(self.fc2(x1+x2_temp), negative_slope=0.01)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.leaky_relu(self.fc3(x2+x3_temp), negative_slope=0.01)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = FocalLoss(alpha=1, gamma=2, reduction='mean')\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(FocalLoss(alpha=1, gamma=2, reduction='mean'))}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelSmoothingLoss wprowadza wygładzanie klas, aby zmniejszyć pewność modelu co do przewidywań\n",
    "\n",
    "LabelSmoothingLoss, 67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6764705882352942, 'loss': 1.6449754972358888}\n"
     ]
    }
   ],
   "source": [
    "from ignite.engine import Engine\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x, x2_temp=0, x3_temp=0):\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.01)\n",
    "        x2 = F.leaky_relu(self.fc2(x1+x2_temp), negative_slope=0.01)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2_temp = x2\n",
    "        x3 = F.leaky_relu(self.fc3(x2+x3_temp), negative_slope=0.01)\n",
    "        x3 = self.dropout3(x3)\n",
    "        x3_temp = x3\n",
    "        x = self.fc4(x3)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = LabelSmoothingLoss(classes=42, smoothing=0.1)\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(LabelSmoothingLoss(classes=42, smoothing=0.1))}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyszukiwanie najlepszego lr_rate i trening z tym lr, w odniesieniu do przykładu musiałem dodać start_lr, end_lr i num_iter, żeby kod wykonywał się bez błędów. Dzięki finderowi udało mi się uzyskać 70%, rekordowo 70,8%, ale nie udało mi się teraz powtórzyć, a nie mam czasu, żeby wykonywać wiele razy i czekać na ten wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.7006920415224913, 'loss': 1.0664540855117324}\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja obiektu FastaiLRFinder\n",
    "lr_finder = FastaiLRFinder()\n",
    "\n",
    "# Przygotowanie słownika z modelem i optymalizatorem\n",
    "to_save = {'model': model, 'optimizer': optimizer}\n",
    "\n",
    "# Dołączenie lr_finder do trenera i ustawienie wartości diverge_th na 1.1\n",
    "with lr_finder.attach(trainer, to_save, diverge_th=1.1, start_lr=1e-6, end_lr=100.0, num_iter=600) as trainer_with_lr_finder:\n",
    "    # Domyślnie start_lr jest taki, jak określono w obiekcie optimizer, \n",
    "    # a end_lr = 10\n",
    "    trainer_with_lr_finder.run(train_loader)\n",
    "\n",
    "# Pobranie wyników po zakończeniu poszukiwań najlepszego LR\n",
    "results = lr_finder.get_results()\n",
    "\n",
    "# Wykres przedstawiający wyniki\n",
    "lr_finder.plot()\n",
    "\n",
    "# Wyświetlenie sugerowanego współczynnika uczenia\n",
    "print(\"Suggested LR:\", lr_finder.lr_suggestion())\n",
    "\n",
    "# Utworzenie obiektów trainer i evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model,\n",
    "    metrics={\"acc\": Accuracy(), \"loss\": Loss(nn.CrossEntropyLoss())},\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Dodanie paska postępu do trenera\n",
    "ProgressBar(persist=True).attach(\n",
    "    trainer, output_transform=lambda x: {\"batch loss\": x}\n",
    ")\n",
    "\n",
    "# Funkcja walidacji po zakończeniu epoki\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)  # Przeprowadzenie walidacji\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Validation Results - Epoch: {trainer.state.epoch} \"\n",
    "          f\"Avg accuracy: {metrics['acc']:.2f} \"\n",
    "          f\"Avg loss: {metrics['loss']:.2f}\")\n",
    "    \n",
    "    # Zastosowanie sugerowanego współczynnika uczenia\n",
    "    lr_finder.apply_suggested_lr(optimizer)\n",
    "    print(f'Training with suggested lr: {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "# Rozpoczęcie treningu\n",
    "trainer.run(train_loader, max_epochs=50)\n",
    "\n",
    "# Ewaluacja na zbiorze testowym\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udało mi się również uzyskać przyzwoite wyniki na transformerze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6868512110726643, 'loss': 1.3529279768260705}\n"
     ]
    }
   ],
   "source": [
    "class TransformerNet(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, num_decoder_layers):\n",
    "        super(TransformerNet, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(d_model, 128)\n",
    "        self.fc2 = nn.Linear(128, 42)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer(x, x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "d_model = 128\n",
    "nhead = 8\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "model = TransformerNet(input_size, d_model, nhead, num_encoder_layers, num_decoder_layers)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.CrossEntropyLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
