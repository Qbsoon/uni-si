{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wprowadzenie do sieci neuronowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieci neuronowe stanowią odrębną i rozbudowaną dziedzinę uczenia maszynowego. Mimo że początkowe modele mogą wydawać się proste, zrewolucjonizowały one sposób myślenia o problemach rozwiązywanych z wykorzystaniem sztucznej inteligencji. Co więcej, w połączeniu z postępującą cyfryzacją danych i rosnącymi możliwościami komputerów, wczesne modele sieci neuronowych stały się fundamentem zaawansowanych, przełomowych technologii, które odmieniły naszą rzeczywistość. Jeszcze kilkadziesiąt lat temu automatyczne rozpoznawanie obrazów czy dźwięków było uznawane za domenę literatury science fiction. Dziś jest to nasza codzienność.  \n",
    "\n",
    "Sztuczne sieci neuronowe, zgodnie z nazwą, są inspirowane funkcjonowaniem ludzkiego mózgu, który składa się z neuronów – komórek nerwowych. Podstawowe podobieństwo między sztucznymi a biologicznymi sieciami neuronowymi polega na ich strukturalnym układzie, opartym na wielokrotnym powielaniu tego samego elementu. Również sposób przekazywania informacji wykazuje analogię – sygnał wędruje zwykle w jednym kierunku, a działanie odbywa się zgodnie z zasadą „wszystko albo nic”. Oznacza to, że słabe impulsy nie powodują reakcji, natomiast przekroczenie określonego progu prowadzi do transmisji sygnału. Poglądowe połączenie dwóch neuronów ilustruje tę koncepcję.  \n",
    "\n",
    "Pierwszy model pojedynczej komórki nerwowej został stworzony w 1943 roku przez Warrena McCullocha i Waltera Pittsa. Wykorzystali go do przedstawienia podstawowych operacji logicznych, takich jak koniunkcja czy alternatywa (McCulloch i Pitts, 1943). Na bazie tego modelu, Frank Rosenblatt w 1958 roku opracował pierwszą prostą sieć neuronową, znaną jako perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Budowa perceptronu:\n",
    "1. **Zbiór danych treningowych**  \n",
    "   Dane wejściowe, zwane sygnałami zewnętrznymi, są opisane jako \\( x^{(j)} = (x_1^{(j)}, x_2^{(j)}, \\dots, x_d^{(j)}) \\), gdzie \\( j = 1, \\dots, N \\). Każdy z tych sygnałów trafia na wejście sieci.\n",
    "\n",
    "2. **Stały sygnał wejściowy**  \n",
    "   Istnieje wejście numer zero, które zawsze przyjmuje wartość \\( x_0 = 1 \\) i jest powiązane z wagą \\( w_0 \\).\n",
    "\n",
    "3. **Wejścia dla sygnałów zewnętrznych**  \n",
    "   Dla \\( i = 1, \\dots, d \\) sygnały \\( x_i \\) są wprowadzane przez odpowiednie wejścia.\n",
    "\n",
    "4. **Wagi wejściowe**  \n",
    "   Każda waga \\( w_{ij} \\) odzwierciedla wpływ danej zmiennej \\( x_i \\) na wynik predykcji dla obiektu \\( j \\).\n",
    "\n",
    "5. **Sumator**  \n",
    "   Odpowiada za obliczenie całkowitego pobudzenia neuronu \\( u_j \\) jako kombinacji liniowej sygnałów i wag.\n",
    "\n",
    "6. **Funkcja aktywacji**  \n",
    "   Funkcja \\( f(u_j) \\) określa wartość wyjściową neuronu na podstawie pobudzenia \\( u_j \\). \n",
    "\n",
    "---\n",
    "\n",
    "Wybór odpowiedniej funkcji aktywacji ma kluczowe znaczenie. Powinna być ona monotoniczna, różniczkowalna w swojej dziedzinie oraz ciągła, choć kształtem może przypominać funkcję skokową. Najczęściej stosowane funkcje to: liniowa, sigmoidalna, tangens hiperboliczny oraz funkcja Gaussa. Nazwy neuronów często pochodzą od zastosowanej funkcji aktywacji.\n",
    "\n",
    "---\n",
    "\n",
    "#### Działanie perceptronu:\n",
    "\n",
    "**Kombinacja liniowa sygnałów i wag:**  \n",
    "Na wyjściu sumatora otrzymujemy liniową kombinację sygnałów wejściowych i wag:\n",
    "\\[\n",
    "u_j = w_0 x_0 + \\sum_{i=1}^d w_i x_i\n",
    "\\]\n",
    "gdzie \\( w_0 x_0 \\) jest wartością progową funkcji aktywacji.\n",
    "\n",
    "**Wartość wyjściowa neuronu:**  \n",
    "Wyjście neuronu to wynik funkcji aktywacji \\( f(u_j) \\), czyli:\n",
    "\\[\n",
    "\\tilde{y}_j = f \\left( w_0 + \\sum_{i=1}^d w_i x_i \\right)\n",
    "\\]\n",
    "Wartość \\( \\tilde{y}_j \\) reprezentuje predykcję perceptronu dla obiektu \\( x^{(j)} \\). \n",
    "\n",
    "Podczas treningu lub testowania predykcja \\( \\tilde{y}_j \\) jest porównywana z rzeczywistą wartością decyzyjną \\( y^{(j)} \\). Proces uczenia polega na iteracyjnym wprowadzaniu obiektów ze zbioru treningowego oraz modyfikacji wag w przypadku błędnej predykcji. \n",
    "\n",
    "---\n",
    "\n",
    "#### Proces treningu:\n",
    "- Na początku wagi są inicjalizowane losowo.\n",
    "- Każde przejście przez cały zbiór treningowy nazywane jest **epoką**.\n",
    "- Jeśli kryterium zakończenia nie zostanie spełnione, trening jest kontynuowany z nową, losową kolejnością obiektów.  \n",
    "Celem treningu jest znalezienie takiego zestawu wag, który zapewni możliwie najlepsze predykcje. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Budowa perceptronu:\n",
    "1. **Zbiór danych treningowych**  \n",
    "   Dane wejściowe, zwane sygnałami zewnętrznymi, są opisane jako:  \n",
    "   $$\n",
    "   x^{(j)} = (x_1^{(j)}, x_2^{(j)}, \\dots, x_d^{(j)})\n",
    "   $$  \n",
    "   gdzie \\( j = 1, \\dots, N \\). Każdy z tych sygnałów trafia na wejście sieci.\n",
    "\n",
    "2. **Stały sygnał wejściowy**  \n",
    "   Istnieje wejście numer zero, które zawsze przyjmuje wartość:  \n",
    "   $$\n",
    "   x_0 = 1\n",
    "   $$  \n",
    "   i jest powiązane z wagą \\( w_0 \\).\n",
    "\n",
    "3. **Wejścia dla sygnałów zewnętrznych**  \n",
    "   Dla \\( i = 1, \\dots, d \\) sygnały \\( x_i \\) są wprowadzane przez odpowiednie wejścia.\n",
    "\n",
    "4. **Wagi wejściowe**  \n",
    "   Każda waga \\( w_{ij} \\) odzwierciedla wpływ danej zmiennej \\( x_i \\) na wynik predykcji dla obiektu \\( j \\).\n",
    "\n",
    "5. **Sumator**  \n",
    "   Odpowiada za obliczenie całkowitego pobudzenia neuronu \\( u_j \\) jako kombinacji liniowej sygnałów i wag.\n",
    "\n",
    "6. **Funkcja aktywacji**  \n",
    "   Funkcja \\( f(u_j) \\) określa wartość wyjściową neuronu na podstawie pobudzenia \\( u_j \\). \n",
    "\n",
    "#### Działanie perceptronu:\n",
    "\n",
    "**Kombinacja liniowa sygnałów i wag:**  \n",
    "Na wyjściu sumatora otrzymujemy liniową kombinację sygnałów wejściowych i wag:\n",
    "$$\n",
    "u_j = w_0 x_0 + \\sum_{i=1}^d w_i x_i\n",
    "$$  \n",
    "gdzie \\( w_0 x_0 \\) jest wartością progową funkcji aktywacji.\n",
    "\n",
    "**Wartość wyjściowa neuronu:**  \n",
    "Wyjście neuronu to wynik funkcji aktywacji \\( f(u_j) \\), czyli:\n",
    "$$\n",
    "\\tilde{y}_j = f \\left( w_0 + \\sum_{i=1}^d w_i x_i \\right)\n",
    "$$  \n",
    "Wartość \\( \\tilde{y}_j \\) reprezentuje predykcję perceptronu dla obiektu \\( x^{(j)} \\).\n",
    "\n",
    "Podczas treningu lub testowania predykcja \\( \\tilde{y}_j \\) jest porównywana z rzeczywistą wartością decyzyjną \\( y^{(j)} \\). Proces uczenia polega na iteracyjnym wprowadzaniu obiektów ze zbioru treningowego oraz modyfikacji wag w przypadku błędnej predykcji.\n",
    "\n",
    "#### Proces treningu:\n",
    "Wartość \\( \\tilde{y}_j \\) stanowi predykcję perceptronu dla obiektu \\( x^{(j)} \\). Na etapie treningu lub testowania jest ona porównywana z rzeczywistą wartością atrybutu decyzyjnego \\( y^{(j)} \\). Proces trenowania sieci neuronowej przebiega iteracyjnie i polega na wprowadzaniu do wejścia perceptronu kolejnych obiektów ze zbioru treningowego. W sytuacjach, gdy predykcja okazuje się błędna, następuje odpowiednia modyfikacja wag.\n",
    "\n",
    "Na początku wagi są zazwyczaj wybierane losowo. Przejście przez cały zbiór treningowy nazywa się **epoką**. Jeśli po jej zakończeniu nie zostało spełnione kryterium zatrzymania, trening jest kontynuowany, a obiekty ze zbioru treningowego są ponownie wprowadzane, tym razem w losowej kolejności.\n",
    "\n",
    "Celem treningu jest ostateczne dopasowanie wag w taki sposób, aby sieć osiągała satysfakcjonujące wyniki predykcji.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kroki algorytmu (trenowanie perceptronu)\n",
    "\n",
    "1. **Inicjalizacja wag:**  \n",
    "   Ustal wagi początkowe, zazwyczaj w sposób losowy.  \n",
    "\n",
    "2. **Rozpoczęcie iteracji:**  \n",
    "   Ustaw indeks obiektu \\( j := 1 \\).  \n",
    "\n",
    "3. **Przetwarzanie obiektu:**  \n",
    "   Wprowadź \\( j \\)-ty obiekt \\( x^{(j)} \\) na wejście sieci i oblicz wynik predykcji \\( \\tilde{y}_j \\).  \n",
    "\n",
    "4. **Porównanie wyników:**  \n",
    "   Porównaj wynik predykcji \\( \\tilde{y}_j \\) z rzeczywistą wartością atrybutu decyzyjnego \\( y^{(j)} \\).  \n",
    "\n",
    "5. **Sprawdzenie poprawności predykcji:**  \n",
    "   - Jeśli odpowiedź sieci jest **nieprawidłowa**, zmodyfikuj wagi zgodnie ze wzorem:  \n",
    "     $$\n",
    "     w_i := w_i + \\Delta w_i\n",
    "     $$  \n",
    "     gdzie \\( \\Delta w_i \\) zależy od wybranego algorytmu uczenia (np. metoda gradientowa).  \n",
    "   - Jeśli odpowiedź jest **prawidłowa**, przejdź do następnego kroku.  \n",
    "\n",
    "6. **Sprawdzenie zakończenia epoki:**  \n",
    "   - Jeśli \\( j = N \\) (wszystkie obiekty zostały przetworzone), oblicz błąd całej epoki:  \n",
    "     - Jeśli błąd epoki jest większy od założonego poziomu, zmień losowo kolejność obiektów w zbiorze treningowym i wróć do kroku nr 2.  \n",
    "     - W przeciwnym razie zakończ algorytm.  \n",
    "   - Jeśli \\( j \\neq N \\), ustaw \\( j := j + 1 \\) i wróć do kroku nr 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aktualizacja wag w perceptronie:\n",
    "\n",
    "Wagi perceptronu są aktualizowane zgodnie z poniższymi wzorami:  \n",
    "$$\n",
    "w_i := w_i + \\alpha \\cdot \\left( y^{(j)} - \\tilde{y}_j \\right) \\cdot x_i^{(j)}\n",
    "$$  \n",
    "$$\n",
    "w_0 := w_0 + \\alpha \\cdot \\left( y^{(j)} - \\tilde{y}_j \\right)\n",
    "$$  \n",
    "gdzie \\( \\alpha > 0 \\) to współczynnik uczenia.\n",
    "\n",
    "\n",
    "Aby lepiej zrozumieć znaczenie wag wyznaczonych w trakcie treningu perceptronu, rozważmy problem klasyfikacji binarnej. Po zakończeniu treningu perceptronu otrzymujemy hiperpłaszczyznę o wymiarze \\( N - 1 \\), która stanowi granicę decyzyjną. Hiperpłaszczyzna ta dzieli \\( N \\)-wymiarową przestrzeń wektorów wejściowych na dwie półprzestrzenie, z których każda odpowiada jednej z klas.\n",
    "\n",
    "W szczególności, jeśli przestrzeń wejściowa jest dwuwymiarowa, granica decyzyjna staje się prostą.\n",
    "\n",
    "Perceptron jest skuteczny tylko w przypadku danych liniowo separowalnych. Oznacza to, że klasy muszą być możliwe do oddzielenia jedną granicą decyzyjną (hiperpłaszczyzną). \n",
    "\n",
    "Dodanie drugiej warstwy neuronów do sieci umożliwia wyznaczenie nieliniowej granicy decyzyjnej. Co więcej, zwiększając liczbę warstw w sieci neuronowej, można uzyskać coraz bardziej złożone granice decyzyjne, co pozwala na efektywne klasyfikowanie bardziej złożonych zbiorów danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wielowarstwowe sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wielowarstwowa sieć neuronowa składa się z kilku warstw neuronów, które są połączone w taki sposób, że wyjścia neuronów z jednej warstwy stają się wejściami neuronów w warstwie kolejnej (Osowski, 1996). Już trójwarstwowa sieć neuronowa jest w stanie modelować dowolną charakterystykę.\n",
    "\n",
    "Nie istnieje uniwersalna i optymalna metoda projektowania architektury sieci neuronowej dla dowolnego problemu. Każdy przypadek wymaga indywidualnego podejścia i dostosowania parametrów.\n",
    "\n",
    "Prosta sieć neuronowa o dwóch warstwach może być przedstawiona jako przykład działania tego modelu. W takiej sieci:  \n",
    "- **Neurony warstwy ukrytej** dzielą przestrzeń obiektów w zbiorze treningowym na dwie półprzestrzenie, rozdzielone hiperpłaszczyznami.  \n",
    "- **Neuron warstwy wyjściowej** dalej dzieli każdą z tych półprzestrzeni na dwie podprzestrzenie.\n",
    "\n",
    "Granica decyzyjna utworzona przez taką sieć jest zbiorem wypukłych wielościanów. Oznacza to, że przestrzeń decyzyjna zostaje podzielona na bardziej złożone regiony, co pozwala na modelowanie bardziej skomplikowanych zależności w danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kroki algorytmu (trenowanie wielowarstwowej sieci neuronowej)\n",
    "\n",
    "1. **Ustalenie hiperparametrów:**  \n",
    "   Określ kluczowe parametry sieci, takie jak liczba warstw oraz liczba neuronów w każdej warstwie.\n",
    "\n",
    "2. **Losowa inicjalizacja wag:**  \n",
    "   Wagi początkowe są ustawiane losowo, często na niewielkie wartości, aby zapewnić stabilność obliczeń.\n",
    "\n",
    "3. **Obliczenie odpowiedzi sieci:**  \n",
    "   Przeprowadź obliczenia warstwa po warstwie, aż do uzyskania wyjścia sieci.\n",
    "\n",
    "4. **Obliczenie błędu:**  \n",
    "   Na wyjściu sieci oblicz różnicę między wartością przewidywaną a rzeczywistą, czyli błąd predykcji.\n",
    "\n",
    "5. **Propagacja błędu wstecz:**  \n",
    "   Rozprowadź błąd z wyjścia sieci do wcześniejszych warstw. Proces ten polega na modyfikacji wag wszystkich neuronów, nadpisując wagi ustalone w kroku nr 2.\n",
    "\n",
    "6. **Iteracja dla kolejnego obiektu:**  \n",
    "   Powtórz kroki 3–5 dla kolejnego obiektu w zbiorze treningowym.\n",
    "\n",
    "7. **Koniec epoki i weryfikacja kryterium stopu:**  \n",
    "   Po przeanalizowaniu wszystkich obiektów w zbiorze treningowym (koniec epoki) sprawdź kryterium zatrzymania. Przykładowym kryterium jest sytuacja, gdy średni błąd przestaje maleć.  \n",
    "   - Jeśli kryterium zatrzymania **nie zostało spełnione**, zmień losowo kolejność obiektów w zbiorze treningowym i wróć do kroku nr 3.  \n",
    "   - Jeśli kryterium **zostało spełnione**, zakończ trening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykład rozpoznawania mowy przy użyciu jednokierunkowej sieci neuronowej\n",
    "\n",
    "W Pythonie do implementacji sieci neuronowych najczęściej wykorzystuje się dwa pakiety: **TensorFlow** (Abadi i in., 2016) oraz **PyTorch** (Paszke i in., 2019). Oba pakiety oferują dużą swobodę w definiowaniu architektury sieci, co stanowi ich istotną zaletę. Jednak dla początkujących użytkowników może to być wyzwaniem, ponieważ wymaga to stworzenia własnych klas oraz funkcji do wczytywania danych i przeprowadzania treningu sieci. Aby ułatwić tę pracę, stworzono nakładki, które upraszczają korzystanie z tych narzędzi, takie jak **Ignite** (Fomin i in., 2020) oraz **Lightning** (Falcon, 2019) dla PyTorcha. W tym przykładzie zastosowana zostanie nakładka **Ignite**.\n",
    "\n",
    "Przykład dotyczy **rozpoznawania mowy** — jednego z kluczowych zastosowań uczenia maszynowego. Dzięki wykorzystaniu sieci neuronowych, które stosują nawet podstawowe rodzaje warstw, uzyskuje się już zadowalające wyniki. W tym przypadku użyta zostanie **jednokierunkowa sieć neuronowa** z warstwami **gęstymi**. Cechą tych warstw jest to, że każdy neuron w warstwie wejściowej jest połączony z każdym neuronem w warstwie wyjściowej, a każde połączenie ma swoją wagę. Wagi te są parametrami sieci i są modyfikowane podczas procesu uczenia.\n",
    "\n",
    "Do rozpoznawania mowy często wykorzystywane są cechy sygnału dźwiękowego, które uzyskuje się na podstawie obliczonego **spektrogramu** i przefiltrowania go za pomocą banku filtrów melowych. Proces ekstrakcji cech zazwyczaj poprzedzany jest filtracją sygnału mowy filtrem **preemfazy**, który uwydatnia składowe o wyższych częstotliwościach. Następnie przelicza się uzyskane wartości na skalę logarytmiczną. Wszystkie te operacje można przeprowadzić za pomocą biblioteki **python_speech_features** dostępnej pod adresem: [python-speech-features](http://python-speech-features.readthedocs.io/).\n",
    "\n",
    "Nagrania, które będą użyte do analizy, pochodzą z bazy **TensorFlow Speech Commands v0.02** dostępnej pod adresem: [TensorFlow Speech Commands](http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz), która zawiera 35 słów w języku angielskim. Sygnały mają długość 1 sekundy — krótsze nagrania zostały odpowiednio uzupełnione zerami, aby osiągnąć stałą długość sygnału. W celu przyspieszenia treningu oraz zredukowania rozmiaru danych, w tym przykładzie zostanie wykorzystane 300 losowo wybranych nagrań dla każdego z 35 słów. W praktyce jednak, dla lepszych wyników, powinno się stosować jak największy zbiór danych.\n",
    "\n",
    "Ekstrakcję cech z tych nagrań, jak opisano powyżej, można zrealizować za pomocą poniższego kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10506 WAV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1465/1170353956.py:30: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, sig = wav.read(signal_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 9517\n",
      "padded_feats shape: (10506, 9517, 26), dtype: float32\n"
     ]
    }
   ],
   "source": [
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "labels_categorical = []\n",
    "root = 'SpeechDataset/'\n",
    "\n",
    "# Iteracja przez katalogi w folderze głównym\n",
    "for ind, subdir in enumerate(os.listdir(root)):\n",
    "    subdir_path = os.path.join(root, subdir)\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "    for file in os.listdir(os.path.join(root, subdir))[:300]:\n",
    "        filepath = os.path.join(root, subdir, file)\n",
    "        if not filepath.endswith('.wav'):\n",
    "            continue\n",
    "        paths.append(filepath)\n",
    "        labels.append(ind)\n",
    "        labels_categorical.append(subdir)\n",
    "\n",
    "print(f\"Found {len(paths)} WAV files\")\n",
    "\n",
    "# Obliczanie cech logfbank dla każdego sygnału\n",
    "logfbank_feats = []\n",
    "for signal_path in paths:\n",
    "    fs, sig = wav.read(signal_path)\n",
    "    fbank_feat = logfbank(sig, samplerate=fs)\n",
    "    logfbank_feats.append(fbank_feat)\n",
    "\n",
    "# Ustalenie maksymalnej długości sygnału i wyrównanie długości\n",
    "lengths = [i.shape[0] for i in logfbank_feats]\n",
    "max_len = np.max(lengths)\n",
    "print(f\"Max length: {max_len}\")\n",
    "\n",
    "# Tworzenie macierzy o ustalonej maksymalnej długości\n",
    "padded_feats = np.zeros((len(lengths), max_len, logfbank_feats[0].shape[1]), dtype=np.float32)\n",
    "for i, feats in enumerate(logfbank_feats):\n",
    "    padded_feats[i, :, :] = np.pad(feats, \n",
    "                                    ((int(np.floor((max_len - feats.shape[0]) / 2)),\n",
    "                                      int(np.ceil((max_len - feats.shape[0]) / 2))),\n",
    "                                     (0, 0)))\n",
    "\n",
    "print(f\"padded_feats shape: {padded_feats.shape}, dtype: {padded_feats.dtype}\")\n",
    "\n",
    "# Zapisanie wyników do plików\n",
    "np.save('logfbank_feats.npy', padded_feats)\n",
    "np.save('labels.npy', labels)\n",
    "np.save('labels_categorical.npy', labels_categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Załadowanie danych\n",
    "feats = np.load('logfbank_feats.npy')\n",
    "labels = np.load('labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels are valid.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 42  # Update this to the correct number of classes\n",
    "\n",
    "# Check if all labels are within the valid range\n",
    "invalid_labels = [label for label in labels if label < 0 or label >= num_classes]\n",
    "if invalid_labels:\n",
    "    print(f\"Invalid labels found: {invalid_labels}\")\n",
    "else:\n",
    "    print(\"All labels are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = feats.reshape(feats.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = feats.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(    \n",
    "    feats,\n",
    "    labels,\n",
    "    random_state=42,\n",
    "    stratify=labels,\n",
    "    train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test,\n",
    "    y_val_test,\n",
    "    random_state=42,\n",
    "    stratify=y_val_test,\n",
    "    train_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierz cech oraz wektor etykiet zostały zapisane do plików, co umożliwia ich ponowne użycie bez konieczności ponownego czasochłonnego obliczania. Po zakończeniu ekstrakcji cech, dane należy rozdzielić na różne zbiory. W poprzednich przypadkach używano dwóch zbiorów: uczącego i testowego. Tym razem jednak dane będą podzielone na trzy zbiory: uczący, walidacyjny i testowy. Zbiór uczący i testowy będą miały tradycyjne zastosowanie – uczący będzie służył do trenowania modelu, a testowy do jego oceny. Zbiór walidacyjny będzie natomiast wykorzystywany do monitorowania wydajności sieci neuronowej w trakcie treningu. Zbiór uczący będzie obejmował 80% danych, podczas gdy walidacyjny i testowy po 10% danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Załadowanie danych\n",
    "feats = np.load('logfbank_feats.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# Przekształcenie danych\n",
    "feats = feats.reshape(feats.shape[0], -1)\n",
    "feats = feats.astype(np.float32)\n",
    "\n",
    "# Podział na zbiory uczący, walidacyjny i testowy\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(    \n",
    "    feats,\n",
    "    labels,\n",
    "    random_state=42,\n",
    "    stratify=labels,\n",
    "    train_size=0.8\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test,\n",
    "    y_val_test,\n",
    "    random_state=42,\n",
    "    stratify=y_val_test,\n",
    "    train_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteki wykorzystywane do implementacji i trenowania sieci neuronowych wymagają, aby dane były przedstawione jako tensory, a nie jako macierze czy tablice, jak miało to miejsce w przypadku wcześniejszych algorytmów. W związku z tym, konieczne jest przekształcenie wektorów etykiet oraz macierzy cech na tensory, a następnie stworzenie z nich obiektu TensorDataset, który jest odpowiednim formatem danych do użycia w sieci neuronowej. Do tego celu służą funkcje `torch.tensor` oraz klasa `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "trainset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "valset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "testset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie, używając klasy DataLoader, tworzone są obiekty do ładowania danych do sieci. Parametr `batch_size` określa liczbę próbek, które będą jednocześnie podawane do modelu. Podział danych na mniejsze partie, zwane wsadami (ang. batch), pozwala na zmniejszenie zużycia pamięci, co jest szczególnie ważne przy dużych zbiorach danych. Dodatkowo, ten proces zwykle przyspiesza trening. Gdy rozmiar wsadu jest mniejszy niż rozmiar całego zbioru, wagi modelu są aktualizowane po każdym wsadzie, ale cała epoka kończy się dopiero po przetworzeniu wszystkich wsadów. Epoka jest wtedy dzielona na iteracje, których liczba odpowiada liczbie wsadów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=256)\n",
    "val_loader = DataLoader(valset, batch_size=256)\n",
    "test_loader = DataLoader(testset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po załadowaniu i odpowiednim przetworzeniu danych, należy stworzyć klasę, w której zdefiniowana będzie struktura sieci. W tej klasie należy określić dwie funkcje:\n",
    "1) `__init__` – w tej funkcji definiuje się rodzaje i rozmiary warstw, które będą stanowiły architekturę sieci,\n",
    "2) `forward` – w tej funkcji opisuje się kolejność warstw, co ustala kierunek przepływu danych w sieci.\n",
    "\n",
    "Zaimplementowana sieć jednokierunkowa będzie składała się z warstw gęstych, które są liniowe i tworzy się je przy użyciu klasy `nn.Linear`. Do tej klasy należy przekazać wymiary warstwy, czyli liczbę neuronów wejściowych oraz wyjściowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZASADA  \n",
    "Liczba neuronów w warstwie wejściowej musi odpowiadać liczbie neuronów w warstwie wyjściowej poprzedniej warstwy. Dla pierwszej warstwy sieci, liczba neuronów wejściowych musi być dopasowana do rozmiaru danych wejściowych. W przypadku danych analizowanych w tym przykładzie, każdy sygnał składa się z 2574 cech, dlatego liczba wejść w pierwszej warstwie musi wynosić 2574."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba neuronów w warstwie wyjściowej powinna odpowiadać liczbie klas w zbiorze danych. W tym przypadku, ponieważ dane zawierają 35 klas, warstwa wyjściowa sieci powinna posiadać 35 wyjść. W funkcji *forward* definiuje się również funkcję aktywacji, która będzie zastosowana w ostatniej warstwie. Wybór funkcji aktywacji ma kluczowy wpływ na wyniki klasyfikacji, ponieważ to ona oblicza wartości na wyjściu sieci. Istnieje wiele funkcji aktywacji, każda odpowiednia do innych zastosowań. W tym przykładzie wykorzystana zostanie funkcja *log_softmax*, będąca logarytmowaną wersją funkcji softmax, która jest znormalizowaną funkcją wykładniczą. Funkcja *softmax* generuje wektor prawdopodobieństw przypisania obiektu do poszczególnych klas, a zastosowanie logarytmu przyspiesza obliczenia numeryczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 120)\n",
    "        self.fc3 = nn.Linear(120, 42)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim rozpoczniemy trening sieci, należy ustalić, na jakim urządzeniu będą przeprowadzane obliczenia — czy mamy dostęp do karty graficznej, czy będziemy korzystać z procesora. Sprawdzanie dostępności karty graficznej odbywa się za pomocą funkcji `torch.cuda.is_available()`. Jeśli karta graficzna jest dostępna, zostanie użyta (ustawiając `device = \"cuda\"`), w przeciwnym razie obliczenia będą realizowane przez procesor (ustawiając `device = \"cpu\"`).\n",
    "\n",
    "Kolejnym krokiem jest zdefiniowanie funkcji straty, czyli ustalenie zmiennej `criterion`, która określi cel uczenia się sieci. W tym przypadku jako funkcję straty zastosujemy klasę `nn.NLLLoss` (ang. negative log likelihood loss). Im mniejsza wartość tej funkcji, tym mniejsza różnica między rzeczywistą klasą a przewidywaniem sieci. `NLLLoss` jest odpowiednikiem entropii krzyżowej, gdy prawdopodobieństwa przynależności do klasy są przekształcone logarytmicznie, co oznacza zastosowanie funkcji aktywacji `log_softmax`. Algorytm obliczania entropii krzyżowej w kontekście binarnym, zwany stratą logarytmiczną, został opisany wcześniej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga  \n",
    "Sieć neuronowa stosowana do klasyfikacji ma liczbę wyjść odpowiadającą liczbie klas w danych, dlatego nie ma potrzeby obliczania skorygowanych prawdopodobieństw. Każde wyjście sieci zwraca prawdopodobieństwo przynależności obiektu do konkretnej klasy. W takim przypadku entropia krzyżowa jest obliczana jako ujemna średnia logarytmiczna prawdopodobieństw, które zostały zwrócone przez odpowiednie wyjścia, odpowiadające rzeczywistym klasom analizowanych obiektów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym ważnym krokiem jest wybór algorytmu optymalizacji wag modelu (ang. optimizer), który dostosowuje ich wartości w celu osiągnięcia ustalonego kryterium, np. minimalizacji wartości NLLLoss. Jednym z najczęściej stosowanych algorytmów optymalizacji jest algorytm stochastycznego spadku gradientu, który został opisany wcześniej. Wielkość kroków w trakcie modyfikacji wag jest określana przez współczynnik uczenia (ang. learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Sprawdza, czy dostępna jest karta graficzna (GPU), jeśli nie, używa CPU\n",
    "print(f'CUDA: {torch.cuda.is_available()}')\n",
    "criterion = nn.NLLLoss()  # Definiuje funkcję strat (strata logarytmiczna z prawdopodobieństw)\n",
    "# device='cpu'\n",
    "\n",
    "i_s = X_train.shape[1]\n",
    "\n",
    "model = Net(i_s)  # Inicjalizuje model sieci neuronowej\n",
    "model.to(device)  # Przenosi model na odpowiednie urządzenie (GPU lub CPU)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-4, momentum=0.9)  # Definiuje optymalizator SGD z określoną szybkością uczenia i momentem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W następnym etapie trzeba zainicjować zmienne, które będą przechowywać bieżące stany modelu oraz optymalizatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kolejnym etapie należy stworzyć dwa obiekty:\n",
    "\n",
    "1) **trainer** – służy do trenowania sieci. Wymaga podania modelu (sieci neuronowej), kryterium oceny (criterion) oraz urządzenia (device), na którym będą wykonywane obliczenia. Używając obiektu trainer, wagi modelu będą aktualizowane w celu osiągnięcia ekstremum zdefiniowanego kryterium (w tym przypadku dążąc do minimum, ponieważ zastosowane kryterium to NLLLoss).\n",
    "\n",
    "2) **evaluator** – służy do ewaluacji modelu, czyli przeprowadza walidację oraz oblicza metryki na zbiorze testowym. Podaje się model i wybrane metryki. W jego przypadku wagi modelu nie będą aktualizowane.\n",
    "\n",
    "Dodatkowo, aby mieć kontrolę nad przebiegiem treningu i śledzić postęp, wykorzystany zostanie pasek postępu, który będzie wyświetlał wyniki uzyskane na zbiorze treningowym w trakcie kolejnych epok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import Loss, Accuracy\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
    "\n",
    "# Tworzymy obiekt trenera\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "\n",
    "# Tworzymy obiekt ewaluatora\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.NLLLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "# Dodajemy pasek postępu do trenera\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed rozpoczęciem procesu treningowego sieci należy również określić liczbę epok. Po każdej z nich możliwe jest obliczenie metryk dla zbioru walidacyjnego, który nie służy bezpośrednio do uczenia, co pozwala ocenić, czy model skutecznie się uczy i czy nie zachodzi ryzyko przeuczenia. Aby przeprowadzić walidację w pakiecie Ignite, należy uruchomić obiekt evaluator, przekazując mu dane walidacyjne. Evaluator powinien zostać podłączony do obiektu trainer za pomocą odpowiedniej funkcji. Poniżej przedstawiono sposób na wyświetlenie wyników walidacji po każdej epoce. Po zakończeniu treningu evaluator będzie wykorzystywany do obliczenia metryk na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc303736e174289807c2d7a5734147d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 1 Avg accuracy: 0.09 Avg loss: 3.53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a412bb8d6f24d81a8c4e0f6564b010e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 2 Avg accuracy: 0.16 Avg loss: 3.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6604fdf6854304a34379f566e1565f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 3 Avg accuracy: 0.14 Avg loss: 3.28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a57300c1692419c8cfe09ff11431293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 4 Avg accuracy: 0.16 Avg loss: 3.20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1675cfb9bc3145e3b8072cee16e65da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 5 Avg accuracy: 0.18 Avg loss: 3.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151077670d1447059a0bddd8fdfd687c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 6 Avg accuracy: 0.18 Avg loss: 3.10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5f571976ed493ebfc002403bd74597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 7 Avg accuracy: 0.19 Avg loss: 3.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b35d6a00814b37a57e409c0655a927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 8 Avg accuracy: 0.22 Avg loss: 2.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4010bb515b4349beb82250cf859aa1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 9 Avg accuracy: 0.24 Avg loss: 2.91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68fb7ed37c2498d8d630032d8bd23de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 10 Avg accuracy: 0.23 Avg loss: 2.87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bf97e8af364d78b084bf513611a447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 11 Avg accuracy: 0.23 Avg loss: 2.85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a72a5ee524845d289f99ee50d4d7182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 12 Avg accuracy: 0.24 Avg loss: 2.81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68a3e7c342d467582cb1b004e947619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/33]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Results - Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Avg accuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m Avg loss: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m      9\u001b[0m         trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch, metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m], metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Trening modelu przez 150 epok\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Ewaluacja modelu na zbiorze testowym\u001b[39;00m\n\u001b[1;32m     15\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mrun(test_loader)\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:1077\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/__init__.py:113\u001b[0m, in \u001b[0;36msupervised_training_step.<locals>.update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m    111\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    112\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 113\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m output \u001b[38;5;241m=\u001b[39m model_fn(model, x)\n\u001b[1;32m    115\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_transform(output)\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/__init__.py:39\u001b[0m, in \u001b[0;36m_prepare_batch\u001b[0;34m(batch, device, non_blocking)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepare batch for training or evaluation: pass to a device with options.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mconvert_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     40\u001b[0m     convert_tensor(y, device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking),\n\u001b[1;32m     41\u001b[0m )\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/utils.py:43\u001b[0m, in \u001b[0;36mconvert_tensor\u001b[0;34m(x, device, non_blocking)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_func\u001b[39m(tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensor\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/utils.py:55\u001b[0m, in \u001b[0;36mapply_to_tensor\u001b[0;34m(x, func)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_to_tensor\u001b[39m(\n\u001b[1;32m     47\u001b[0m     x: Union[torch\u001b[38;5;241m.\u001b[39mTensor, collections\u001b[38;5;241m.\u001b[39mSequence, collections\u001b[38;5;241m.\u001b[39mMapping, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m], func: Callable\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[torch\u001b[38;5;241m.\u001b[39mTensor, collections\u001b[38;5;241m.\u001b[39mSequence, collections\u001b[38;5;241m.\u001b[39mMapping, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply a function on a tensor or mapping, or sequence of tensors.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        x: input tensor or mapping, or sequence of tensors.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        func: the function to apply on ``x``.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/utils.py:71\u001b[0m, in \u001b[0;36mapply_to_type\u001b[0;34m(x, input_type, func)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a function on an object of `input_type` or mapping, or sequence of objects of `input_type`.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    func: the function to apply on ``x``.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, input_type):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/utils.py:41\u001b[0m, in \u001b[0;36mconvert_tensor.<locals>._func\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_func\u001b[39m(tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ignite.engine import Events\n",
    "from IPython.display import clear_output\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "# Walidacja ma być przeprowadzona po zakończeniu każdej epoki\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "# Trening modelu przez 150 epok\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "# Ewaluacja modelu na zbiorze testowym\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład: Automatyczne ustalanie współczynnika uczenia  \n",
    "W powyższym przykłądzie wartość współczynnika uczenia została ręcznie przypisana do funkcji `optim.SGD` i wynosi 3e-4. Istnieje także możliwość automatycznego dostosowania tego współczynnika – w tym celu używa się funkcji `FastaiLRFinder`. Wartość współczynnika jest określana na podstawie parametru `diverge_th`, który kontroluje moment, w którym proces poszukiwania optymalnej wartości zostaje przerwany. Poszukiwania są zatrzymywane, gdy spełnione zostanie kryterium: `current loss > diverge_th * best_loss`.\n",
    "\n",
    "UWAGA  \n",
    "Parametr `diverge_th` może przyjąć dowolną wartość nie mniejszą niż 1, a jego domyślna wartość to 5. Wartość mniejsza niż 5 skutkuje szybszym zakończeniem poszukiwań najlepszego współczynnika uczenia, ale może być ryzykowna, ponieważ w przypadku napotkania lokalnego minimum na początku procesu, poszukiwania zostaną zakończone zbyt wcześnie. W praktyce pozwolenie na większe wartości `current_loss` na początku procesu, a tym samym kontynuowanie poszukiwań, może umożliwić znalezienie globalnego minimum lub przynajmniej lokalnego minimum o niższej wartości, co w konsekwencji prowadzi do lepszego doboru parametru i bardziej efektywnego treningu sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/SI/si/lib/python3.11/site-packages/ignite/handlers/lr_finder.py:514: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  obj = torch.load(cache_filepath.as_posix())\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "learning rate finder didn't run yet so results can't be plotted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m results \u001b[38;5;241m=\u001b[39m lr_finder\u001b[38;5;241m.\u001b[39mget_results()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Wykres przedstawiający wyniki\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mlr_finder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Wyświetlenie sugerowanego współczynnika uczenia\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggested LR:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr_finder\u001b[38;5;241m.\u001b[39mlr_suggestion())\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/handlers/lr_finder.py:271\u001b[0m, in \u001b[0;36mFastaiLRFinder.plot\u001b[0;34m(self, skip_start, skip_end, log_lr, display_suggestion, ax, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method requires matplotlib to be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with command: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m pip install matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_history:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning rate finder didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt run yet so results can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be plotted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_start \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_start cannot be negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: learning rate finder didn't run yet so results can't be plotted"
     ]
    }
   ],
   "source": [
    "from ignite.handlers import FastaiLRFinder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inicjalizacja obiektu FastaiLRFinder\n",
    "lr_finder = FastaiLRFinder()\n",
    "\n",
    "# Przygotowanie słownika z modelem i optymalizatorem\n",
    "to_save = {'model': model, 'optimizer': optimizer}\n",
    "\n",
    "# Dołączenie lr_finder do trenera i ustawienie wartości diverge_th na 1.1\n",
    "with lr_finder.attach(trainer, to_save, diverge_th=1.1, start_lr=1e-6, end_lr=1.0, num_iter=200) as trainer_with_lr_finder:\n",
    "    # Domyślnie start_lr jest taki, jak określono w obiekcie optimizer, \n",
    "    # a end_lr = 10\n",
    "    trainer_with_lr_finder.run(train_loader)\n",
    "\n",
    "# Pobranie wyników po zakończeniu poszukiwań najlepszego LR\n",
    "results = lr_finder.get_results()\n",
    "\n",
    "# Wykres przedstawiający wyniki\n",
    "lr_finder.plot()\n",
    "\n",
    "# Wyświetlenie sugerowanego współczynnika uczenia\n",
    "print(\"Suggested LR:\", lr_finder.lr_suggestion())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po określeniu optymalnej wartości współczynnika uczenia, należy przekazać tę wartość do obiektu optymalizatora. Służy do tego funkcja `apply_suggested_lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current run is terminating due to exception: mat1 and mat2 shapes cannot be multiplied (256x247442 and 2574x256)\n",
      "Engine run is terminating due to exception: mat1 and mat2 shapes cannot be multiplied (256x247442 and 2574x256)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x247442 and 2574x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining with suggested lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Rozpoczęcie treningu\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Ewaluacja na zbiorze testowym\u001b[39;00m\n\u001b[1;32m     37\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mrun(test_loader)\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:1096\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/engine.py:1077\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/__init__.py:114\u001b[0m, in \u001b[0;36msupervised_training_step.<locals>.update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m    112\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    113\u001b[0m x, y \u001b[38;5;241m=\u001b[39m prepare_batch(batch, device\u001b[38;5;241m=\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[0;32m--> 114\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_transform(output)\n\u001b[1;32m    116\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/ignite/engine/__init__.py:439\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m amp_mode, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_supervised_trainer\u001b[39m(\n\u001b[1;32m    427\u001b[0m     model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m    428\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m    429\u001b[0m     loss_fn: Union[Callable[[Any, Any], torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule],\n\u001b[1;32m    430\u001b[0m     device: Optional[Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    431\u001b[0m     non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    432\u001b[0m     prepare_batch: Callable \u001b[38;5;241m=\u001b[39m _prepare_batch,\n\u001b[1;32m    433\u001b[0m     model_transform: Callable[[Any], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m output: output,\n\u001b[1;32m    434\u001b[0m     output_transform: Callable[[Any, Any, Any, torch\u001b[38;5;241m.\u001b[39mTensor], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y, y_pred, loss: loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    435\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    436\u001b[0m     amp_mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    437\u001b[0m     scaler: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.GradScaler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    438\u001b[0m     gradient_accumulation_steps: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m--> 439\u001b[0m     model_fn: Callable[[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, Any], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m model, x: \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Engine:\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Factory function for creating a trainer for supervised models.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m        Added support for ``mps`` device\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     device_type \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01melse\u001b[39;00m device\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Przechodzimy przez pierwszą warstwę\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)  \u001b[38;5;66;03m# Zastosowanie dropout po pierwszej warstwie\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)  \u001b[38;5;66;03m# Przechodzimy przez drugą warstwę\u001b[39;00m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/SI/si/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x247442 and 2574x256)"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.handlers import FastaiLRFinder\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Utworzenie obiektów trainer i evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model,\n",
    "    metrics={\"acc\": Accuracy(), \"loss\": Loss(nn.NLLLoss())},\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Dodanie paska postępu do trenera\n",
    "ProgressBar(persist=True).attach(\n",
    "    trainer, output_transform=lambda x: {\"batch loss\": x}\n",
    ")\n",
    "\n",
    "# Funkcja walidacji po zakończeniu epoki\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)  # Przeprowadzenie walidacji\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Validation Results - Epoch: {trainer.state.epoch} \"\n",
    "          f\"Avg accuracy: {metrics['acc']:.2f} \"\n",
    "          f\"Avg loss: {metrics['loss']:.2f}\")\n",
    "    \n",
    "    # Zastosowanie sugerowanego współczynnika uczenia\n",
    "    lr_finder.apply_suggested_lr(optimizer)\n",
    "    print(f'Training with suggested lr: {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "# Rozpoczęcie treningu\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "# Ewaluacja na zbiorze testowym\n",
    "evaluator.run(test_loader)\n",
    "clear_output()\n",
    "print(evaluator.state.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład: Zastosowanie warstwy dropout\n",
    "\n",
    "Sieci neuronowe, zwłaszcza te głębokie, czyli składające się z wielu warstw ukrytych, mają tendencję do przeuczania się, gdy liczba danych treningowych jest zbyt mała. Ponieważ nie zawsze jest możliwe zwiększenie zbioru uczącego, konieczne staje się zastosowanie innych metod, które pomagają zminimalizować przeuczenie. Jedną z popularnych technik jest dropout, który polega na losowym \"wyłączaniu\" neuronów podczas każdej iteracji (czyli ustawianiu ich wag na 0) oraz na skalowaniu wag pozostałych neuronów przez współczynnik 1/(1 - p), gdzie p oznacza prawdopodobieństwo wyłączenia danego neuronu. Dzięki temu sieć nie jest w stanie idealnie dopasować się do danych uczących, ponieważ musi nauczyć się dostosowywać wagi w taki sposób, by uzyskiwać dobre wyniki, nawet gdy część neuronów jest nieaktywna.\n",
    "\n",
    "Podczas definiowania warstwy dropout, należy ustalić, z jakim prawdopodobieństwem neurony będą wyłączane. Domyślnie wynosi ono 0,5, ale można je dostosować, pamiętając, że zmiana tego parametru wymaga staranności. Jeśli wartość p będzie zbyt wysoka, sieć może mieć trudności w nauce rozpoznawania zależności w danych, co wpłynie na skuteczność klasyfikacji. Z kolei zbyt niskie p sprawi, że regularyzacja będzie nieskuteczna i nie zmniejszy przeuczenia. Warstwy dropout powinny być inicjalizowane w metodzie init klasy modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)  # Pierwsza warstwa gęsta\n",
    "        self.fc2 = nn.Linear(256, 120)   # Druga warstwa gęsta\n",
    "        self.fc3 = nn.Linear(120, 42)    # Trzecia warstwa gęsta\n",
    "        self.dropout1 = nn.Dropout(p = 0.5)  # Pierwsza warstwa dropout (50% prawdopodobieństwo wyłączenia neuronów)\n",
    "        self.dropout2 = nn.Dropout(p = 0.2)  # Druga warstwa dropout (20% prawdopodobieństwo wyłączenia neuronów)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Przechodzimy przez pierwszą warstwę\n",
    "        x = self.dropout1(x)  # Zastosowanie dropout po pierwszej warstwie\n",
    "        x = self.fc2(x)  # Przechodzimy przez drugą warstwę\n",
    "        x = self.dropout2(x)  # Zastosowanie dropout po drugiej warstwie\n",
    "        x = self.fc3(x)  # Przechodzimy przez trzecią warstwę\n",
    "        return F.log_softmax(x, dim = 1)  # Zastosowanie logarytmu softmax na wyjściu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: Modyfikacja architektury jednokierunkowej sieci neuronowej do rozpoznawania mowy\n",
    "\n",
    "W przykładzie zatytułowanym \"Rozpoznawanie mowy przy użyciu jednokierunkowej sieci neuronowej\" zaprezentowano bardzo prostą architekturę sieci. Niestety, jej zastosowanie nie prowadzi do zadowalających wyników – dokładność klasyfikacji na zbiorze walidacyjnym wynosi jedynie 0,33, a na zbiorze testowym 0,34. Celem jest modyfikacja tej sieci, aby osiągnąć wyższą dokładność klasyfikacji na obu zbiorach. Można to osiągnąć przez wprowadzenie następujących zmian:\n",
    "\n",
    "- Dodanie dodatkowych warstw (należy zadbać o odpowiednią liczbę wejść i wyjść),\n",
    "- Wprowadzenie warstw dropout, które pomogą w regularizacji sieci,\n",
    "- Zmiana funkcji aktywacji w warstwach (np. zastosowanie funkcji ReLU: `x = F.relu(self.fc1(x))`),\n",
    "- Zmiana algorytmu optymalizacji wag na inny, bardziej efektywny.\n",
    "\n",
    "Po wprowadzeniu modyfikacji warto sprawdzić, czy dotychczasowa liczba epok jest wystarczająca do nauczenia sieci. Jeśli w trakcie treningu dokładność na zbiorze walidacyjnym nadal rośnie, oznacza to, że sieć nie jest jeszcze w pełni wytrenowana i warto zwiększyć liczbę epok. Jeśli natomiast zauważysz spadek dokładności, oznacza to, że sieć mogła się przeuczyć i liczba epok powinna zostać zmniejszona.\n",
    "\n",
    "**UWAGA**  \n",
    "Przeuczenie sieci występuje, gdy zauważalny jest wyraźny spadek dokładności klasyfikacji na zbiorze walidacyjnym. Jednakże, pojedyncze spadki dokładności, po których następuje stabilizacja lub wzrost tej wartości, są normalnym zjawiskiem w trakcie treningu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
