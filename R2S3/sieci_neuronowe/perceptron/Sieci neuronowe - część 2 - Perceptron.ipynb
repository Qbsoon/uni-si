{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wprowadzenie do sieci neuronowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieci neuronowe stanowią odrębną i rozbudowaną dziedzinę uczenia maszynowego. Mimo że początkowe modele mogą wydawać się proste, zrewolucjonizowały one sposób myślenia o problemach rozwiązywanych z wykorzystaniem sztucznej inteligencji. Co więcej, w połączeniu z postępującą cyfryzacją danych i rosnącymi możliwościami komputerów, wczesne modele sieci neuronowych stały się fundamentem zaawansowanych, przełomowych technologii, które odmieniły naszą rzeczywistość. Jeszcze kilkadziesiąt lat temu automatyczne rozpoznawanie obrazów czy dźwięków było uznawane za domenę literatury science fiction. Dziś jest to nasza codzienność.  \n",
    "\n",
    "Sztuczne sieci neuronowe, zgodnie z nazwą, są inspirowane funkcjonowaniem ludzkiego mózgu, który składa się z neuronów – komórek nerwowych. Podstawowe podobieństwo między sztucznymi a biologicznymi sieciami neuronowymi polega na ich strukturalnym układzie, opartym na wielokrotnym powielaniu tego samego elementu. Również sposób przekazywania informacji wykazuje analogię – sygnał wędruje zwykle w jednym kierunku, a działanie odbywa się zgodnie z zasadą „wszystko albo nic”. Oznacza to, że słabe impulsy nie powodują reakcji, natomiast przekroczenie określonego progu prowadzi do transmisji sygnału. Poglądowe połączenie dwóch neuronów ilustruje tę koncepcję.  \n",
    "\n",
    "Pierwszy model pojedynczej komórki nerwowej został stworzony w 1943 roku przez Warrena McCullocha i Waltera Pittsa. Wykorzystali go do przedstawienia podstawowych operacji logicznych, takich jak koniunkcja czy alternatywa (McCulloch i Pitts, 1943). Na bazie tego modelu, Frank Rosenblatt w 1958 roku opracował pierwszą prostą sieć neuronową, znaną jako perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Budowa perceptronu:\n",
    "1. **Zbiór danych treningowych**  \n",
    "   Dane wejściowe, zwane sygnałami zewnętrznymi, są opisane jako \\( x^{(j)} = (x_1^{(j)}, x_2^{(j)}, \\dots, x_d^{(j)}) \\), gdzie \\( j = 1, \\dots, N \\). Każdy z tych sygnałów trafia na wejście sieci.\n",
    "\n",
    "2. **Stały sygnał wejściowy**  \n",
    "   Istnieje wejście numer zero, które zawsze przyjmuje wartość \\( x_0 = 1 \\) i jest powiązane z wagą \\( w_0 \\).\n",
    "\n",
    "3. **Wejścia dla sygnałów zewnętrznych**  \n",
    "   Dla \\( i = 1, \\dots, d \\) sygnały \\( x_i \\) są wprowadzane przez odpowiednie wejścia.\n",
    "\n",
    "4. **Wagi wejściowe**  \n",
    "   Każda waga \\( w_{ij} \\) odzwierciedla wpływ danej zmiennej \\( x_i \\) na wynik predykcji dla obiektu \\( j \\).\n",
    "\n",
    "5. **Sumator**  \n",
    "   Odpowiada za obliczenie całkowitego pobudzenia neuronu \\( u_j \\) jako kombinacji liniowej sygnałów i wag.\n",
    "\n",
    "6. **Funkcja aktywacji**  \n",
    "   Funkcja \\( f(u_j) \\) określa wartość wyjściową neuronu na podstawie pobudzenia \\( u_j \\). \n",
    "\n",
    "---\n",
    "\n",
    "Wybór odpowiedniej funkcji aktywacji ma kluczowe znaczenie. Powinna być ona monotoniczna, różniczkowalna w swojej dziedzinie oraz ciągła, choć kształtem może przypominać funkcję skokową. Najczęściej stosowane funkcje to: liniowa, sigmoidalna, tangens hiperboliczny oraz funkcja Gaussa. Nazwy neuronów często pochodzą od zastosowanej funkcji aktywacji.\n",
    "\n",
    "---\n",
    "\n",
    "#### Działanie perceptronu:\n",
    "\n",
    "**Kombinacja liniowa sygnałów i wag:**  \n",
    "Na wyjściu sumatora otrzymujemy liniową kombinację sygnałów wejściowych i wag:\n",
    "\\[\n",
    "u_j = w_0 x_0 + \\sum_{i=1}^d w_i x_i\n",
    "\\]\n",
    "gdzie \\( w_0 x_0 \\) jest wartością progową funkcji aktywacji.\n",
    "\n",
    "**Wartość wyjściowa neuronu:**  \n",
    "Wyjście neuronu to wynik funkcji aktywacji \\( f(u_j) \\), czyli:\n",
    "\\[\n",
    "\\tilde{y}_j = f \\left( w_0 + \\sum_{i=1}^d w_i x_i \\right)\n",
    "\\]\n",
    "Wartość \\( \\tilde{y}_j \\) reprezentuje predykcję perceptronu dla obiektu \\( x^{(j)} \\). \n",
    "\n",
    "Podczas treningu lub testowania predykcja \\( \\tilde{y}_j \\) jest porównywana z rzeczywistą wartością decyzyjną \\( y^{(j)} \\). Proces uczenia polega na iteracyjnym wprowadzaniu obiektów ze zbioru treningowego oraz modyfikacji wag w przypadku błędnej predykcji. \n",
    "\n",
    "---\n",
    "\n",
    "#### Proces treningu:\n",
    "- Na początku wagi są inicjalizowane losowo.\n",
    "- Każde przejście przez cały zbiór treningowy nazywane jest **epoką**.\n",
    "- Jeśli kryterium zakończenia nie zostanie spełnione, trening jest kontynuowany z nową, losową kolejnością obiektów.  \n",
    "Celem treningu jest znalezienie takiego zestawu wag, który zapewni możliwie najlepsze predykcje. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Budowa perceptronu:\n",
    "1. **Zbiór danych treningowych**  \n",
    "   Dane wejściowe, zwane sygnałami zewnętrznymi, są opisane jako:  \n",
    "   $$\n",
    "   x^{(j)} = (x_1^{(j)}, x_2^{(j)}, \\dots, x_d^{(j)})\n",
    "   $$  \n",
    "   gdzie \\( j = 1, \\dots, N \\). Każdy z tych sygnałów trafia na wejście sieci.\n",
    "\n",
    "2. **Stały sygnał wejściowy**  \n",
    "   Istnieje wejście numer zero, które zawsze przyjmuje wartość:  \n",
    "   $$\n",
    "   x_0 = 1\n",
    "   $$  \n",
    "   i jest powiązane z wagą \\( w_0 \\).\n",
    "\n",
    "3. **Wejścia dla sygnałów zewnętrznych**  \n",
    "   Dla \\( i = 1, \\dots, d \\) sygnały \\( x_i \\) są wprowadzane przez odpowiednie wejścia.\n",
    "\n",
    "4. **Wagi wejściowe**  \n",
    "   Każda waga \\( w_{ij} \\) odzwierciedla wpływ danej zmiennej \\( x_i \\) na wynik predykcji dla obiektu \\( j \\).\n",
    "\n",
    "5. **Sumator**  \n",
    "   Odpowiada za obliczenie całkowitego pobudzenia neuronu \\( u_j \\) jako kombinacji liniowej sygnałów i wag.\n",
    "\n",
    "6. **Funkcja aktywacji**  \n",
    "   Funkcja \\( f(u_j) \\) określa wartość wyjściową neuronu na podstawie pobudzenia \\( u_j \\). \n",
    "\n",
    "#### Działanie perceptronu:\n",
    "\n",
    "**Kombinacja liniowa sygnałów i wag:**  \n",
    "Na wyjściu sumatora otrzymujemy liniową kombinację sygnałów wejściowych i wag:\n",
    "$$\n",
    "u_j = w_0 x_0 + \\sum_{i=1}^d w_i x_i\n",
    "$$  \n",
    "gdzie \\( w_0 x_0 \\) jest wartością progową funkcji aktywacji.\n",
    "\n",
    "**Wartość wyjściowa neuronu:**  \n",
    "Wyjście neuronu to wynik funkcji aktywacji \\( f(u_j) \\), czyli:\n",
    "$$\n",
    "\\tilde{y}_j = f \\left( w_0 + \\sum_{i=1}^d w_i x_i \\right)\n",
    "$$  \n",
    "Wartość \\( \\tilde{y}_j \\) reprezentuje predykcję perceptronu dla obiektu \\( x^{(j)} \\).\n",
    "\n",
    "Podczas treningu lub testowania predykcja \\( \\tilde{y}_j \\) jest porównywana z rzeczywistą wartością decyzyjną \\( y^{(j)} \\). Proces uczenia polega na iteracyjnym wprowadzaniu obiektów ze zbioru treningowego oraz modyfikacji wag w przypadku błędnej predykcji.\n",
    "\n",
    "#### Proces treningu:\n",
    "Wartość \\( \\tilde{y}_j \\) stanowi predykcję perceptronu dla obiektu \\( x^{(j)} \\). Na etapie treningu lub testowania jest ona porównywana z rzeczywistą wartością atrybutu decyzyjnego \\( y^{(j)} \\). Proces trenowania sieci neuronowej przebiega iteracyjnie i polega na wprowadzaniu do wejścia perceptronu kolejnych obiektów ze zbioru treningowego. W sytuacjach, gdy predykcja okazuje się błędna, następuje odpowiednia modyfikacja wag.\n",
    "\n",
    "Na początku wagi są zazwyczaj wybierane losowo. Przejście przez cały zbiór treningowy nazywa się **epoką**. Jeśli po jej zakończeniu nie zostało spełnione kryterium zatrzymania, trening jest kontynuowany, a obiekty ze zbioru treningowego są ponownie wprowadzane, tym razem w losowej kolejności.\n",
    "\n",
    "Celem treningu jest ostateczne dopasowanie wag w taki sposób, aby sieć osiągała satysfakcjonujące wyniki predykcji.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kroki algorytmu (trenowanie perceptronu)\n",
    "\n",
    "1. **Inicjalizacja wag:**  \n",
    "   Ustal wagi początkowe, zazwyczaj w sposób losowy.  \n",
    "\n",
    "2. **Rozpoczęcie iteracji:**  \n",
    "   Ustaw indeks obiektu \\( j := 1 \\).  \n",
    "\n",
    "3. **Przetwarzanie obiektu:**  \n",
    "   Wprowadź \\( j \\)-ty obiekt \\( x^{(j)} \\) na wejście sieci i oblicz wynik predykcji \\( \\tilde{y}_j \\).  \n",
    "\n",
    "4. **Porównanie wyników:**  \n",
    "   Porównaj wynik predykcji \\( \\tilde{y}_j \\) z rzeczywistą wartością atrybutu decyzyjnego \\( y^{(j)} \\).  \n",
    "\n",
    "5. **Sprawdzenie poprawności predykcji:**  \n",
    "   - Jeśli odpowiedź sieci jest **nieprawidłowa**, zmodyfikuj wagi zgodnie ze wzorem:  \n",
    "     $$\n",
    "     w_i := w_i + \\Delta w_i\n",
    "     $$  \n",
    "     gdzie \\( \\Delta w_i \\) zależy od wybranego algorytmu uczenia (np. metoda gradientowa).  \n",
    "   - Jeśli odpowiedź jest **prawidłowa**, przejdź do następnego kroku.  \n",
    "\n",
    "6. **Sprawdzenie zakończenia epoki:**  \n",
    "   - Jeśli \\( j = N \\) (wszystkie obiekty zostały przetworzone), oblicz błąd całej epoki:  \n",
    "     - Jeśli błąd epoki jest większy od założonego poziomu, zmień losowo kolejność obiektów w zbiorze treningowym i wróć do kroku nr 2.  \n",
    "     - W przeciwnym razie zakończ algorytm.  \n",
    "   - Jeśli \\( j \\neq N \\), ustaw \\( j := j + 1 \\) i wróć do kroku nr 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aktualizacja wag w perceptronie:\n",
    "\n",
    "Wagi perceptronu są aktualizowane zgodnie z poniższymi wzorami:  \n",
    "$$\n",
    "w_i := w_i + \\alpha \\cdot \\left( y^{(j)} - \\tilde{y}_j \\right) \\cdot x_i^{(j)}\n",
    "$$  \n",
    "$$\n",
    "w_0 := w_0 + \\alpha \\cdot \\left( y^{(j)} - \\tilde{y}_j \\right)\n",
    "$$  \n",
    "gdzie \\( \\alpha > 0 \\) to współczynnik uczenia.\n",
    "\n",
    "\n",
    "Aby lepiej zrozumieć znaczenie wag wyznaczonych w trakcie treningu perceptronu, rozważmy problem klasyfikacji binarnej. Po zakończeniu treningu perceptronu otrzymujemy hiperpłaszczyznę o wymiarze \\( N - 1 \\), która stanowi granicę decyzyjną. Hiperpłaszczyzna ta dzieli \\( N \\)-wymiarową przestrzeń wektorów wejściowych na dwie półprzestrzenie, z których każda odpowiada jednej z klas.\n",
    "\n",
    "W szczególności, jeśli przestrzeń wejściowa jest dwuwymiarowa, granica decyzyjna staje się prostą.\n",
    "\n",
    "Perceptron jest skuteczny tylko w przypadku danych liniowo separowalnych. Oznacza to, że klasy muszą być możliwe do oddzielenia jedną granicą decyzyjną (hiperpłaszczyzną). \n",
    "\n",
    "Dodanie drugiej warstwy neuronów do sieci umożliwia wyznaczenie nieliniowej granicy decyzyjnej. Co więcej, zwiększając liczbę warstw w sieci neuronowej, można uzyskać coraz bardziej złożone granice decyzyjne, co pozwala na efektywne klasyfikowanie bardziej złożonych zbiorów danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wielowarstwowe sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wielowarstwowa sieć neuronowa składa się z kilku warstw neuronów, które są połączone w taki sposób, że wyjścia neuronów z jednej warstwy stają się wejściami neuronów w warstwie kolejnej (Osowski, 1996). Już trójwarstwowa sieć neuronowa jest w stanie modelować dowolną charakterystykę.\n",
    "\n",
    "Nie istnieje uniwersalna i optymalna metoda projektowania architektury sieci neuronowej dla dowolnego problemu. Każdy przypadek wymaga indywidualnego podejścia i dostosowania parametrów.\n",
    "\n",
    "Prosta sieć neuronowa o dwóch warstwach może być przedstawiona jako przykład działania tego modelu. W takiej sieci:  \n",
    "- **Neurony warstwy ukrytej** dzielą przestrzeń obiektów w zbiorze treningowym na dwie półprzestrzenie, rozdzielone hiperpłaszczyznami.  \n",
    "- **Neuron warstwy wyjściowej** dalej dzieli każdą z tych półprzestrzeni na dwie podprzestrzenie.\n",
    "\n",
    "Granica decyzyjna utworzona przez taką sieć jest zbiorem wypukłych wielościanów. Oznacza to, że przestrzeń decyzyjna zostaje podzielona na bardziej złożone regiony, co pozwala na modelowanie bardziej skomplikowanych zależności w danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kroki algorytmu (trenowanie wielowarstwowej sieci neuronowej)\n",
    "\n",
    "1. **Ustalenie hiperparametrów:**  \n",
    "   Określ kluczowe parametry sieci, takie jak liczba warstw oraz liczba neuronów w każdej warstwie.\n",
    "\n",
    "2. **Losowa inicjalizacja wag:**  \n",
    "   Wagi początkowe są ustawiane losowo, często na niewielkie wartości, aby zapewnić stabilność obliczeń.\n",
    "\n",
    "3. **Obliczenie odpowiedzi sieci:**  \n",
    "   Przeprowadź obliczenia warstwa po warstwie, aż do uzyskania wyjścia sieci.\n",
    "\n",
    "4. **Obliczenie błędu:**  \n",
    "   Na wyjściu sieci oblicz różnicę między wartością przewidywaną a rzeczywistą, czyli błąd predykcji.\n",
    "\n",
    "5. **Propagacja błędu wstecz:**  \n",
    "   Rozprowadź błąd z wyjścia sieci do wcześniejszych warstw. Proces ten polega na modyfikacji wag wszystkich neuronów, nadpisując wagi ustalone w kroku nr 2.\n",
    "\n",
    "6. **Iteracja dla kolejnego obiektu:**  \n",
    "   Powtórz kroki 3–5 dla kolejnego obiektu w zbiorze treningowym.\n",
    "\n",
    "7. **Koniec epoki i weryfikacja kryterium stopu:**  \n",
    "   Po przeanalizowaniu wszystkich obiektów w zbiorze treningowym (koniec epoki) sprawdź kryterium zatrzymania. Przykładowym kryterium jest sytuacja, gdy średni błąd przestaje maleć.  \n",
    "   - Jeśli kryterium zatrzymania **nie zostało spełnione**, zmień losowo kolejność obiektów w zbiorze treningowym i wróć do kroku nr 3.  \n",
    "   - Jeśli kryterium **zostało spełnione**, zakończ trening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykład rozpoznawania mowy przy użyciu jednokierunkowej sieci neuronowej\n",
    "\n",
    "W Pythonie do implementacji sieci neuronowych najczęściej wykorzystuje się dwa pakiety: **TensorFlow** (Abadi i in., 2016) oraz **PyTorch** (Paszke i in., 2019). Oba pakiety oferują dużą swobodę w definiowaniu architektury sieci, co stanowi ich istotną zaletę. Jednak dla początkujących użytkowników może to być wyzwaniem, ponieważ wymaga to stworzenia własnych klas oraz funkcji do wczytywania danych i przeprowadzania treningu sieci. Aby ułatwić tę pracę, stworzono nakładki, które upraszczają korzystanie z tych narzędzi, takie jak **Ignite** (Fomin i in., 2020) oraz **Lightning** (Falcon, 2019) dla PyTorcha. W tym przykładzie zastosowana zostanie nakładka **Ignite**.\n",
    "\n",
    "Przykład dotyczy **rozpoznawania mowy** — jednego z kluczowych zastosowań uczenia maszynowego. Dzięki wykorzystaniu sieci neuronowych, które stosują nawet podstawowe rodzaje warstw, uzyskuje się już zadowalające wyniki. W tym przypadku użyta zostanie **jednokierunkowa sieć neuronowa** z warstwami **gęstymi**. Cechą tych warstw jest to, że każdy neuron w warstwie wejściowej jest połączony z każdym neuronem w warstwie wyjściowej, a każde połączenie ma swoją wagę. Wagi te są parametrami sieci i są modyfikowane podczas procesu uczenia.\n",
    "\n",
    "Do rozpoznawania mowy często wykorzystywane są cechy sygnału dźwiękowego, które uzyskuje się na podstawie obliczonego **spektrogramu** i przefiltrowania go za pomocą banku filtrów melowych. Proces ekstrakcji cech zazwyczaj poprzedzany jest filtracją sygnału mowy filtrem **preemfazy**, który uwydatnia składowe o wyższych częstotliwościach. Następnie przelicza się uzyskane wartości na skalę logarytmiczną. Wszystkie te operacje można przeprowadzić za pomocą biblioteki **python_speech_features** dostępnej pod adresem: [python-speech-features](http://python-speech-features.readthedocs.io/).\n",
    "\n",
    "Nagrania, które będą użyte do analizy, pochodzą z bazy **TensorFlow Speech Commands v0.02** dostępnej pod adresem: [TensorFlow Speech Commands](http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz), która zawiera 35 słów w języku angielskim. Sygnały mają długość 1 sekundy — krótsze nagrania zostały odpowiednio uzupełnione zerami, aby osiągnąć stałą długość sygnału. W celu przyspieszenia treningu oraz zredukowania rozmiaru danych, w tym przykładzie zostanie wykorzystane 300 losowo wybranych nagrań dla każdego z 35 słów. W praktyce jednak, dla lepszych wyników, powinno się stosować jak największy zbiór danych.\n",
    "\n",
    "Ekstrakcję cech z tych nagrań, jak opisano powyżej, można zrealizować za pomocą poniższego kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "labels_categorical = []\n",
    "root = 'SpeechDataset/'\n",
    "\n",
    "# Iteracja przez katalogi w folderze głównym\n",
    "for ind, subdir in enumerate(os.listdir(root)):\n",
    "    for file in os.listdir(os.path.join(root, subdir))[:300]:\n",
    "        filepath = os.path.join(root, subdir, file)\n",
    "        paths.append(filepath)\n",
    "        labels.append(ind)\n",
    "        labels_categorical.append(subdir)\n",
    "\n",
    "# Obliczanie cech logfbank dla każdego sygnału\n",
    "logfbank_feats = []\n",
    "for signal_path in paths:\n",
    "    fs, sig = wav.read(signal_path)\n",
    "    fbank_feat = logfbank(sig, samplerate=fs)\n",
    "    logfbank_feats.append(fbank_feat)\n",
    "\n",
    "# Ustalenie maksymalnej długości sygnału i wyrównanie długości\n",
    "lengths = [i.shape[0] for i in logfbank_feats]\n",
    "max_len = np.max(lengths)\n",
    "\n",
    "# Tworzenie macierzy o ustalonej maksymalnej długości\n",
    "padded_feats = np.zeros((len(lengths), max_len, logfbank_feats[0].shape[1]))\n",
    "for i, feats in enumerate(logfbank_feats):\n",
    "    padded_feats[i, :, :] = np.pad(feats, \n",
    "                                    ((np.int(np.floor((max_len - feats.shape[0]) / 2)),\n",
    "                                      np.int(np.ceil((max_len - feats.shape[0]) / 2))),\n",
    "                                     (0, 0)))\n",
    "\n",
    "# Zapisanie wyników do plików\n",
    "np.save('logfbank_feats.npy', padded_feats)\n",
    "np.save('labels.npy', labels)\n",
    "np.save('labels_categorical.npy', labels_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierz cech oraz wektor etykiet zostały zapisane do plików, co umożliwia ich ponowne użycie bez konieczności ponownego czasochłonnego obliczania. Po zakończeniu ekstrakcji cech, dane należy rozdzielić na różne zbiory. W poprzednich przypadkach używano dwóch zbiorów: uczącego i testowego. Tym razem jednak dane będą podzielone na trzy zbiory: uczący, walidacyjny i testowy. Zbiór uczący i testowy będą miały tradycyjne zastosowanie – uczący będzie służył do trenowania modelu, a testowy do jego oceny. Zbiór walidacyjny będzie natomiast wykorzystywany do monitorowania wydajności sieci neuronowej w trakcie treningu. Zbiór uczący będzie obejmował 80% danych, podczas gdy walidacyjny i testowy po 10% danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Załadowanie danych\n",
    "feats = np.load('logfbank_feats.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# Przekształcenie danych\n",
    "feats = feats.reshape(feats.shape[0], -1)\n",
    "feats = feats.astype(np.float32)\n",
    "\n",
    "# Podział na zbiory uczący, walidacyjny i testowy\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(\n",
    "    feats,\n",
    "    labels,\n",
    "    random_state=42,\n",
    "    stratify=labels,\n",
    "    train_size=0.8\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test,\n",
    "    y_val_test,\n",
    "    random_state=42,\n",
    "    stratify=y_val_test,\n",
    "    train_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteki wykorzystywane do implementacji i trenowania sieci neuronowych wymagają, aby dane były przedstawione jako tensory, a nie jako macierze czy tablice, jak miało to miejsce w przypadku wcześniejszych algorytmów. W związku z tym, konieczne jest przekształcenie wektorów etykiet oraz macierzy cech na tensory, a następnie stworzenie z nich obiektu TensorDataset, który jest odpowiednim formatem danych do użycia w sieci neuronowej. Do tego celu służą funkcje `torch.tensor` oraz klasa `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "trainset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "valset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "testset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie, używając klasy DataLoader, tworzone są obiekty do ładowania danych do sieci. Parametr `batch_size` określa liczbę próbek, które będą jednocześnie podawane do modelu. Podział danych na mniejsze partie, zwane wsadami (ang. batch), pozwala na zmniejszenie zużycia pamięci, co jest szczególnie ważne przy dużych zbiorach danych. Dodatkowo, ten proces zwykle przyspiesza trening. Gdy rozmiar wsadu jest mniejszy niż rozmiar całego zbioru, wagi modelu są aktualizowane po każdym wsadzie, ale cała epoka kończy się dopiero po przetworzeniu wszystkich wsadów. Epoka jest wtedy dzielona na iteracje, których liczba odpowiada liczbie wsadów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=256)\n",
    "val_loader = DataLoader(valset, batch_size=256)\n",
    "test_loader = DataLoader(testset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po załadowaniu i odpowiednim przetworzeniu danych, należy stworzyć klasę, w której zdefiniowana będzie struktura sieci. W tej klasie należy określić dwie funkcje:\n",
    "1) `__init__` – w tej funkcji definiuje się rodzaje i rozmiary warstw, które będą stanowiły architekturę sieci,\n",
    "2) `forward` – w tej funkcji opisuje się kolejność warstw, co ustala kierunek przepływu danych w sieci.\n",
    "\n",
    "Zaimplementowana sieć jednokierunkowa będzie składała się z warstw gęstych, które są liniowe i tworzy się je przy użyciu klasy `nn.Linear`. Do tej klasy należy przekazać wymiary warstwy, czyli liczbę neuronów wejściowych oraz wyjściowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZASADA  \n",
    "Liczba neuronów w warstwie wejściowej musi odpowiadać liczbie neuronów w warstwie wyjściowej poprzedniej warstwy. Dla pierwszej warstwy sieci, liczba neuronów wejściowych musi być dopasowana do rozmiaru danych wejściowych. W przypadku danych analizowanych w tym przykładzie, każdy sygnał składa się z 2574 cech, dlatego liczba wejść w pierwszej warstwie musi wynosić 2574."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba neuronów w warstwie wyjściowej powinna odpowiadać liczbie klas w zbiorze danych. W tym przypadku, ponieważ dane zawierają 35 klas, warstwa wyjściowa sieci powinna posiadać 35 wyjść. W funkcji *forward* definiuje się również funkcję aktywacji, która będzie zastosowana w ostatniej warstwie. Wybór funkcji aktywacji ma kluczowy wpływ na wyniki klasyfikacji, ponieważ to ona oblicza wartości na wyjściu sieci. Istnieje wiele funkcji aktywacji, każda odpowiednia do innych zastosowań. W tym przykładzie wykorzystana zostanie funkcja *log_softmax*, będąca logarytmowaną wersją funkcji softmax, która jest znormalizowaną funkcją wykładniczą. Funkcja *softmax* generuje wektor prawdopodobieństw przypisania obiektu do poszczególnych klas, a zastosowanie logarytmu przyspiesza obliczenia numeryczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2574, 256)\n",
    "        self.fc2 = nn.Linear(256, 120)\n",
    "        self.fc3 = nn.Linear(120, 35)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim rozpoczniemy trening sieci, należy ustalić, na jakim urządzeniu będą przeprowadzane obliczenia — czy mamy dostęp do karty graficznej, czy będziemy korzystać z procesora. Sprawdzanie dostępności karty graficznej odbywa się za pomocą funkcji `torch.cuda.is_available()`. Jeśli karta graficzna jest dostępna, zostanie użyta (ustawiając `device = \"cuda\"`), w przeciwnym razie obliczenia będą realizowane przez procesor (ustawiając `device = \"cpu\"`).\n",
    "\n",
    "Kolejnym krokiem jest zdefiniowanie funkcji straty, czyli ustalenie zmiennej `criterion`, która określi cel uczenia się sieci. W tym przypadku jako funkcję straty zastosujemy klasę `nn.NLLLoss` (ang. negative log likelihood loss). Im mniejsza wartość tej funkcji, tym mniejsza różnica między rzeczywistą klasą a przewidywaniem sieci. `NLLLoss` jest odpowiednikiem entropii krzyżowej, gdy prawdopodobieństwa przynależności do klasy są przekształcone logarytmicznie, co oznacza zastosowanie funkcji aktywacji `log_softmax`. Algorytm obliczania entropii krzyżowej w kontekście binarnym, zwany stratą logarytmiczną, został opisany wcześniej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga  \n",
    "Sieć neuronowa stosowana do klasyfikacji ma liczbę wyjść odpowiadającą liczbie klas w danych, dlatego nie ma potrzeby obliczania skorygowanych prawdopodobieństw. Każde wyjście sieci zwraca prawdopodobieństwo przynależności obiektu do konkretnej klasy. W takim przypadku entropia krzyżowa jest obliczana jako ujemna średnia logarytmiczna prawdopodobieństw, które zostały zwrócone przez odpowiednie wyjścia, odpowiadające rzeczywistym klasom analizowanych obiektów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym ważnym krokiem jest wybór algorytmu optymalizacji wag modelu (ang. optimizer), który dostosowuje ich wartości w celu osiągnięcia ustalonego kryterium, np. minimalizacji wartości NLLLoss. Jednym z najczęściej stosowanych algorytmów optymalizacji jest algorytm stochastycznego spadku gradientu, który został opisany wcześniej. Wielkość kroków w trakcie modyfikacji wag jest określana przez współczynnik uczenia (ang. learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Sprawdza, czy dostępna jest karta graficzna (GPU), jeśli nie, używa CPU\n",
    "criterion = nn.NLLLoss()  # Definiuje funkcję strat (strata logarytmiczna z prawdopodobieństw)\n",
    "model = Net()  # Inicjalizuje model sieci neuronowej\n",
    "model.to(device)  # Przenosi model na odpowiednie urządzenie (GPU lub CPU)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-4, momentum=0.9)  # Definiuje optymalizator SGD z określoną szybkością uczenia i momentem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W następnym etapie trzeba zainicjować zmienne, które będą przechowywać bieżące stany modelu oraz optymalizatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model_state = model.state_dict()\n",
    "init_opt_state = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kolejnym etapie należy stworzyć dwa obiekty:\n",
    "\n",
    "1) **trainer** – służy do trenowania sieci. Wymaga podania modelu (sieci neuronowej), kryterium oceny (criterion) oraz urządzenia (device), na którym będą wykonywane obliczenia. Używając obiektu trainer, wagi modelu będą aktualizowane w celu osiągnięcia ekstremum zdefiniowanego kryterium (w tym przypadku dążąc do minimum, ponieważ zastosowane kryterium to NLLLoss).\n",
    "\n",
    "2) **evaluator** – służy do ewaluacji modelu, czyli przeprowadza walidację oraz oblicza metryki na zbiorze testowym. Podaje się model i wybrane metryki. W jego przypadku wagi modelu nie będą aktualizowane.\n",
    "\n",
    "Dodatkowo, aby mieć kontrolę nad przebiegiem treningu i śledzić postęp, wykorzystany zostanie pasek postępu, który będzie wyświetlał wyniki uzyskane na zbiorze treningowym w trakcie kolejnych epok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import Loss, Accuracy\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
    "\n",
    "# Tworzymy obiekt trenera\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "\n",
    "# Tworzymy obiekt ewaluatora\n",
    "evaluator = create_supervised_evaluator(model, \n",
    "                                         metrics={\"acc\": Accuracy(), \n",
    "                                                  \"loss\": Loss(nn.NLLLoss())}, \n",
    "                                         device=device)\n",
    "\n",
    "# Dodajemy pasek postępu do trenera\n",
    "ProgressBar(persist=True).attach(trainer, \n",
    "                                  output_transform=lambda x: {\"batch loss\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed rozpoczęciem procesu treningowego sieci należy również określić liczbę epok. Po każdej z nich możliwe jest obliczenie metryk dla zbioru walidacyjnego, który nie służy bezpośrednio do uczenia, co pozwala ocenić, czy model skutecznie się uczy i czy nie zachodzi ryzyko przeuczenia. Aby przeprowadzić walidację w pakiecie Ignite, należy uruchomić obiekt evaluator, przekazując mu dane walidacyjne. Evaluator powinien zostać podłączony do obiektu trainer za pomocą odpowiedniej funkcji. Poniżej przedstawiono sposób na wyświetlenie wyników walidacji po każdej epoce. Po zakończeniu treningu evaluator będzie wykorzystywany do obliczenia metryk na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "# Walidacja ma być przeprowadzona po zakończeniu każdej epoki\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {} Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(\n",
    "        trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
    "\n",
    "# Trening modelu przez 150 epok\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "# Ewaluacja modelu na zbiorze testowym\n",
    "evaluator.run(test_loader)\n",
    "print(evaluator.state.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład: Automatyczne ustalanie współczynnika uczenia  \n",
    "W powyższym przykłądzie wartość współczynnika uczenia została ręcznie przypisana do funkcji `optim.SGD` i wynosi 3e-4. Istnieje także możliwość automatycznego dostosowania tego współczynnika – w tym celu używa się funkcji `FastaiLRFinder`. Wartość współczynnika jest określana na podstawie parametru `diverge_th`, który kontroluje moment, w którym proces poszukiwania optymalnej wartości zostaje przerwany. Poszukiwania są zatrzymywane, gdy spełnione zostanie kryterium: `current loss > diverge_th * best_loss`.\n",
    "\n",
    "UWAGA  \n",
    "Parametr `diverge_th` może przyjąć dowolną wartość nie mniejszą niż 1, a jego domyślna wartość to 5. Wartość mniejsza niż 5 skutkuje szybszym zakończeniem poszukiwań najlepszego współczynnika uczenia, ale może być ryzykowna, ponieważ w przypadku napotkania lokalnego minimum na początku procesu, poszukiwania zostaną zakończone zbyt wcześnie. W praktyce pozwolenie na większe wartości `current_loss` na początku procesu, a tym samym kontynuowanie poszukiwań, może umożliwić znalezienie globalnego minimum lub przynajmniej lokalnego minimum o niższej wartości, co w konsekwencji prowadzi do lepszego doboru parametru i bardziej efektywnego treningu sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.handlers import FastaiLRFinder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inicjalizacja obiektu FastaiLRFinder\n",
    "lr_finder = FastaiLRFinder()\n",
    "\n",
    "# Przygotowanie słownika z modelem i optymalizatorem\n",
    "to_save = {'model': model, 'optimizer': optimizer}\n",
    "\n",
    "# Dołączenie lr_finder do trenera i ustawienie wartości diverge_th na 1.1\n",
    "with lr_finder.attach(trainer, to_save, diverge_th=1.1) as trainer_with_lr_finder:\n",
    "    # Domyślnie start_lr jest taki, jak określono w obiekcie optimizer, \n",
    "    # a end_lr = 10\n",
    "    trainer_with_lr_finder.run(train_loader)\n",
    "\n",
    "# Pobranie wyników po zakończeniu poszukiwań najlepszego LR\n",
    "results = lr_finder.get_results()\n",
    "\n",
    "# Wykres przedstawiający wyniki\n",
    "lr_finder.plot()\n",
    "\n",
    "# Wyświetlenie sugerowanego współczynnika uczenia\n",
    "print(\"Suggested LR:\", lr_finder.lr_suggestion())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po określeniu optymalnej wartości współczynnika uczenia, należy przekazać tę wartość do obiektu optymalizatora. Służy do tego funkcja `apply_suggested_lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.handlers import FastaiLRFinder\n",
    "\n",
    "# Utworzenie obiektów trainer i evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model,\n",
    "    metrics={\"acc\": Accuracy(), \"loss\": Loss(nn.NLLLoss())},\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Dodanie paska postępu do trenera\n",
    "ProgressBar(persist=True).attach(\n",
    "    trainer, output_transform=lambda x: {\"batch loss\": x}\n",
    ")\n",
    "\n",
    "# Funkcja walidacji po zakończeniu epoki\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)  # Przeprowadzenie walidacji\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Validation Results - Epoch: {trainer.state.epoch} \"\n",
    "          f\"Avg accuracy: {metrics['acc']:.2f} \"\n",
    "          f\"Avg loss: {metrics['loss']:.2f}\")\n",
    "    \n",
    "    # Zastosowanie sugerowanego współczynnika uczenia\n",
    "    lr_finder.apply_suggested_lr(optimizer)\n",
    "    print(f'Training with suggested lr: {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "# Rozpoczęcie treningu\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "\n",
    "# Ewaluacja na zbiorze testowym\n",
    "evaluator.run(test_loader)\n",
    "print(evaluator.state.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład: Zastosowanie warstwy dropout\n",
    "\n",
    "Sieci neuronowe, zwłaszcza te głębokie, czyli składające się z wielu warstw ukrytych, mają tendencję do przeuczania się, gdy liczba danych treningowych jest zbyt mała. Ponieważ nie zawsze jest możliwe zwiększenie zbioru uczącego, konieczne staje się zastosowanie innych metod, które pomagają zminimalizować przeuczenie. Jedną z popularnych technik jest dropout, który polega na losowym \"wyłączaniu\" neuronów podczas każdej iteracji (czyli ustawianiu ich wag na 0) oraz na skalowaniu wag pozostałych neuronów przez współczynnik 1/(1 - p), gdzie p oznacza prawdopodobieństwo wyłączenia danego neuronu. Dzięki temu sieć nie jest w stanie idealnie dopasować się do danych uczących, ponieważ musi nauczyć się dostosowywać wagi w taki sposób, by uzyskiwać dobre wyniki, nawet gdy część neuronów jest nieaktywna.\n",
    "\n",
    "Podczas definiowania warstwy dropout, należy ustalić, z jakim prawdopodobieństwem neurony będą wyłączane. Domyślnie wynosi ono 0,5, ale można je dostosować, pamiętając, że zmiana tego parametru wymaga staranności. Jeśli wartość p będzie zbyt wysoka, sieć może mieć trudności w nauce rozpoznawania zależności w danych, co wpłynie na skuteczność klasyfikacji. Z kolei zbyt niskie p sprawi, że regularyzacja będzie nieskuteczna i nie zmniejszy przeuczenia. Warstwy dropout powinny być inicjalizowane w metodzie init klasy modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2574, 256)  # Pierwsza warstwa gęsta\n",
    "        self.fc2 = nn.Linear(256, 120)   # Druga warstwa gęsta\n",
    "        self.fc3 = nn.Linear(120, 35)    # Trzecia warstwa gęsta\n",
    "        self.dropout1 = nn.Dropout(p = 0.5)  # Pierwsza warstwa dropout (50% prawdopodobieństwo wyłączenia neuronów)\n",
    "        self.dropout2 = nn.Dropout(p = 0.2)  # Druga warstwa dropout (20% prawdopodobieństwo wyłączenia neuronów)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Przechodzimy przez pierwszą warstwę\n",
    "        x = self.dropout1(x)  # Zastosowanie dropout po pierwszej warstwie\n",
    "        x = self.fc2(x)  # Przechodzimy przez drugą warstwę\n",
    "        x = self.dropout2(x)  # Zastosowanie dropout po drugiej warstwie\n",
    "        x = self.fc3(x)  # Przechodzimy przez trzecią warstwę\n",
    "        return F.log_softmax(x, dim = 1)  # Zastosowanie logarytmu softmax na wyjściu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: Modyfikacja architektury jednokierunkowej sieci neuronowej do rozpoznawania mowy\n",
    "\n",
    "W przykładzie zatytułowanym \"Rozpoznawanie mowy przy użyciu jednokierunkowej sieci neuronowej\" zaprezentowano bardzo prostą architekturę sieci. Niestety, jej zastosowanie nie prowadzi do zadowalających wyników – dokładność klasyfikacji na zbiorze walidacyjnym wynosi jedynie 0,33, a na zbiorze testowym 0,34. Celem jest modyfikacja tej sieci, aby osiągnąć wyższą dokładność klasyfikacji na obu zbiorach. Można to osiągnąć przez wprowadzenie następujących zmian:\n",
    "\n",
    "- Dodanie dodatkowych warstw (należy zadbać o odpowiednią liczbę wejść i wyjść),\n",
    "- Wprowadzenie warstw dropout, które pomogą w regularizacji sieci,\n",
    "- Zmiana funkcji aktywacji w warstwach (np. zastosowanie funkcji ReLU: `x = F.relu(self.fc1(x))`),\n",
    "- Zmiana algorytmu optymalizacji wag na inny, bardziej efektywny.\n",
    "\n",
    "Po wprowadzeniu modyfikacji warto sprawdzić, czy dotychczasowa liczba epok jest wystarczająca do nauczenia sieci. Jeśli w trakcie treningu dokładność na zbiorze walidacyjnym nadal rośnie, oznacza to, że sieć nie jest jeszcze w pełni wytrenowana i warto zwiększyć liczbę epok. Jeśli natomiast zauważysz spadek dokładności, oznacza to, że sieć mogła się przeuczyć i liczba epok powinna zostać zmniejszona.\n",
    "\n",
    "**UWAGA**  \n",
    "Przeuczenie sieci występuje, gdy zauważalny jest wyraźny spadek dokładności klasyfikacji na zbiorze walidacyjnym. Jednakże, pojedyncze spadki dokładności, po których następuje stabilizacja lub wzrost tej wartości, są normalnym zjawiskiem w trakcie treningu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
