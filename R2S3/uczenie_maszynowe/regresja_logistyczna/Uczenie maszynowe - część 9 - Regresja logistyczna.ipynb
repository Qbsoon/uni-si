{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosowanie: klasyfikacja binarna.\n",
    "\n",
    "Metoda: uczenie nadzorowane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja logistyczna, mimo swojej nazwy, nie jest metodą rozwiązywania problemów regresji, lecz klasyfikacji binarnej. W tym podejściu zmienna zależna \\(y\\) (atrybut decyzyjny) może przyjmować jedynie dwie wartości: \\(y \\in Y = \\{0, 1\\}\\), gdzie \\(Y\\) oznacza przestrzeń wyników. W związku z tym zmienna losowa \\(y\\), przy zadanych wektorze cech \\(x\\) i parametrach \\(\\theta\\), ma rozkład Bernoulliego \\(B(\\phi)\\), gdzie \\(\\phi = P(y = 1)\\).\n",
    "\n",
    "Zależności te można wyrazić następująco:\n",
    "\n",
    "$$\n",
    "p(y = 1 \\mid \\phi) = \\phi\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(y = 0 \\mid \\phi) = 1 - \\phi\n",
    "$$\n",
    "\n",
    "Podobnie jak regresja liniowa, regresja logistyczna może być postrzegana jako szczególny przypadek uogólnionych modeli liniowych. Aby lepiej to zrozumieć, warto odnieść się do założeń tych modeli i przeanalizować je w kontekście regresji logistycznej, zgodnie z podejściem McCullagha i Neldera (1989)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oto przejrzysta parafraza z poprawnym formatowaniem wzorów:\n",
    "\n",
    "---\n",
    "\n",
    "### Założenie nr 1: Rozkład zmiennej \\(y\\)\n",
    "\n",
    "Wiadomo, że zmienna \\(y\\) ma rozkład Bernoulliego. Aby wykazać, że rozkład Bernoulliego należy do rodziny rozkładów wykładniczych, można zastosować podstawowe własności logarytmów. \n",
    "\n",
    "Rozkład Bernoulliego można wyrazić jako:\n",
    "\n",
    "$$\n",
    "p(y; \\phi) = \\phi^y (1 - \\phi)^{(1-y)}\n",
    "$$\n",
    "\n",
    "Po zastosowaniu logarytmu:\n",
    "\n",
    "$$\n",
    "= \\exp \\left( \\log \\left( \\phi^y (1 - \\phi)^{(1-y)} \\right) \\right)\n",
    "$$\n",
    "\n",
    "Rozdzielając składniki logarytmiczne:\n",
    "\n",
    "$$\n",
    "= \\exp \\left( y \\cdot \\log(\\phi) + (1-y) \\cdot \\log(1-\\phi) \\right)\n",
    "$$\n",
    "\n",
    "Zapisując to w postaci rozdzielnej:\n",
    "\n",
    "$$\n",
    "= \\exp \\left( y \\cdot \\log(\\phi) + \\log(1-\\phi) - y \\cdot \\log(1-\\phi) \\right)\n",
    "$$\n",
    "\n",
    "Łącząc składniki:\n",
    "\n",
    "$$\n",
    "= \\exp \\left( y \\cdot \\log(\\phi) - y \\cdot \\log(1-\\phi) + \\log(1-\\phi) \\right)\n",
    "$$\n",
    "\n",
    "Ostateczna forma:\n",
    "\n",
    "$$\n",
    "= \\exp \\left( y \\cdot \\log \\left( \\frac{\\phi}{1-\\phi} \\right) + \\log(1-\\phi) \\right)\n",
    "$$\n",
    "\n",
    "Zatem:\n",
    "\n",
    "$$\n",
    "z(y) = 1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "T(y) = y,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\eta(\\phi) = \\log \\left( \\frac{\\phi}{1 - \\phi} \\right),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\kappa(\\phi) = -\\log(1 - \\phi).\n",
    "$$\n",
    "\n",
    "Rozkład Bernoulliego jest więc szczególnym przypadkiem rozkładu wykładniczego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Założenie nr 2: Wartość oczekiwana \\(T(y)\\) przy znanym \\(x\\)\n",
    "\n",
    "W rozważanym modelu należy estymować wartość oczekiwaną \\(T(y)\\) przy znanym \\(x\\). Z założenia nr 1 wiadomo, że \\(T(y) = y\\), co oznacza:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\mathbb{E}(y \\mid x; \\theta) = \\phi.\n",
    "$$\n",
    "\n",
    "Dodatkowo, z założenia nr 1 wiadomo, że:\n",
    "\n",
    "$$\n",
    "\\eta(\\phi) = \\log\\left(\\frac{\\phi}{1 - \\phi}\\right),\n",
    "$$\n",
    "\n",
    "co można przekształcić, aby wyrazić \\(\\phi\\) jako:\n",
    "\n",
    "$$\n",
    "\\phi = \\frac{1}{1 + e^{-\\eta}}.\n",
    "$$\n",
    "\n",
    "Podstawiając tę zależność do powyższego wzoru, uzyskujemy:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\mathbb{E}(y \\mid x; \\theta) = \\frac{1}{1 + e^{-\\eta}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Założenie nr 3: Postać parametru naturalnego i wyprowadzenie funkcji \\( h_\\theta(x) \\)\n",
    "\n",
    "Trzecie założenie uogólnionych modeli liniowych określa, że parametr naturalny rozkładu \\(\\eta\\) jest liniową kombinacją cech \\(x\\), czyli:\n",
    "\n",
    "$$\n",
    "\\eta = \\theta^T x.\n",
    "$$\n",
    "\n",
    "Stąd funkcja \\( h_\\theta(x) \\) dla regresji logistycznej przyjmuje postać:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}.\n",
    "$$\n",
    "\n",
    "Dzięki założeniom uogólnionych modeli liniowych otrzymaliśmy postać funkcji \\( h_\\theta(x) \\). W przypadku regresji liniowej ta funkcja jest znana z góry, a jej wyprowadzenie z uogólnionych modeli liniowych jest formalnością. Jednak w innych przypadkach, gdy postać \\( h_\\theta(x) \\) nie jest oczywista, znajomość tych założeń okazuje się niezwykle przydatna, pod warunkiem że rozkład zmiennej \\( y \\) należy do rodziny wykładniczej.\n",
    "\n",
    "### Funkcja prawdopodobieństwa i klasyfikacja\n",
    "\n",
    "Aby dokończyć zadanie, czyli znaleźć model klasyfikacji, należy wyznaczyć parametry \\(\\theta\\), które najlepiej spełniają równanie. Wiemy, że \\( (y \\mid x; \\theta) \\sim B(\\phi) \\) i że \\( h_\\theta(x) = \\phi \\), co pozwala zapisać prawdopodobieństwa dla dwóch klas:\n",
    "\n",
    "$$\n",
    "P(y = 1 \\mid x; \\theta) = h_\\theta(x),\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(y = 0 \\mid x; \\theta) = 1 - h_\\theta(x).\n",
    "$$\n",
    "\n",
    "Zatem ogólna funkcja prawdopodobieństwa ma postać:\n",
    "\n",
    "$$\n",
    "P(y \\mid x; \\theta) = \\left(h_\\theta(x)\\right)^y \\cdot \\left(1 - h_\\theta(x)\\right)^{1 - y}.\n",
    "$$\n",
    "\n",
    "Dla zbioru treningowego składającego się z \\( N \\) niezależnych próbek \\((x^{(j)}, y^{(j)})\\), funkcja wiarygodności wynosi:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{j=1}^N P(y^{(j)} \\mid x^{(j)}; \\theta) = \\prod_{j=1}^N \\left(h_\\theta(x^{(j)})\\right)^{y^{(j)}} \\cdot \\left(1 - h_\\theta(x^{(j)})\\right)^{1 - y^{(j)}}.\n",
    "$$\n",
    "\n",
    "Ponieważ \\( h_\\theta(x) \\) ma postać:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}},\n",
    "$$\n",
    "\n",
    "logarytm funkcji wiarygodności, czyli tzw. funkcja log-wiarygodności, jest wyrażona jako:\n",
    "\n",
    "$$\n",
    "l(\\theta) = \\ln L(\\theta) = \\sum_{j=1}^N \\left( y^{(j)} \\ln \\left(h_\\theta(x^{(j)})\\right) + \\left(1 - y^{(j)}\\right) \\ln \\left(1 - h_\\theta(x^{(j)})\\right) \\right).\n",
    "$$\n",
    "\n",
    "### Wyznaczanie parametrów \\(\\theta\\)\n",
    "\n",
    "Aby znaleźć optymalne parametry \\(\\theta\\), należy rozwiązać równanie, w którym gradient funkcji log-wiarygodności zeruje się:\n",
    "\n",
    "$$\n",
    "\\nabla l(\\theta) = 0.\n",
    "$$\n",
    "\n",
    "Jednak w praktyce parametry \\(\\theta\\) są zwykle wyznaczane numerycznie za pomocą iteracyjnych metod, takich jak metoda najmniejszych kwadratów z regularyzacją wag (Mardia i in., 1979)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ocena jakości regresji logistycznej\n",
    "\n",
    "W poprzednich materiałach omówiono standardowe metody oceny różnych modeli, szczególnie klasyfikatorów. Regresja logistyczna jednak należy do specyficznej grupy klasyfikatorów, w których model nie zwraca konkretnej klasy, ale prawdopodobieństwo przynależności obiektu do klasy pozytywnej (\\(y = 1\\)). To sprawia, że konieczne jest stosowanie szczególnych miar oceny jakości modelu, opartych na prognozowanych prawdopodobieństwach.\n",
    "\n",
    "Jedną z takich miar jest **strata logarytmiczna** (ang. *log loss*), nazywana także binarną entropią krzyżową. Jest ona obliczana jako ujemna średnia logarytmów skorygowanych prawdopodobieństw, co można wyprowadzić z równania funkcji log-wiarygodności regresji logistycznej. Strata logarytmiczna jest zdefiniowana jako:\n",
    "\n",
    "$$\n",
    "\\text{log loss} = -\\frac{1}{N} \\sum_{j=1}^N \\left[ y^{(j)} \\ln(h_\\theta(x^{(j)})) + (1 - y^{(j)}) \\ln(1 - h_\\theta(x^{(j)})) \\right].\n",
    "$$\n",
    "\n",
    "Wartość ta jest ujemna, ponieważ logarytm prawdopodobieństwa, które leży w zakresie \\([0, 1]\\), przyjmuje wartości ujemne. Przemnożenie wyniku przez \\(-1\\) sprawia, że strata logarytmiczna jest dodatnia, co ułatwia interpretację: im mniejsza wartość, tym prognozy modelu są bliższe rzeczywistości.\n",
    "\n",
    "Oprócz straty logarytmicznej, do oceny modeli zwracających prawdopodobieństwa przynależności do klas stosuje się wskaźnik **ROC AUC** (pole pod krzywą ROC). Aby jednak zrozumieć znaczenie tej miary, najpierw należy wyjaśnić, czym jest krzywa ROC (ang. *Receiver Operating Characteristic*). \n",
    "\n",
    "Krzywa ROC przedstawia zdolność modelu do klasyfikowania obiektów w zależności od przyjętego progu decyzyjnego. Na osi pionowej pokazuje czułość (ang. *True Positive Rate*, TPR), a na osi poziomej współczynnik fałszywych pozytywów (ang. *False Positive Rate*, FPR), który jest równy \\(1 - \\text{specyficzność}\\). Idealny model charakteryzuje się krzywą, która dla \\(FPR = 0\\) osiąga \\(TPR = 1\\), a następnie biegnie równolegle do osi poziomej. Im większe odchylenie krzywej od tego idealnego przebiegu, tym gorsza jakość modelu.\n",
    "\n",
    "### Miara ROC AUC\n",
    "\n",
    "Wskaźnik ROC AUC (ang. *Area Under Curve*) to pole pod krzywą ROC. W idealnym przypadku \\(ROC\\_AUC = 1\\), co oznacza doskonały model. Jeśli wartość \\(ROC\\_AUC = 0.5\\), model prawdopodobnie przewiduje klasy w sposób losowy (np. z równym prawdopodobieństwem 50% dla klasy „0” i „1”). Taki model nie nadaje się do praktycznego zastosowania. W danych rzeczywistych osiągnięcie wartości \\(ROC\\_AUC = 1\\) jest rzadkie, ale dążymy do maksymalizacji tego wskaźnika.\n",
    "\n",
    "Przykład krzywej ROC dla określonego zbioru testowego znajduje się w przykładzie poniżej.\n",
    "\n",
    "**UWAGA**  \n",
    "Każdy model losowy osiąga \\(ROC\\_AUC = 0.5\\). Jednak możliwe jest, że model z \\(ROC\\_AUC = 0.5\\) nie generuje predykcji w pełni losowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: Przewidywanie prawdopodobieństwa przeżycia katastrofy na podstawie danych o pasażerach Titanica\n",
    "\n",
    "Dane dotyczące pasażerów Titanica, dostępne pod adresem: [Kaggle - Titanic Dataset](https://www.kaggle.com/datasets/azeembootwala/titanic), posłużą jako przykład działania regresji logistycznej. Zestaw danych został wstępnie przetworzony, co oznacza, że jest gotowy do treningu i ewaluacji modelu. W ramach przetwarzania dane zostały znormalizowane, brakujące wartości uzupełniono lub usunięto, a zmienne kategoryczne zakodowano w formie binarnej (0 i 1).\n",
    "\n",
    "Na początek dane należy wczytać do dwóch osobnych struktur **DataFrame** – jednej dla zbioru treningowego, a drugiej dla zbioru testowego. Po wczytaniu danych zauważymy, że zestaw zawiera 15 kolumn:\n",
    "\n",
    "1. **Unnamed: 0** – kolumna z automatycznie nadaną nazwą, zawierająca numery porządkowe wierszy,\n",
    "2. **PassengerId** – unikalny identyfikator pasażera,\n",
    "3. **Survived** – informacja, czy pasażer przeżył katastrofę (1 – przeżył, 0 – nie przeżył),\n",
    "4. **Sex** – płeć pasażera (0 – kobieta, 1 – mężczyzna),\n",
    "5. **Age** – znormalizowany wiek pasażera (wartości w przedziale od 0 do 1),\n",
    "6. **Fare** – wysokość zapłaconej opłaty za bilet,\n",
    "7. **Pclass_1** – czy pasażer podróżował w pierwszej klasie (1 – tak, 0 – nie),\n",
    "8. **Pclass_2** – czy pasażer podróżował w drugiej klasie (1 – tak, 0 – nie),\n",
    "9. **Pclass_3** – czy pasażer podróżował w trzeciej klasie (1 – tak, 0 – nie),\n",
    "10. **Family_size** – liczba członków rodziny na pokładzie, znormalizowana do przedziału (0, 1),\n",
    "11–15. **Title_1, Title_2, Title_3, Title_4** – zmienne binarne wskazujące status pasażera (np. żonaty, kawaler, panna, mężatka),\n",
    "16. **Emb_1, Emb_2, Emb_3** – zmienne binarne wskazujące port zaokrętowania pasażera (Cherbourg, Queenstown, Southampton).\n",
    "\n",
    "Analiza zmiennych takich jak **Unnamed: 0** (numer porządkowy) oraz **PassengerId** (identyfikator pasażera) nie wnosi wartości informacyjnej, ponieważ nie opisują one żadnych cech pasażera. Dlatego te kolumny zostaną usunięte z danych przed przystąpieniem do uczenia modelu. \n",
    "\n",
    "Ten proces pozwala skupić się na istotnych zmiennych, które mogą wpłynąć na przewidywanie prawdopodobieństwa przeżycia pasażerów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    make_scorer\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (\n",
    "    cross_validate, \n",
    "    StratifiedKFold\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# Wczytanie danych\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Usunięcie zbędnych kolumn\n",
    "train_df.drop(columns=['Unnamed: 0', 'PassengerId'], inplace=True)\n",
    "test_df.drop(columns=['Unnamed: 0', 'PassengerId'], inplace=True)\n",
    "\n",
    "# Przygotowanie danych wejściowych i wyjściowych\n",
    "columns = train_df.columns\n",
    "X_train = train_df[columns[1:]].to_numpy()\n",
    "X_test = test_df[columns[1:]].to_numpy()\n",
    "y_train = train_df['Survived'].to_numpy()\n",
    "y_test = test_df['Survived'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początek model regresji logistycznej zostanie utworzony z domyślnymi ustawieniami hiperparametrów. Po zakończeniu treningu zostanie poddany ocenie – dzięki metodzie `predict` można określić przynależność obiektów do poszczególnych klas, co pozwala na wyznaczenie macierzy pomyłek oraz obliczenie kluczowych metryk oceniających skuteczność modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Inicjalizacja modelu regresji logistycznej\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Trening modelu\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na danych testowych\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "\n",
    "# Wyświetlenie raportu klasyfikacji\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby otrzymać prawdopodobieństwo przynależności obiektów do poszczególnych klas, zamiast samej klasy przewidywanej, należy skorzystać z metody `predict_proba`. Prawdopodobieństwa przypisania obiektów do klasy 1 znajdują się w pierwszej kolumnie uzyskanej macierzy predykcji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UWAGA  \n",
    "Regresja logistyczna w bibliotece scikit-learn jest klasyfikatorem, a nie modelem regresyjnym. Dlatego użycie metody `predict_proba` zwraca dla każdego obiektu wektor dwóch wartości: prawdopodobieństwa przynależności do klasy 0 oraz do klasy 1. Podobne zachowanie można zaobserwować w przypadku innych modeli klasyfikacyjnych korzystających z `predict_proba`. Natomiast w modelach regresyjnych wynik predykcji jest pojedynczą wartością, ponieważ regresory zwracają jedno wyjście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "# Predykcja prawdopodobieństw na danych testowych\n",
    "preds = lr.predict_proba(X_test)\n",
    "\n",
    "# Obliczenie i wyświetlenie wskaźnika ROC AUC\n",
    "print(\"ROC AUC Score:\")\n",
    "print(roc_auc_score(y_test, preds[:, 1]))\n",
    "\n",
    "# Obliczenie i wyświetlenie straty logarytmicznej\n",
    "print(\"\\nLog Loss:\")\n",
    "print(log_loss(y_test, preds[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartość pola pod krzywą ROC (ROC_AUC) uzyskana na zbiorze testowym wynosi około 0,89, a strata logarytmiczna osiąga wartość 0,3728477052627943. Są to całkiem dobre wyniki – ROC_AUC znacząco przewyższa wartość 0,5, co wskazuje na dobrą zdolność modelu do rozróżniania klas. Jednak stosunkowo wysoka wartość straty logarytmicznej sugeruje, że zdolności generalizacyjne modelu są umiarkowane. Warto jednak podkreślić, że w tym przypadku hiperparametry modelu nie były optymalizowane, więc wynik można uznać za zadowalający.\n",
    "\n",
    "Dla porównania wartość straty logarytmicznej zostanie obliczona ręcznie zgodnie ze wzorem. W tym celu należy zastosować następujący schemat obliczania prawdopodobieństw skorygowanych:\n",
    "1. Jeśli obiekt należy do klasy 1, skorygowane prawdopodobieństwo równe jest wartości przewidywanej przez model (\\(y_{\\text{pred}}\\)).\n",
    "2. Jeśli obiekt należy do klasy 0, skorygowane prawdopodobieństwo wynosi \\(1 - y_{\\text{pred}}\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczanie skorygowanego prawdopodobieństwa\n",
    "corrected_prob = [\n",
    "    1 - y_pred if y_true == 0 else y_pred\n",
    "    for y_pred, y_true in zip(preds[:, 1], y_test)\n",
    "]\n",
    "\n",
    "# Konwersja do tablicy numpy\n",
    "corrected_prob = np.array(corrected_prob)\n",
    "\n",
    "# Obliczanie logarytmów skorygowanych prawdopodobieństw\n",
    "log_prob = np.log(corrected_prob + 1e-15)\n",
    "\n",
    "# Obliczanie straty logarytmicznej\n",
    "logloss = -np.mean(log_prob)\n",
    "\n",
    "# Wyświetlenie wyniku\n",
    "print(\"Log Loss:\", logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczona wartość straty logarytmicznej wynosi 0,3728477052627926, co jest praktycznie równe wynikowi uzyskanemu wcześniej. Niewielkie różnice między tymi wartościami a wynikiem uzyskanym przy użyciu funkcji `log_loss` z biblioteki scikit-learn wynikają z ograniczeń numerycznych. W praktyce takie różnice są pomijalne, dlatego wyniki metryk podaje się zazwyczaj z mniejszą dokładnością, najczęściej do dwóch lub czterech miejsc po przecinku.\n",
    "\n",
    "Krzywą ROC, na podstawie której wyznaczono wskaźnik ROC_AUC, można narysować przy użyciu poniższej funkcji. Model generujący losowe predykcje zostanie oznaczony niebieską linią przerywaną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y, preds, image_path=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    # Obliczenie FPR, TPR i progów\n",
    "    fpr, tpr, thresholds = roc_curve(y, preds)\n",
    "\n",
    "    # Rysowanie wykresu ROC\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Model teoretyczny\\nzwracający predykcje losowe')\n",
    "    plt.plot(fpr, tpr, marker='.', label='Uzyskany model')\n",
    "    plt.xlabel('Odsetek predykcji prawdziwie dodatnich (TPR)')\n",
    "    plt.ylabel('Odsetek predykcji fałszywie dodatnich (FPR)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Zapis wykresu, jeśli podano ścieżkę\n",
    "    if image_path:\n",
    "        plt.savefig(image_path)\n",
    "\n",
    "    # Wyświetlenie wykresu\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przebieg uzyskanej krzywej ROC potwierdza, że model osiąga wyniki znacznie lepsze niż model generujący losowe predykcje, co wynika również z wartości wskaźnika ROC_AUC. Ponieważ predykcje uzyskane za pomocą metody `predict_proba` są zmiennymi ciągłymi, nie można bezpośrednio obliczyć standardowych metryk sukcesu. Aby to zrobić, konieczne jest przekształcenie ciągłych wartości na liczby całkowite reprezentujące przynależność do klas.\n",
    "\n",
    "Do tego celu należy przyjąć próg, który określi, że wartości poniżej niego przyporządkowują obiekty do klasy 0, a wartości powyżej do klasy 1. Istnieją różne sposoby ustalania takiego progu. Poniżej przedstawiono kod funkcji, która implementuje metodę opartą na maksymalizacji średniej geometrycznej TPR i TNR (\\(1 - \\text{FPR}\\)) dla całego zbioru danych (Liu, 2012). Metoda ta zapewnia najwęższe przedziały ufności dla dokładności klasyfikacji i cechuje się największą stabilnością w porównaniu z innymi powszechnie stosowanymi podejściami (Unal, 2017).\n",
    "\n",
    "Po ustaleniu progu należy dokonać binarnego podziału wyników predykcji ciągłych. Poniżej znajduje się kod realizujący to zadanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie prawdopodobieństw predykcji na zbiorze treningowym i testowym\n",
    "preds_train = lr.predict_proba(X_train)\n",
    "preds_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Wyznaczenie optymalnego progu\n",
    "threshold = get_threshold(y_train, y_test, preds_train[:, 1], preds_test[:, 1])\n",
    "\n",
    "# Binarna klasyfikacja na podstawie optymalnego progu\n",
    "bool_preds = preds[:, 1] > threshold\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, bool_preds))\n",
    "\n",
    "# Wyświetlenie raportu klasyfikacji\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, bool_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównując macierze pomyłek uzyskane za pomocą metod `predict` oraz `predict_proba` z progowaniem, można zauważyć, że metoda `predict` nieznacznie przeważa – liczba poprawnie zaklasyfikowanych obiektów z klasy 0 jest większa o jeden. Wynik ten jest związany z doborem wartości progu. Zmieniając próg, możemy uzyskać różne wyniki metryk, takich jak czułość czy swoistość, nawet dla tego samego modelu. Wyższy próg skutkuje większą liczbą obiektów przypisanych do klasy 0, natomiast niższy próg prowadzi do większej liczby obiektów przypisanych do klasy 1.\n",
    "\n",
    "Regresję logistyczną można zoptymalizować, dostosowując wartości hiperparametrów w celu maksymalizacji wybranej metryki. Poniżej przedstawiono kod optymalizujący model pod kątem maksymalizacji wskaźnika ROC AUC. Alternatywnie można skupić się na innych metrykach, takich jak dokładność klasyfikacji czy F1-score. \n",
    "\n",
    "Hiperparametry poddane optymalizacji obejmują:\n",
    "- **C** – parametr regulujący siłę regularyzacji, który kontroluje wartości wag modelu. Pozwala zmniejszyć ryzyko przeuczenia oraz nadmiernego dopasowania do danych.\n",
    "- **solver** – algorytm stosowany do optymalizacji wag.\n",
    "- **max_iter** – maksymalna liczba iteracji, jakie algorytm wykona w celu osiągnięcia kryterium zatrzymania (pod warunkiem, że algorytm jest zbieżny). Jeśli algorytm nie zbiegnie się lub nie znajdzie optymalnych wag w określonej liczbie iteracji, proces optymalizacji zostaje przerwany, a wybierany jest najlepszy uzyskany wynik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UWAGA  \n",
    "Optymalizacja hiperparametrów modelu może być również ukierunkowana na minimalizację funkcji celu. W takim przypadku miarą używaną do oceny modelu jest wskaźnik błędu. Dla modeli klasyfikacyjnych najczęściej stosuje się stratę logarytmiczną, natomiast dla modeli regresyjnych standardowymi miarami są błąd średniokwadratowy (MSE) lub średni błąd bezwzględny (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definicja miary oceny\n",
    "scoring = {'roc_macro': make_scorer(roc_auc_score)}\n",
    "\n",
    "# Funkcja celu dla optymalizacji hiperparametrów\n",
    "def objective(trial, model, get_space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(\n",
    "        mdl, X, y, \n",
    "        scoring=scoring,\n",
    "        cv=StratifiedKFold(n_splits=5),\n",
    "        return_train_score=True\n",
    "    )\n",
    "    return np.mean(scores['test_roc_macro'])\n",
    "\n",
    "# Przestrzeń hiperparametrów\n",
    "def get_space(trial):\n",
    "    space = {\n",
    "        \"C\": trial.suggest_uniform(\"C\", 0, 2),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"lbfgs\", \"liblinear\"])\n",
    "    }\n",
    "    return space\n",
    "\n",
    "# Liczba prób optymalizacji\n",
    "trials = 15\n",
    "model = LogisticRegression\n",
    "\n",
    "# Inicjalizacja optymalizacji\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optymalizacja\n",
    "study.optimize(\n",
    "    lambda x: objective(x, model, get_space, X_train, y_train), \n",
    "    n_trials=trials\n",
    ")\n",
    "\n",
    "# Wyświetlenie najlepszych hiperparametrów\n",
    "print('Best Parameters:', study.best_params)\n",
    "\n",
    "# Trening modelu z optymalnymi hiperparametrami\n",
    "lr = model(**study.best_params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym\n",
    "preds = lr.predict(X_test)\n",
    "print('Test ROC_AUC:', roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zaprezentowanym przykładzie optymalizacja hiperparametrów modelu regresji logistycznej nie przyniosła poprawy wyników. Metryki, takie jak dokładność klasyfikacji, czułość, precyzja i F1, obliczone za pomocą funkcji `classification_report`, pozostają na tym samym poziomie, co dla modelu z domyślnymi ustawieniami hiperparametrów. Prawdopodobnym powodem tego jest ograniczona liczba iteracji przeprowadzonych podczas optymalizacji – wykonano jedynie 15 prób, co mogło uniemożliwić osiągnięcie globalnego maksimum funkcji celu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie: Przewidywanie prawdopodobieństwa zachorowania na cukrzycę typu 2\n",
    "\n",
    "#### 1. Pobranie i wczytanie danych\n",
    "Pobierz dane ze strony [Kaggle - Diabetes Data Set](https://www.kaggle.com/mathchi/diabetes-data-set) i załaduj je do struktury **DataFrame**. Uzyskana tabela zawiera dziewięć kolumn:\n",
    "\n",
    "- **Pregnancies** – liczba przebytych ciąż,\n",
    "- **Glucose** – stężenie glukozy dwie godziny po wykonaniu testu obciążenia glukozą,\n",
    "- **BloodPressure** – rozkurczowe ciśnienie krwi (w mmHg),\n",
    "- **SkinThickness** – grubość fałdu skórnego na ramieniu (w mm),\n",
    "- **Insulin** – stężenie insuliny dwie godziny po teście obciążenia glukozą,\n",
    "- **BMI** – wskaźnik masy ciała,\n",
    "- **DiabetesPedigreeFunction** – wskaźnik ryzyka zachorowania na cukrzycę na podstawie wywiadu rodzinnego,\n",
    "- **Age** – wiek,\n",
    "- **Outcome** – przynależność do klasy:\n",
    "  - 0 – brak diagnozy cukrzycy,\n",
    "  - 1 – diagnoza cukrzycy.\n",
    "\n",
    "#### 2. Podział danych\n",
    "Podziel dane na zbiór uczący i testowy, aby przeprowadzić trening i ewaluację modelu.\n",
    "\n",
    "#### 3. Trening modelu z domyślnymi hiperparametrami\n",
    "Przeprowadź trening klasyfikatora opartego na regresji logistycznej, stosując domyślne ustawienia hiperparametrów, a następnie dokonaj jego ewaluacji.\n",
    "\n",
    "#### 4. Optymalizacja modelu\n",
    "Zdefiniuj funkcję celu (`objective`) w taki sposób, aby maksymalizować wartość pola pod krzywą ROC (ROC_AUC) i przeprowadź optymalizację hiperparametrów.\n",
    "\n",
    "#### 5. Trening modelu z optymalnymi hiperparametrami\n",
    "Przeprowadź trening modelu przy użyciu najlepszych znalezionych parametrów. Wykonaj predykcje na zbiorze testowym, używając zarówno metody `predict`, jak i `predict_proba`. W przypadku użycia metody `predict_proba` wyznacz punkt odcięcia na krzywej ROC w celu dychotomizacji predykcji.\n",
    "\n",
    "#### 6. Analiza wyników\n",
    "Wyznacz wartości kluczowych metryk sukcesu, takich jak dokładność, czułość, precyzja czy F1-score, i przeanalizuj wyniki. Zastanów się, czy optymalizacja hiperparametrów znacząco wpłynęła na skuteczność modelu. Sprawdź, czy wyniki uzyskane za pomocą metod `predict` i `predict_proba` różnią się.\n",
    "\n",
    "#### 7. Wybór istotniejszej metryki\n",
    "Rozważ, która metryka – czułość czy precyzja – jest ważniejsza w kontekście danych związanych z cukrzycą. Uzasadnij swoją odpowiedź, biorąc pod uwagę kontekst zadania i potencjalne konsekwencje błędów klasyfikacyjnych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
