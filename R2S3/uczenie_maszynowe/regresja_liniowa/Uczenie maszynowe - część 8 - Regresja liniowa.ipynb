{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja liniowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosowanie: regresja.\n",
    "\n",
    "Metoda: uczenie nadzorowane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja liniowa\n",
    "\n",
    "Problemy rozwiązywane za pomocą modelu regresji liniowej mają na celu uchwycenie zależności pomiędzy zmiennymi, co umożliwia przewidywanie wartości zmiennej decyzyjnej dla obiektów spoza zbiorów treningowego i testowego. W kontekście regresji liniowej zmienne niezależne (atrybuty warunkowe) określają dane wejściowe, natomiast zmienna zależna (atrybut decyzyjny) jest wartością, którą model ma przewidzieć.\n",
    "\n",
    "Regresja liniowa najlepiej opisuje przypadki, w których zmienne są liniowo zależne. Hipoteza w trenowanym modelu może być wyrażona równaniem:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\ldots + \\theta_d x_d,\n",
    "$$\n",
    "\n",
    "gdzie \\(\\theta_i\\) to parametry modelu, które są optymalizowane w procesie uczenia. Wprowadzenie \\(x_0 = 1\\) pozwala zapisać hipotezę w bardziej zwartej formie:\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\sum_{i=0}^d \\theta_i x_i = \\theta^T x,\n",
    "$$\n",
    "\n",
    "co dla \\(j\\)-tego przykładu ze zbioru treningowego (\\(j = 1, \\ldots, N\\)) wygląda następująco:\n",
    "\n",
    "$$\n",
    "h_\\theta(x^{(j)}) = \\sum_{i=0}^d \\theta_i x_i^{(j)} = \\theta^T x^{(j)}.\n",
    "$$\n",
    "\n",
    "Możemy to zapisać wektorowo:\n",
    "\n",
    "$$\n",
    "h_\\theta(x^{(j)}) = \\theta^T x^{(j)},\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "- \\(\\theta = [\\theta_0, \\theta_1, \\ldots, \\theta_d]^T\\),\n",
    "- \\(x^{(j)} = [x_0^{(j)}, x_1^{(j)}, \\ldots, x_d^{(j)}]^T\\).\n",
    "\n",
    "Rozwiązanie problemu regresji polega na znalezieniu takiego wektora \\(\\theta\\), który najlepiej opisuje liniową zależność między zmienną zależną a zmiennymi niezależnymi. Ponieważ dane empiryczne zawierają błędy, można zapisać równanie uwzględniające błąd:\n",
    "\n",
    "$$\n",
    "y^{(j)} = \\theta^T x^{(j)} + \\epsilon^{(j)},\n",
    "$$\n",
    "\n",
    "gdzie \\(\\epsilon^{(j)}\\) jest błędem losowym, który można modelować jako zmienną losową o rozkładzie normalnym \\(N(0, \\sigma^2)\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja gęstości prawdopodobieństwa błędu \\(\\epsilon^{(j)}\\) jest zdefiniowana jako:\n",
    "\n",
    "$$\n",
    "p(\\epsilon^{(j)}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(\\epsilon^{(j)})^2}{2\\sigma^2}}.\n",
    "$$\n",
    "\n",
    "Dla zmiennej \\(y^{(j)}\\) z danym \\(x^{(j)}\\) oraz parametrami \\(\\theta\\), funkcja gęstości prawdopodobieństwa przyjmuje postać:\n",
    "\n",
    "$$\n",
    "p(y^{(j)} | x^{(j)}; \\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}}.\n",
    "$$\n",
    "\n",
    "W równaniu funkcji \\( p(y|X; \\theta) \\) określamy prawdopodobieństwo \\( y \\) dla ustalonych \\( X \\) i parametrów \\(\\theta\\). Macierz \\( X \\) (znana jako macierz cech) definiujemy jako zbiór wektorów cech dla wszystkich przykładów w zbiorze treningowym. Zapisujemy ją jako:\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "1 & x_1^{(1)} & x_2^{(1)} & \\cdots & x_d^{(1)} \\\\\n",
    "1 & x_1^{(2)} & x_2^{(2)} & \\cdots & x_d^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_1^{(N)} & x_2^{(N)} & \\cdots & x_d^{(N)}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "Zatem funkcja gęstości prawdopodobieństwa dla wektora \\(y\\) przy danych \\(X\\) i parametrach \\(\\theta\\) jest opisana jako funkcja wiarygodności \\(L(\\theta)\\):\n",
    "\n",
    "$$\n",
    "L(\\theta; X, y) = \\prod_{j=1}^N p(y^{(j)} | x^{(j)}; \\theta).\n",
    "$$\n",
    "\n",
    "Przy niezależności \\(\\epsilon^{(j)}\\), funkcja wiarygodności ma postać:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{j=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}}.\n",
    "$$\n",
    "\n",
    "Przyjmuje ona maksimum dla tych samych argumentów co funkcja logarytmiczna \\(l(\\theta) = \\ln(L(\\theta))\\). Logarytm funkcji wiarygodności przekształca się do postaci:\n",
    "\n",
    "$$\n",
    "l(\\theta) = \\ln(L(\\theta)) = \\ln\\left(\\prod_{j=1}^N \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\ln\\left(\\frac{N}{\\sqrt{2\\pi\\sigma}}\\prod_{j=1}^N e^{-\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\ln\\left(\\frac{N}{\\sqrt{2\\pi\\sigma}}\\right) + \\ln\\left(\\prod_{j=1}^N e^{-\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\ln\\left(\\frac{N}{\\sqrt{2\\pi\\sigma}}\\right) + \\sum_{j=1}^N \\ln\\left(e^{-\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\ln\\left(\\frac{N}{\\sqrt{2\\pi\\sigma}}\\right) + \\sum_{j=1}^N -\\frac{(y^{(j)} - \\theta^T x^{(j)})^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\ln\\left(\\frac{N}{\\sqrt{2\\pi\\sigma}}\\right) - \\frac{1}{\\sigma^2} \\cdot \\frac{1}{2} \\sum_{j=1}^N (y^{(j)} - \\theta^T x^{(j)})^2.\n",
    "$$\n",
    "\n",
    "Ponieważ:\n",
    "\n",
    "$$\n",
    "\\left(y^{(j)} - \\theta^T x^{(j)}\\right)^2 = \\left(-\\theta^T x^{(j)} + y^{(j)}\\right)^2 = \\left(-( \\theta^T x^{(j)} - y^{(j)} )\\right)^2 = \\left(\\theta^T x^{(j)} - y^{(j)}\\right)^2,\n",
    "$$\n",
    "\n",
    "możemy zapisać, że:\n",
    "\n",
    "$$\n",
    "l(\\theta) = \\ln\\left(\\frac{N}{\\sqrt{2\\pi\\sigma}}\\right) - \\frac{1}{\\sigma^2} \\cdot \\frac{1}{2} \\sum_{j=1}^N \\left(y^{(j)} - \\theta^T x^{(j)}\\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z przedstawionego równania wynika, że maksymalizacja funkcji logarytmu wiarygodności \\( l(\\theta) \\) sprowadza się do minimalizacji wyrażenia:\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\sum_{j=1}^N \\left(\\theta^T x^{(j)} - y^{(j)}\\right)^2.\n",
    "$$\n",
    "\n",
    "Problem znalezienia wartości \\(\\theta_i\\), które maksymalizują prawdopodobieństwo \\( p(y|X; \\theta) \\), można więc zredukować do minimalizacji funkcji kosztu \\( J(\\theta) \\), która jest zdefiniowana jako:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\sum_{j=1}^N \\left(h_\\theta(x^{(j)}) - y^{(j)}\\right)^2,\n",
    "$$\n",
    "\n",
    "gdzie \\( h_\\theta(x^{(j)}) \\) jest postacią hipotezy modelu.\n",
    "\n",
    "Aby znaleźć argument minimalizujący funkcję kosztu \\( J(\\theta) \\), można zastosować różne metody optymalizacji, takie jak:\n",
    "- **metoda analityczna**: polega na rozwiązaniu układu równań normalnych,\n",
    "- **metoda gradientu prostego**: iteracyjna technika bazująca na minimalizacji błędu poprzez aktualizację parametrów \\(\\theta\\) w kierunku przeciwnym do gradientu funkcji kosztu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda analityczna\n",
    "\n",
    "Niech:\n",
    "$$\n",
    "y = \\begin{bmatrix}\n",
    "y^{(1)} \\\\\n",
    "y^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "y^{(N)}\n",
    "\\end{bmatrix}, \\quad\n",
    "X = \\begin{bmatrix}\n",
    "1 & x_1^{(1)} & \\cdots & x_d^{(1)} \\\\\n",
    "1 & x_1^{(2)} & \\cdots & x_d^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_1^{(N)} & \\cdots & x_d^{(N)}\n",
    "\\end{bmatrix}, \\quad\n",
    "\\theta = \\begin{bmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_d\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Wtedy można zapisać wektorowo:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "h_\\theta(x^{(1)}) - y^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "h_\\theta(x^{(N)}) - y^{(N)}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\theta^T x^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "\\theta^T x^{(N)}\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "y^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "y^{(N)}\n",
    "\\end{bmatrix}\n",
    "= X\\theta - y.\n",
    "$$\n",
    "\n",
    "Zatem funkcja kosztu przyjmuje postać:\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\sum_{j=1}^N \\left(h_\\theta(x^{(j)}) - y^{(j)}\\right)^2 =\n",
    "\\frac{1}{2} (X\\theta - y)^T (X\\theta - y) =\n",
    "\\frac{1}{2} \\left(\\theta^T X^T X \\theta - \\theta^T X^T y - y^T X \\theta + y^T y\\right).\n",
    "$$\n",
    "\n",
    "W celu wyznaczenia argumentu minimum funkcji kosztu należy znaleźć miejsce zerowe gradientu tej funkcji. Gradient funkcji kosztu można zapisać następująco:\n",
    "\n",
    "#### Gradient:\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\nabla_\\theta \\frac{1}{2} \\left(\\theta^T X^T X \\theta - \\theta^T X^T y - y^T X \\theta + y^T y\\right)\n",
    "$$\n",
    "\n",
    "Korzystając z właściwości macierzy i śladu, otrzymujemy:\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\frac{1}{2} \\nabla_\\theta \\text{tr} \\left(\\theta^T X^T X \\theta - \\theta^T X^T y - y^T X \\theta + y^T y\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{2} \\nabla_\\theta \\left[\\text{tr}(\\theta^T X^T X \\theta) - \\text{tr}((y^T X) \\theta) - \\text{tr}((\\theta^T X^T) y) + \\text{tr}(y^T y)\\right].\n",
    "$$\n",
    "\n",
    "Pochodna daje:\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\frac{1}{2} \\left[2X^T X \\theta - 2X^T y\\right] = X^T X \\theta - X^T y.\n",
    "$$\n",
    "\n",
    "Gradient znika (\\(\\nabla_\\theta J(\\theta) = 0\\)) dla:\n",
    "$$\n",
    "X^T X \\theta = X^T y.\n",
    "$$\n",
    "\n",
    "Rozwiązanie:\n",
    "$$\n",
    "\\theta = (X^T X)^{-1} X^T y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zakładając, że macierz \\( X^T X \\) jest nieosobliwa, poszukiwany wektor parametrów \\(\\theta_i\\) (\\(i = 1, \\ldots, d\\)) można wyznaczyć przy użyciu następującego wzoru:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = 0 \\iff X^T X \\theta - X^T y = 0 \\iff X^T X \\theta = X^T y \\iff \\theta = (X^T X)^{-1} X^T y.\n",
    "$$\n",
    "\n",
    "To równanie jest stosunkowo proste i intuicyjne, co może sugerować, że nie ma potrzeby sięgania po alternatywne metody. Niemniej jednak w praktyce, gdy mamy do czynienia z bardzo dużymi zbiorami danych — na przykład z milionami przykładów i tysiącami cech — taka metoda staje się niepraktyczna. Powód leży w znacznym zapotrzebowaniu na zasoby obliczeniowe i pamięć, co sprawia, że bezpośrednie obliczenie odwrotności macierzy \\( (X^T X)^{-1} \\) jest niewydajne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularyzacja Tichonowa\n",
    "\n",
    "Stosowanie metody analitycznej w regresji liniowej może prowadzić do uzyskania wektora \\(\\theta\\) z dużymi wartościami bezwzględnymi. W praktyce oznacza to, że model regresyjny ma wysokie wagi, co powoduje, że prognozowane wyjście \\(y\\) staje się bardzo wrażliwe na nawet niewielkie zmiany w danych wejściowych \\(x_i\\). Taka sytuacja jest niekorzystna, ponieważ zwiększa ryzyko przeuczenia modelu oraz może prowadzić do dużego błędu generalizacji.\n",
    "\n",
    "Dodatkowym problemem jest możliwość występowania liniowej zależności między zmiennymi objaśniającymi. Ryzyko to rośnie, gdy liczba zmiennych objaśniających przewyższa liczbę obserwacji. W takich przypadkach macierz \\(X^T X\\) może być nieodwracalna, co uniemożliwia zastosowanie metody analitycznej do znalezienia jednoznacznego rozwiązania.\n",
    "\n",
    "Jednym z najpopularniejszych sposobów rozwiązania tych problemów jest **regularyzacja Tichonowa**, znana również jako regularyzacja \\(L2\\). Polega ona na modyfikacji funkcji kosztu poprzez dodanie składnika regularyzacyjnego z parametrem \\(\\alpha \\geq 0\\), który wprowadza karę za zbyt wysokie wartości wag modelu (Goodfellow i in., 2018). Funkcja kosztu po regularyzacji przyjmuje postać:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\left[(X\\theta - y)^T (X\\theta - y) + \\alpha \\theta^T \\theta\\right].\n",
    "$$\n",
    "\n",
    "W wyniku tego modyfikacja prowadzi do następującego rozwiązania dla wektora \\(\\theta\\):\n",
    "\n",
    "$$\n",
    "\\theta = (X^T X + \\alpha I)^{-1} X^T y,\n",
    "$$\n",
    "\n",
    "gdzie \\(I\\) to macierz jednostkowa o wymiarach \\(d \\times d\\).\n",
    "\n",
    "### Wpływ parametru \\(\\alpha\\):\n",
    "- Dla \\(\\alpha = 0\\), model sprowadza się do standardowej regresji liniowej.\n",
    "- Dla \\(\\alpha \\to \\infty\\), wszystkie wagi dążą do zera, co zapobiega przeuczeniu.\n",
    "\n",
    "Wartość parametru regularyzacji \\(\\alpha\\) jest zazwyczaj dobierana na podstawie optymalizacji z użyciem walidacji krzyżowej.\n",
    "\n",
    "### Uwagi:\n",
    "- Parametr \\(\\alpha\\) bywa również oznaczany jako \\(\\lambda\\).\n",
    "- Regresja liniowa z regularyzacją Tichonowa jest nazywana **regresją grzbietową** (ang. *ridge regression*).\n",
    "- Istnieje także bayesowska wersja regresji grzbietowej, w której zamiast konkretnych wartości współczynników \\(\\theta_i\\) estymuje się ich rozkłady prawdopodobieństwa. Ten wariant nazywa się **bayesowską regresją grzbietową** (ang. *Bayesian ridge regression*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda gradientu prostego\n",
    "\n",
    "Metoda gradientu prostego jest jedną z technik pozwalających na znalezienie wektora \\(\\theta\\) poprzez minimalizację funkcji kosztu za pomocą jej gradientu. Aby zrozumieć zasadę działania tego algorytmu, należy przypomnieć, że gradient funkcji wielowymiarowej jest wektorem wskazującym kierunek, w którym funkcja zmienia się najszybciej, a jego zwrot określa, w którą stronę funkcja rośnie.\n",
    "\n",
    "Zgodnie z wcześniejszymi wyprowadzeniami gradient funkcji kosztu można zapisać jako:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\sum_{i=1}^N \\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "Na podstawie wcześniejszych obliczeń przeprowadzonych w metodzie analitycznej, gradient funkcji kosztu można wyrazić za pomocą następującego wzoru:\n",
    "\n",
    "$$\n",
    "\\nabla J(\\theta) = X^T X \\theta - X^T y.\n",
    "$$\n",
    "\n",
    "Metoda gradientu prostego polega na iteracyjnym zmniejszaniu wartości funkcji kosztu aż do osiągnięcia punktu minimum, przy czym krok wykonywany w każdej iteracji ma długość proporcjonalną do \\(\\alpha\\) i zmienia kierunek w zależności od gradientu w danym punkcie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kroki algorytmu (metoda gradientu prostego)\n",
    "\n",
    "1. **Ustalenie kryterium zatrzymania**, na przykład:\n",
    "   - Maksymalna liczba iteracji \\(t_{\\text{max}}\\),\n",
    "   - Gradient bliski zera: \\(|\\nabla J(\\theta^{(t)})| < \\epsilon\\), gdzie \\(\\epsilon\\) to ustalona wartość, np. \\(\\epsilon = 10^{-3}\\),\n",
    "   - Brak poprawy w funkcji celu: \\(d(\\theta^{(t+1)}, \\theta^{(t)}) < \\epsilon\\), gdzie \\(\\epsilon\\) to ustalona wartość.\n",
    "\n",
    "2. **Określenie wielkości kroku \\(\\alpha\\)**.\n",
    "\n",
    "3. **Wybranie początkowych wartości parametrów \\(\\theta^{(0)}\\)** jako punktu startowego.\n",
    "\n",
    "4. **Inicjalizacja licznika iteracji**: \\(i := 0\\).\n",
    "\n",
    "5. **Obliczenie wartości funkcji kosztu** \\(J_i = J(\\theta^{(i)})\\) oraz gradientu \\(g_i = \\nabla J(\\theta^{(i)})\\) w punkcie startowym.\n",
    "\n",
    "6. **Wyznaczenie kierunku poszukiwań**: \\(d = -g_i\\).\n",
    "\n",
    "7. **Wykonanie kroku w kierunku \\(d\\)**: \n",
    "   $$\\theta^{(i+1)} := \\theta^{(i)} + \\alpha d.$$\n",
    "\n",
    "8. **Obliczenie w nowym punkcie** wartości funkcji kosztu \\(J_{i+1} = J(\\theta^{(i+1)})\\) oraz gradientu \\(g_{i+1} = \\nabla J(\\theta^{(i+1)})\\).\n",
    "\n",
    "9. **Sprawdzenie warunku poprawy funkcji kosztu**:\n",
    "   - Jeśli \\(J_{i+1} < J_i\\), zwiększyć \\(i := i + 1\\) i powrócić do kroków 6–8,\n",
    "   - Jeśli nie, sprawdzić kryterium zatrzymania; jeśli nie jest spełnione, zmniejszyć krok \\(\\alpha\\) i wrócić do kroku 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szczegóły dotyczące wyboru parametrów w algorytmie gradientu prostego\n",
    "\n",
    "#### (*)\n",
    "Wartość parametru \\(\\alpha\\) (współczynnik uczenia) jest hiperparametrem, którego wybór ma kluczowe znaczenie dla efektywności algorytmu. Wpływa na tempo zbieżności i stabilność procesu optymalizacji:\n",
    "\n",
    "- Jeśli \\(\\alpha\\) jest **zbyt małe**, algorytm będzie działał bardzo wolno, ponieważ krok w kierunku minimum będzie za mały, co znacząco wydłuży czas zbieżności.\n",
    "- Jeśli \\(\\alpha\\) jest **zbyt duże**, istnieje ryzyko pominięcia minimum. Algorytm może zacząć oscylować lub funkcja kosztu zacznie rosnąć zamiast maleć.\n",
    "\n",
    "Z tego powodu wartość \\(\\alpha\\) powinna być dobrana z odpowiednią starannością, często z wykorzystaniem eksperymentalnej optymalizacji lub walidacji krzyżowej.\n",
    "\n",
    "#### (**)\n",
    "Gradient funkcji wskazuje kierunek największego wzrostu jej wartości. W problemach optymalizacyjnych, gdzie celem jest znalezienie minimum funkcji, interesuje nas przeciwny kierunek – tam, gdzie funkcja maleje. Dlatego w algorytmie gradientu prostego stosuje się **przeciwny zwrot do gradientu** (czyli \\(-\\nabla J(\\theta)\\)), co pozwala na sukcesywne zmniejszanie wartości funkcji kosztu. \n",
    "\n",
    "Wartość kroku w tym przeciwnym kierunku jest następnie regulowana przez hiperparametr \\(\\alpha\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UWAGA\n",
    "\n",
    "Algorytm gradientowy, powszechnie stosowany w zadaniach optymalizacyjnych w celu znalezienia ekstremum funkcji, charakteryzuje się wrażliwością na minima lokalne. Oznacza to, że w danej przestrzeni parametrów algorytm będzie dążył do najbliższego lokalnego minimum, w zależności od punktu początkowego.\n",
    "\n",
    "W przypadku regresji liniowej taka cecha algorytmu nie jest jednak problematyczna, ponieważ funkcja kosztu dla regresji liniowej ma charakter wypukły i zawiera wyłącznie jedno minimum globalne, co gwarantuje zbieżność do optymalnego rozwiązania niezależnie od punktu startowego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: Regresja liniowa – metoda najmniejszych kwadratów\n",
    "\n",
    "Pod adresem: [Kaggle – Insurance Dataset](https://www.kaggle.com/datasets/mirichoi0218/insurance) znajduje się zestaw danych dotyczący kosztów procedur medycznych pokrywanych przez firmę ubezpieczeniową. Dane te obejmują siedem zmiennych:\n",
    "\n",
    "1. **age** – wiek osoby poddanej procedurze medycznej,\n",
    "2. **sex** – płeć (mężczyzna/kobieta),\n",
    "3. **bmi** – wskaźnik masy ciała,\n",
    "4. **children** – liczba dzieci,\n",
    "5. **smoker** – status palacza („yes” lub „no”),\n",
    "6. **region** – region geograficzny Stanów Zjednoczonych („northwest”, „northeast”, „southwest”, „southeast”),\n",
    "7. **charges** – koszty pokrywane przez ubezpieczyciela.\n",
    "\n",
    "Regresja liniowa może być użyta do przewidywania wysokości kosztów, które ubezpieczyciel poniesie na podstawie dostępnych parametrów. Wyniki tego modelu mogą posłużyć do wyznaczania optymalnych składek ubezpieczeniowych dla różnych klientów.\n",
    "\n",
    "---\n",
    "\n",
    "### Przygotowanie danych do analizy\n",
    "\n",
    "Przed zastosowaniem regresji liniowej konieczne jest przemyślenie kilku aspektów dotyczących danych:\n",
    "\n",
    "1. **Typ danych wejściowych**: \n",
    "   - Model regresji liniowej przyjmuje wyłącznie dane numeryczne.\n",
    "   - W analizowanych danych znajdują się zmienne kategorialne, takie jak:\n",
    "     - **sex** (płeć),\n",
    "     - **smoker** (status palenia),\n",
    "     - **region** (region geograficzny).\n",
    "\n",
    "   Te zmienne należy zakodować na wartości liczbowe. Można do tego użyć funkcji **OrdinalEncoder** z biblioteki `scikit-learn`, która automatycznie przekonwertuje wartości tekstowe na numeryczne.\n",
    "\n",
    "2. **Interpretowalność danych zakodowanych**:\n",
    "   - **Płeć**: Można ją przedstawić jako zmienną binarną (np. 0 dla kobiety, 1 dla mężczyzny), co jest intuicyjne i logiczne.\n",
    "   - **Status palacza**: Podobnie jak płeć, tę zmienną można zakodować binarnie (0 dla „nie pali”, 1 dla „pali”).\n",
    "   - **Region geograficzny**: Zakodowanie regionów jako wartości numerycznych (np. 0 dla „southeast”, 1 dla „northeast”, itd.) jest mniej intuicyjne, ponieważ wartości numeryczne sugerują pewien porządek lub hierarchię, której tutaj brakuje. Przypisanie takich wartości byłoby arbitralne, a różne sposoby kodowania mogłyby prowadzić do różnych wyników modelu.\n",
    "\n",
    "   **Rozwiązanie**: Zamiast kodować zmienną „region”, można ją pominąć podczas budowy i ewaluacji modelu, aby uniknąć problemów interpretacyjnych.\n",
    "\n",
    "Przed rozpoczęciem modelowania należy upewnić się, że dane są w odpowiedniej formie numerycznej, a ich reprezentacja jest logiczna i zgodna z założeniami regresji liniowej. W przypadku zmiennych binarnych, takich jak płeć i status palacza, użycie kodowania 0/1 jest odpowiednie. Natomiast w przypadku bardziej złożonych zmiennych kategorialnych, takich jak region, warto rozważyć ich pominięcie, aby uniknąć problemów związanych z arbitralnością przypisywanych wartości liczbowych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    explained_variance_score,\n",
    "    max_error\n",
    ")\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Wczytanie danych\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Usunięcie kolumny 'region'\n",
    "df.drop(columns=['region'], inplace=True)\n",
    "\n",
    "# Przygotowanie danych wejściowych i wyjściowych\n",
    "X_col_names = df.columns[:-1]\n",
    "X = df[X_col_names].to_numpy()\n",
    "y = df['charges'].to_numpy()\n",
    "\n",
    "# Inicjalizacja kodera OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "# Kodowanie zmiennych nienumerycznych na wartości liczbowe\n",
    "X[:, 1] = enc.fit_transform(X[:, 1].reshape(-1, 1)).squeeze()  # Kodowanie płci\n",
    "X[:, 4] = enc.fit_transform(X[:, 4].reshape(-1, 1)).squeeze()  # Kodowanie statusu palacza\n",
    "\n",
    "# Opis:\n",
    "# reshape(-1, 1) - Dodanie wymiaru jednostkowego, ponieważ OrdinalEncoder wymaga danych dwuwymiarowych,\n",
    "# więc z wektora należy utworzyć macierz o wymiarach długość_wektora × 1\n",
    "# squeeze() - Usunięcie zbędnych wymiarów po kodowaniu\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    random_state=42,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# Uwaga:\n",
    "# Podczas pracy z danymi do modelu regresyjnego nie należy przeprowadzać stratyfikacji\n",
    "# (tj. nie należy używać parametru `stratify=y`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby dopasować model regresji liniowej do danych, można skorzystać z klasy **LinearRegression** dostępnej w bibliotece `scikit-learn`. Domyślnie model uwzględnia wyraz wolny, który nie jest równy zeru. Jeśli chcemy dopasować model bez wyrazu wolnego, wystarczy podczas inicjalizacji przekazać argument `fit_intercept=False`.\n",
    "\n",
    "Modele regresji liniowej są zazwyczaj oceniane za pomocą dwóch popularnych metryk:\n",
    "1. **MAE** (*Mean Absolute Error*) – średni błąd bezwzględny, który wskazuje, o jaką wartość model myli się średnio. (patrz: równanie (5.3)).\n",
    "2. **MSE** (*Mean Squared Error*) – błąd średniokwadratowy, mierzący średnią kwadratową różnic między wartościami rzeczywistymi a przewidywaniami (patrz: równanie).\n",
    "\n",
    "Dodatkowo, aby oszacować największy błąd popełniany przez model, można skorzystać z funkcji **max_error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, max_error\n",
    "\n",
    "# Inicjalizacja modelu regresji liniowej\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Dopasowanie modelu do danych treningowych\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Przewidywanie wartości na zbiorze testowym\n",
    "preds = reg.predict(X_test)\n",
    "\n",
    "# Obliczenie i wyświetlenie metryk błędu\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, preds))\n",
    "print(\"Max Error:\", max_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza błędów modelu\n",
    "\n",
    "Model regresji liniowej generuje stosunkowo duże błędy:\n",
    "- **Średni błąd bezwzględny (MAE)** wynosi około **4213**, co oznacza, że model średnio myli się o tę wartość na przykładach testowych.\n",
    "- **Maksymalny błąd** wynosi około **22 820**, co wskazuje na przypadki, w których przewidywania modelu znacząco odbiegają od rzeczywistości.\n",
    "\n",
    "Aby lepiej zrozumieć charakterystykę błędów popełnianych przez model, można zwizualizować rozkład wartości rzeczywistych i przewidywanych, korzystając z histogramów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tworzenie wykresu\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Ustawienia osi\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "# Histogramy dla kwot rzeczywistych i przewidywanych\n",
    "ax.hist(y_test, bins=30, alpha=0.5, label='Kwota rzeczywista')  # Dodano bins i alpha dla lepszej wizualizacji\n",
    "ax.hist(preds, bins=30, alpha=0.5, label='Kwota przewidywana')\n",
    "\n",
    "# Legenda\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "# Wyświetlanie wykresu\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby zwizualizować rozkład różnic pomiędzy kwotami rzeczywistymi a przewidywanymi, możemy obliczyć różnice \\( \\text{residuals} = y_{\\text{test}} - \\text{preds} \\) i przedstawić je na histogramie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))  # Tworzenie wykresu z ustalonym rozmiarem\n",
    "plt.xticks(fontsize=14)  # Ustawienie wielkości czcionki dla osi X\n",
    "ax.hist(y_test - preds)  # Rysowanie histogramu różnic\n",
    "plt.show()  # Wyświetlenie wykresu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza histogramów wskazuje, że najczęściej popełniane przez model błędy dotyczą stosunkowo niewielkich kwot. W większości przypadków model przewyższa rzeczywiste koszty procedur medycznych, co oznacza, że jego przewidywania są zawyżone. Z kolei największe różnice między wartościami rzeczywistymi a przewidywanymi pojawiają się w sytuacjach, gdy model zaniża koszty, co może sugerować trudności w przewidywaniu wyższych wartości w danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: Metoda stochastycznego zejścia gradientowego (SGD)\n",
    "\n",
    "Metoda gradientu prostego bywa kosztowna zarówno pod względem obliczeń, jak i czasu, szczególnie przy pracy z dużymi zbiorami danych. W praktyce często zastępuje się ją bardziej efektywną metodą stochastycznego zejścia gradientowego (ang. Stochastic Gradient Descent, SGD).\n",
    "\n",
    "Główna różnica między SGD a klasycznym gradientem prostym polega na sposobie obliczania gradientu. Zamiast uwzględniania całego zbioru danych uczących, w SGD gradient jest oszacowywany i aktualizowany na podstawie pojedynczego, losowo wybranego przykładu z danych (Ketkar, 2017).\n",
    "\n",
    "W bibliotece scikit-learn implementacja metody SGD, wykorzystywana do szacowania współczynników regresji liniowej, znajduje się w klasie **SGDRegressor**, dostępnej pod adresem: [SGDRegressor w dokumentacji scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uwaga: Implementacja SGD dla klasyfikacji\n",
    "\n",
    "Oprócz zastosowania stochastycznego zejścia gradientowego w regresji, istnieje także jego implementacja przeznaczona do klasyfikacji. W takim przypadku należy skorzystać z klasy **SGDClassifier**, która również jest dostępna w bibliotece scikit-learn. \n",
    "\n",
    "Dokumentację tej klasy można znaleźć pod adresem: [SGDClassifier w dokumentacji scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html). \n",
    "\n",
    "Warto pamiętać o tym rozróżnieniu, aby właściwie dobrać narzędzie do konkretnego zadania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Tworzenie modelu regresji\n",
    "reg = SGDRegressor()\n",
    "\n",
    "# Dopasowanie modelu do danych treningowych\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na danych testowych\n",
    "preds = reg.predict(X_test)\n",
    "\n",
    "# Obliczenie średniego błędu bezwzględnego\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "# Wyświetlenie wyniku\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższy kod inicjalizuje model **SGDRegressor** z domyślnymi ustawieniami hiperparametrów, które obejmują między innymi:\n",
    "\n",
    "- **loss** – funkcję kosztu,\n",
    "- **penalty** – typ regularyzacji,\n",
    "- **alpha** – wartość parametru regularyzacji,\n",
    "- **max_iter** – maksymalną liczbę iteracji, czyli przejść przez cały zbiór danych treningowych w trakcie nauki,\n",
    "- **learning_rate** – parametr określający wielkość kroku podczas poszukiwania minimum lokalnego funkcji kosztu.\n",
    "\n",
    "Szczegółowy opis wszystkich dostępnych hiperparametrów znajduje się w dokumentacji klasy **SGDClassifier**.\n",
    "\n",
    "Aby poprawić działanie modelu, można przeprowadzić optymalizację hiperparametrów, np. z wykorzystaniem biblioteki **Optuna**. Poniżej znajduje się przykład kodu ilustrujący, jak optymalizować wybrane parametry modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Metryka, która posłuży do określenia funkcji celu\n",
    "scoring = {'mae': make_scorer(mean_absolute_error)}\n",
    "\n",
    "# Model, który będzie optymalizowany\n",
    "model = SGDRegressor\n",
    "\n",
    "# Definicja przestrzeni hiperparametrów\n",
    "# Hiperparametry, które zostaną poddane optymalizacji, oraz zakresy ich wartości\n",
    "def get_space(trial):\n",
    "    space = {\n",
    "        \"alpha\": trial.suggest_uniform(\"alpha\", 0, 1),\n",
    "        \"loss\": trial.suggest_categorical(\"loss\", [\n",
    "            'squared_loss', 'huber', \n",
    "            'epsilon_insensitive', \n",
    "            'squared_epsilon_insensitive'\n",
    "        ]),\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", ['l1', 'l2', 'elasticnet'])\n",
    "    }\n",
    "    return space\n",
    "\n",
    "# Liczba prób\n",
    "trials = 500\n",
    "\n",
    "# Definicja funkcji celu\n",
    "def objective(trial, model, get_space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "    mdl = model(**model_space)\n",
    "    # Walidacja będzie przeprowadzana z użyciem 5-krotnego sprawdzianu krzyżowego\n",
    "    scores = cross_validate(\n",
    "        mdl, X, y, \n",
    "        scoring=scoring,\n",
    "        cv=KFold(n_splits=5),\n",
    "        return_train_score=True\n",
    "    )\n",
    "    return np.mean(scores['test_mae'])\n",
    "\n",
    "# Inicjalizacja optymalizacji\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Przeprowadzenie optymalizacji\n",
    "study.optimize(\n",
    "    lambda x: objective(x, model, get_space, X_train, y_train), \n",
    "    n_trials=trials\n",
    ")\n",
    "\n",
    "# Wyświetlenie dobranych wartości hiperparametrów\n",
    "print('params:', study.best_params)\n",
    "\n",
    "# Trening modelu z optymalnymi hiperparametrami\n",
    "sgd = model(**study.best_params)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "preds = sgd.predict(X_test)\n",
    "\n",
    "# Wyświetlenie błędu absolutnego uzyskanego na zbiorze testowym\n",
    "print('test MAE:', mean_absolute_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: Regresja grzbietowa\n",
    "\n",
    "Regresję grzbietową można zrealizować za pomocą klasy **Ridge** dostępnej w bibliotece scikit-learn. Poniższy kod ilustruje sposób inicjalizacji i trenowania modelu z domyślnymi wartościami hiperparametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Inicjalizacja modelu regresji grzbietowej\n",
    "reg = Ridge()\n",
    "\n",
    "# Trenowanie modelu na danych treningowych\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Dokonanie predykcji na zbiorze testowym\n",
    "preds = reg.predict(X_test)\n",
    "\n",
    "# Obliczenie średniego błędu bezwzględnego\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "# Wyświetlenie wyniku\n",
    "print(\"Mean Absolute Error:\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W regresji grzbietowej najczęściej optymalizuje się trzy kluczowe hiperparametry:\n",
    "\n",
    "1. **alpha** – parametr regularyzacji, który kontroluje siłę penalizacji modelu,\n",
    "2. **solver** – metoda używana do obliczenia współczynników regresji,\n",
    "3. **max_iter** – maksymalna liczba iteracji, po której metoda sprzężonego gradientu powinna osiągnąć zbieżność. Jeśli zbieżność nie zostanie uzyskana, procedura zostanie przerwana, zwracając najlepszy wynik osiągnięty do tego momentu.\n",
    "\n",
    "Szczegółowy opis wszystkich dostępnych hiperparametrów można znaleźć w dokumentacji klasy **Ridge**, dostępnej pod adresem: [Ridge – dokumentacja scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Metryka, która posłuży do określenia funkcji celu\n",
    "scoring = {'mae': make_scorer(mean_absolute_error)}\n",
    "\n",
    "# Model, który będzie optymalizowany\n",
    "model = Ridge\n",
    "\n",
    "# Definicja przestrzeni hiperparametrów\n",
    "# Hiperparametry, które zostaną poddane optymalizacji, oraz zakresy ich wartości\n",
    "def get_space(trial):\n",
    "    space = {\n",
    "        \"alpha\": trial.suggest_uniform(\"alpha\", 0, 1),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\n",
    "            'svd', 'cholesky', 'sparse_cg'\n",
    "        ])\n",
    "    }\n",
    "    return space\n",
    "\n",
    "# Liczba prób\n",
    "trials = 500\n",
    "\n",
    "# Definicja funkcji celu\n",
    "def objective(trial, model, get_space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "    mdl = model(**model_space)\n",
    "    # Walidacja będzie przeprowadzana z użyciem 5-krotnego sprawdzianu krzyżowego\n",
    "    scores = cross_validate(\n",
    "        mdl, X, y, \n",
    "        scoring=scoring,\n",
    "        cv=KFold(n_splits=5),\n",
    "        return_train_score=True\n",
    "    )\n",
    "    return np.mean(scores['test_mae'])\n",
    "\n",
    "# Inicjalizacja optymalizacji\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Przeprowadzenie optymalizacji\n",
    "study.optimize(\n",
    "    lambda x: objective(x, model, get_space, X_train, y_train), \n",
    "    n_trials=trials\n",
    ")\n",
    "\n",
    "# Wyświetlenie dobranych wartości hiperparametrów\n",
    "print('params:', study.best_params)\n",
    "\n",
    "# Trening modelu z optymalnymi hiperparametrami\n",
    "ridge = model(**study.best_params)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "preds = ridge.predict(X_test)\n",
    "\n",
    "# Wyświetlenie błędu absolutnego uzyskanego na zbiorze testowym\n",
    "print('test MAE:', mean_absolute_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesowską regresję grzbietową można przeprowadzić za pomocą klasy **BayesianRidge**, która jest dostępna w bibliotece scikit-learn. Dokumentację tej klasy znaleźć można pod adresem: [BayesianRidge w dokumentacji scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie: Przewidywanie cen mieszkań za pomocą regresji liniowej\n",
    "\n",
    "#### 1. Pobranie i wczytanie danych:\n",
    "Pod adresem: [Kaggle - Real Estate Price Prediction](https://www.kaggle.com/quantbruce/real-estate-price-prediction) znajdują się dane dotyczące cen mieszkań w Singapurze. Pobierz plik, a następnie wczytaj go do struktury **DataFrame**. Wczytana tabela zawiera osiem kolumn:\n",
    "\n",
    "1. **No** – numer porządkowy,\n",
    "2. **X1 transaction date** – data zakupu,\n",
    "3. **X2 house age** – wiek budynku (w latach),\n",
    "4. **X3 distance to the nearest MRT station** – odległość od najbliższej stacji metra,\n",
    "5. **X4 number of convenience stores** – liczba sklepów w okolicy,\n",
    "6. **X5 latitude** – szerokość geograficzna,\n",
    "7. **X6 longitude** – długość geograficzna,\n",
    "8. **Y house price of unit area** – cena za jednostkę powierzchni.\n",
    "\n",
    "#### 2. Przygotowanie danych:\n",
    "- Usuń zbędne kolumny, które nie będą wykorzystywane w analizie.\n",
    "- Podziel dane na zbiór uczący i testowy w stosunku 80:20 (0,8:0,2).\n",
    "\n",
    "#### 3. Trening i ewaluacja modelu:\n",
    "- Przeprowadź trening modelu regresji liniowej przy użyciu klasy **LinearRegression**.\n",
    "- Oceń model, obliczając:\n",
    "  - Średnią wartość błędu przewidywań (np. za pomocą **Mean Absolute Error**).\n",
    "  - Największy błąd przewidywań (np. za pomocą metryki **Max Error**).\n",
    "\n",
    "#### 4. Optymalizacja modelu:\n",
    "Zastanów się, czy model liniowy inicjalizowany funkcją **LinearRegression** można zoptymalizować. Odpowiedź uzasadnij."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie: Wyznaczanie częstotliwości tonu podstawowego przy użyciu regresji grzbietowej\n",
    "\n",
    "#### 1. Przygotowanie danych:\n",
    "- Pobierz nagrania mowy z korpusu mowy zawierającego nagrania samogłosek o przedłużonej fonacji emitowanych z różną wysokością głosu. Dane dostępne są pod adresem: [https://osf.io/cwquj/](https://osf.io/cwquj/).\n",
    "- Wykonaj następujące kroki:\n",
    "  - **Wektor częstotliwości tonu podstawowego**: Wyznacz wektor z częstotliwościami tonu podstawowego na podstawie nagrań.\n",
    "  - **Macierz parametrów akustycznych**: Wygeneruj zestaw cech akustycznych opisujących sygnał mowy przy użyciu zestawu cech **ComParE_2016** z biblioteki **openSMILE**. Ustaw poziom ekstrakcji na **Functionals**, aby uzyskać statystyczne parametry cech sygnału.\n",
    "  - **Podział danych**: Podziel dane na zbiór uczący i testowy.\n",
    "  - **Standaryzacja**: Ustandaryzuj dane, aby każda cecha miała średnią równą 0 i wariancję równą 1.\n",
    "  - **Redukcja wymiarowości**: Zmniejsz liczbę cech opisujących jeden obiekt do 100, wykorzystując funkcję **SelectKBest**. Wybierz cechy, które mają największy wpływ na działanie modelu: [SelectKBest w dokumentacji scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html).\n",
    "\n",
    "#### 2. Trening i optymalizacja modelu:\n",
    "- Przeprowadź trening modelu regresji grzbietowej (**Ridge Regression**) na przygotowanych danych.\n",
    "- Optymalizuj hiperparametry modelu, aby przewidzieć wartość częstotliwości tonu podstawowego.\n",
    "- Wybierz metryki ewaluacji używane podczas optymalizacji:\n",
    "  - **Błąd średniokwadratowy (MSE)**.\n",
    "  - **Średni błąd bezwzględny (MAE)**.\n",
    "\n",
    "#### 3. Ewaluacja modelu:\n",
    "- Oceń uzyskane modele na zbiorze testowym.\n",
    "- Odpowiedz na pytanie: Czy metryka używana podczas optymalizacji (MSE vs. MAE) wpływa na wyniki uzyskane przez model?\n",
    "\n",
    "#### 4. Rozszerzenie optymalizacji:\n",
    "- Zmodyfikuj funkcję celu (**objective**) oraz przestrzeń hiperparametrów (**get_space**), aby objąć optymalizacją również liczbę cech wybieranych przez **SelectKBest**.\n",
    "- Wykorzystaj funkcję **make_pipeline**, aby uprościć proces optymalizacji: [make_pipeline w dokumentacji scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
