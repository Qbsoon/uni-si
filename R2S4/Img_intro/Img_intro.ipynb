{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageOps, ImageFilter, ImageEnhance, ImageSequence\n",
    "from IPython.display import display\n",
    "\n",
    "img_name = \"20250427_194007.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0def431",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.save(\"cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.thumbnail((256,2566))\n",
    "img.save(\"img_thumbnail.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.format, f\"{img.size}x{img.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ca3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = (450, 600, 750, 900)\n",
    "cat_in_box = img.crop(box)\n",
    "cat_in_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b47096",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = cat_in_box.transpose(Image.Transpose.ROTATE_180)\n",
    "img.paste(region, box)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d248934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(im_s: Image.Image, delta: int) -> Image.Image:\n",
    "    \"\"\"Roll an image sideways.\"\"\"\n",
    "    im = im_s.copy()\n",
    "    xsize, ysize = im.size\n",
    "\n",
    "\n",
    "    delta = delta % xsize\n",
    "    if delta == 0:\n",
    "        return im\n",
    "\n",
    "    part1 = im.crop((0, 0, delta, ysize))\n",
    "    part2 = im.crop((delta, 0, xsize, ysize))\n",
    "    im.paste(part1, (xsize - delta, 0, xsize, ysize))\n",
    "    im.paste(part2, (0, 0, xsize - delta, ysize))\n",
    "\n",
    "    return im\n",
    "\n",
    "roll(img, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(im1: Image.Image, im2: Image.Image) -> Image.Image:\n",
    "    w = im1.size[0] + im2.size[0]\n",
    "    h = max(im1.size[1], im2.size[1])\n",
    "    im = Image.new(\"RGBA\", (w, h))\n",
    "\n",
    "    im.paste(im1.copy())\n",
    "    im.paste(im2.copy(), (im1.size[0], 0))\n",
    "\n",
    "    return im\n",
    "\n",
    "merge(img, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bacb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = img.split()\n",
    "im = Image.merge(\"RGB\", (g, b, r))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77551213",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img.resize((128, 128))\n",
    "display(out)\n",
    "out = img.rotate(-90)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "display(out)\n",
    "out = img.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c729b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (256, 512)\n",
    "ImageOps.contain(im, size).save(\"imageops_contain.webp\")\n",
    "ImageOps.cover(im, size).save(\"imageops_cover.webp\")\n",
    "ImageOps.fit(im, size).save(\"imageops_fit.webp\")\n",
    "ImageOps.pad(im, size, color=\"#f00\").save(\"imageops_pad.webp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img.filter(ImageFilter.DETAIL)\n",
    "display(out)\n",
    "out = img.filter(ImageFilter.SMOOTH)\n",
    "display(out)\n",
    "out = img.filter(ImageFilter.BLUR)\n",
    "display(out)\n",
    "out = img.filter(ImageFilter.SHARPEN)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b549f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img.point(lambda i: i * 1.3)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afef9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the image into individual bands\n",
    "source = img.split()\n",
    "\n",
    "R, G, B = 0, 1, 2\n",
    "\n",
    "# select regions where red is less than 100\n",
    "mask = source[R].point(lambda i: i < 100 and 255)\n",
    "\n",
    "# process the green band\n",
    "out = source[G].point(lambda i: i * 0.7)\n",
    "\n",
    "# paste the processed band back, but only where red was < 100\n",
    "source[G].paste(out, None, mask)\n",
    "\n",
    "# build a new multiband image\n",
    "im = Image.merge(im.mode, source)\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "enh = ImageEnhance.Contrast(img)\n",
    "display(enh.enhance(1.5))\n",
    "enh = ImageEnhance.Sharpness(img)\n",
    "display(enh.enhance(2.0))\n",
    "enh = ImageEnhance.Color(img)\n",
    "display(enh.enhance(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81356b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.copy().rotate(180).save(\"cat_rotated.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img.copy(), img.copy().rotate(270), img.copy().rotate(180), img.copy().rotate(90)]\n",
    "images[0].save(\"cat.gif\", save_all=True, append_images=images[1:], duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(fn) for fn in [\"cat.jpg\", \"cat_rotated.jpg\"]]\n",
    "images[0].save(\"cat.gif\", save_all=True, append_images=images[1:], duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdcb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in ImageSequence.Iterator(Image.open(\"cat.gif\")):\n",
    "    display(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in ImageSequence.Iterator(Image.open(\"cat.gif\")):\n",
    "    display(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c09030",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_show(img, name=\"cat\"):\n",
    "    cv.namedWindow(name, cv.WINDOW_FULLSCREEN)\n",
    "    cv.imshow(name, img)\n",
    "    cv.moveWindow(name, 0, 0)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb6a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv_show(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv.resize(img,None,fx=0.5, fy=0.5, interpolation = cv.INTER_CUBIC)\n",
    "cv_show(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b07d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "cv_show(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "rows,cols = res.shape\n",
    "dst = cv.warpAffine(res,M,(cols,rows))\n",
    "cv_show(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65346128",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "rows,cols = res.shape\n",
    "M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "cv_show(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols,ch = img.shape\n",
    " \n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    " \n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    " \n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01233881",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols,ch = img.shape\n",
    " \n",
    "pts1 = np.float32([[345,438],[730,438],[345,700],[730,700]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    " \n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    " \n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bcd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((15,15),np.float32)/225\n",
    "dst = cv.filter2D(img,-1,kernel)\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "cv_show(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffa76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.blur(img,(10,10))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "cv_show(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img,(15,15),0)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "cv_show(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39216f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "ret,thresh1 = cv.threshold(img_th,127,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img_th,127,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img_th,127,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img_th,127,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img_th,127,255,cv.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img_th, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    " \n",
    "for image, title in zip(images, titles):\n",
    "    cv_show(image, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e808ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "img_th = cv.medianBlur(img_th,5)\n",
    " \n",
    "ret,th1 = cv.threshold(img_th,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img_th,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img_th,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    " \n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img_th, th1, th2, th3]\n",
    "\n",
    "for image, title in zip(images, titles):\n",
    "    cv_show(image, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_th = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "ret1,th1 = cv.threshold(img_th,127,255,cv.THRESH_BINARY)\n",
    " \n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv.threshold(img_th,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    " \n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv.GaussianBlur(img_th,(5,5),0)\n",
    "ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    " \n",
    "# plot all the images and their histograms\n",
    "images = [img_th, 0, th1,\n",
    "          img_th, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    " \n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "for i in [0,2,5,6,8]:\n",
    "    cv_show(images[i], titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name)\n",
    "kernel = cv.getStructuringElement(cv.MORPH_CROSS,(5,5))\n",
    "erosion = cv.erode(img,kernel,iterations = 1)\n",
    "dilation = cv.dilate(img,kernel,iterations = 1)\n",
    "closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)\n",
    "gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)\n",
    "tophat = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel)\n",
    "blackhat = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel)\n",
    "images = [img, erosion, dilation, closing, gradient, tophat, blackhat]\n",
    "titles = ['Original Image', 'Erosion', 'Dilation', 'Closing', 'Gradient', 'Tophat', 'Blackhat']\n",
    "for image, title in zip(images, titles):\n",
    "    cv_show(image, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name)\n",
    "laplacian = cv.Laplacian(img,cv.CV_64F)\n",
    "sobelx = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)\n",
    "sobely = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)\n",
    "cv_show(img, \"Original Image\")\n",
    "cv_show(laplacian, \"Laplacian\")\n",
    "cv_show(sobelx, \"Sobel X\")\n",
    "cv_show(sobely, \"Sobel Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name)\n",
    "edges = cv.Canny(img,100,200)\n",
    "cv_show(edges, \"Canny Edges\")\n",
    "edges_reversed = []\n",
    "for i in edges:\n",
    "    edges_reversed.append([255 - j for j in i])\n",
    "cv_show(np.array(edges_reversed, dtype=\"uint8\"), \"Canny Edges Reversed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76292d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name)\n",
    "img_low = cv.pyrDown(img)\n",
    "img_low2 = cv.pyrDown(img_low)\n",
    "img_high = cv.pyrUp(img_low)\n",
    "img_high2 = cv.pyrUp(img)\n",
    "images = [img, img_low, img_low2, img_high, img_high2]\n",
    "titles = ['Original', 'Lowered', 'Lowered again', 'Lowered made highered', 'Original made highered']\n",
    "for image, title in zip(images, titles):\n",
    "    cv_show(image, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70203fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cv.imread('apple.jpg')\n",
    "B = cv.imread('orange.jpg')\n",
    " \n",
    "# generate Gaussian pyramid for A\n",
    "G = A.copy()\n",
    "gpA = [G]\n",
    "for i in range(6):\n",
    "    G = cv.pyrDown(G)\n",
    "    gpA.append(G)\n",
    " \n",
    "# generate Gaussian pyramid for B\n",
    "G = B.copy()\n",
    "gpB = [G]\n",
    "for i in range(6):\n",
    "    G = cv.pyrDown(G)\n",
    "    gpB.append(G)\n",
    " \n",
    "# generate Laplacian Pyramid for A\n",
    "lpA = [gpA[5]]\n",
    "for i in range(5,0,-1):\n",
    "    GE = cv.pyrUp(gpA[i])\n",
    "    L = cv.subtract(gpA[i-1],GE)\n",
    "    lpA.append(L)\n",
    " \n",
    "# generate Laplacian Pyramid for B\n",
    "lpB = [gpB[5]]\n",
    "for i in range(5,0,-1):\n",
    "    GE = cv.pyrUp(gpB[i])\n",
    "    L = cv.subtract(gpB[i-1],GE)\n",
    "    lpB.append(L)\n",
    " \n",
    "# Now add left and right halves of images in each level\n",
    "LS = []\n",
    "for la,lb in zip(lpA,lpB):\n",
    "    rows,cols,dpt = la.shape\n",
    "    ls = np.hstack((la[:,0:cols//2], lb[:,cols//2:]))\n",
    "    LS.append(ls)\n",
    " \n",
    "# now reconstruct\n",
    "ls_ = LS[0]\n",
    "for i in range(1,6):\n",
    "    ls_ = cv.pyrUp(ls_)\n",
    "    ls_ = cv.add(ls_, LS[i])\n",
    " \n",
    "# image with direct connecting each half\n",
    "real = np.hstack((A[:,:cols//2],B[:,cols//2:]))\n",
    "\n",
    "images = [A, B, ls_, real]\n",
    "titles = ['Apple', 'Orange', 'Pyramid blended', 'Directly blended']\n",
    "for image, title in zip(images, titles):\n",
    "    cv_show(image, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lightning.png', cv.IMREAD_GRAYSCALE)\n",
    "ret, thresh = cv.threshold(img, 127, 255, 0)\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "cv_show(cv.drawContours(img, contours, -1, (0,255,0), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lightning.png', cv.IMREAD_GRAYSCALE)\n",
    "ret,thresh = cv.threshold(img,127,255,0)\n",
    "contours,hierarchy = cv.findContours(thresh, 1, 2)\n",
    " \n",
    "cnt = contours[0]\n",
    "M = cv.moments(cnt)\n",
    "print( M )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c70312",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = int(M['m10']/M['m00'])\n",
    "cy = int(M['m01']/M['m00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03584f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = cv.contourArea(cnt)\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e562bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter = cv.arcLength(cnt,True)\n",
    "perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4798ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = cv.boundingRect(cnt)\n",
    "x = cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "cv_show(x, \"Bounding Rect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ee9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = cv.minAreaRect(cnt)\n",
    "box = cv.boxPoints(rect)\n",
    "box = np.int0(box)\n",
    "cv_show(cv.drawContours(img,[box],0,(0,0,255),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),radius = cv.minEnclosingCircle(cnt)\n",
    "center = (int(x),int(y))\n",
    "radius = int(radius)\n",
    "cv_show(cv.circle(img,center,radius,(0,255,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96105405",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols = img.shape[:2]\n",
    "[vx,vy,x,y] = cv.fitLine(cnt, cv.DIST_L2,0,0.01,0.01)\n",
    "lefty = int((-x*vy/vx) + y)\n",
    "righty = int(((cols-x)*vy/vx)+y)\n",
    "cv_show(cv.line(img,(cols-1,righty),(0,lefty),(0,255,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "img2 = img.copy()\n",
    "template = cv.imread('template.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert template is not None, \"file could not be read, check with os.path.exists()\"\n",
    "w, h = template.shape[::-1]\n",
    " \n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['TM_CCOEFF', 'TM_CCOEFF_NORMED', 'TM_CCORR',\n",
    "            'TM_CCORR_NORMED', 'TM_SQDIFF', 'TM_SQDIFF_NORMED']\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(template,cmap = 'gray')\n",
    "plt.title('Template Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.suptitle('Original Image and Template')\n",
    "plt.show()\n",
    " \n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = getattr(cv, meth)\n",
    " \n",
    "    # Apply template Matching\n",
    "    res = cv.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    " \n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    " \n",
    "    cv.rectangle(img,top_left, bottom_right, 255, 2)\n",
    " \n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ecc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lightning.png')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "edges = cv.Canny(gray,50,150,apertureSize = 3)\n",
    "\n",
    "lines = cv.HoughLines(edges,1,np.pi/180,40)\n",
    "for line in lines:\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "cv_show(img, \"Hough Lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lightning.png')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "edges = cv.Canny(gray,50,150,apertureSize = 3)\n",
    "lines = cv.HoughLinesP(edges,1,np.pi/180,40,minLineLength=20,maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "cv_show(img, \"Hough Lines Probabilistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('circles.jpg', cv.IMREAD_GRAYSCALE)\n",
    "img = cv.medianBlur(img,5)\n",
    "cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "\n",
    "circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,\n",
    "                            param1=50,param2=30,minRadius=0,maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "cv_show(cimg, \"Hough Circles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('water_coins.jpg')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "cv_show(thresh, \"Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)\n",
    "cv_show(unknown, \"Unknown Region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "markers = cv.watershed(img,markers)\n",
    "img[markers == -1] = [0,0,255]\n",
    "\n",
    "cv_show(img, \"Watershed Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_name)\n",
    "plt.imshow(img),plt.colorbar(),plt.show()\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "rect = (250,220,974,1412)\n",
    "cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)\n",
    "\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "plt.imshow(img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newmask is the mask image I manually labelled\n",
    "newmask = cv.imread('newmask.png')\n",
    "plt.imshow(newmask),plt.colorbar(),plt.show()\n",
    "newmask = cv.imread('newmask.png', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "assert newmask is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# wherever it is marked white (sure foreground), change mask=1\n",
    "# wherever it is marked black (sure background), change mask=0\n",
    "mask[newmask == 0] = 0\n",
    "mask[newmask == 255] = 1\n",
    "\n",
    "mask, bgdModel, fgdModel = cv.grabCut(img,mask,None,bgdModel,fgdModel,5,cv.GC_INIT_WITH_MASK)\n",
    "\n",
    "mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask[:,:,np.newaxis]\n",
    "plt.imshow(img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('digits.png')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Now we split the image to 5000 cells, each 20x20 size\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    "\n",
    "# Make it into a Numpy array: its size will be (50,100,20,20)\n",
    "x = np.array(cells)\n",
    "\n",
    "# Now we prepare the training data and test data\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "\n",
    "# Create labels for train and test data\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k,250)[:,np.newaxis]\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "# Initiate kNN, train it on the training data, then test it with the test data with k=1\n",
    "knn = cv.ml.KNearest_create()\n",
    "knn.train(train, cv.ml.ROW_SAMPLE, train_labels)\n",
    "ret,result,neighbours,dist = knn.findNearest(test,k=5)\n",
    "\n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print( accuracy )\n",
    "\n",
    "plt.imshow(img[200:500, 200:500]),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Parameters from the tutorial image (diamondmarkers.jpg)\n",
    "squareLength = 0.04      # Example size in meters (adjust if known, but ratio is key)\n",
    "markerLength = 0.02      # Example size in meters (adjust if known, but ratio is key)\n",
    "ratio = squareLength / markerLength\n",
    "\n",
    "# Camera parameters (REPLACE WITH YOUR ACTUAL CALIBRATION RESULTS)\n",
    "cameraMatrix = np.array([[1000.,    0.,  320.],  # fx, 0, cx\n",
    "                         [   0., 1000.,  240.],  # 0, fy, cy\n",
    "                         [   0.,    0.,    1.]], dtype=np.float32)\n",
    "distCoeffs = np.zeros((5, 1), dtype=np.float32) # Assuming no lens distortion\n",
    "\n",
    "# Image input\n",
    "image_path = 'diamondmarkers.jpg' # The image provided in the tutorial\n",
    "\n",
    "# --- Initialization ---\n",
    "try:\n",
    "    # *** Revert to original dictionary ***\n",
    "    dictionary_name = cv.aruco.DICT_4X4_50\n",
    "    dictionary = cv.aruco.getPredefinedDictionary(dictionary_name)\n",
    "    print(f\"Using dictionary: {dictionary_name}\")\n",
    "except AttributeError:\n",
    "    print(f\"Error: Dictionary '{dictionary_name}' not found.\")\n",
    "    sys.exit()\n",
    "\n",
    "params = cv.aruco.DetectorParameters()\n",
    "# --- Parameters with Subpixel Refinement & Perspective Adjustment ---\n",
    "params.adaptiveThreshConstant = 7\n",
    "# *** Re-enable Subpixel corner refinement ***\n",
    "params.cornerRefinementMethod = cv.aruco.CORNER_REFINE_SUBPIX\n",
    "params.cornerRefinementWinSize = 5\n",
    "params.cornerRefinementMaxIterations = 30\n",
    "params.cornerRefinementMinAccuracy = 0.1\n",
    "\n",
    "# *** Adjust perspective removal slightly ***\n",
    "params.perspectiveRemovePixelPerCell = 10 # Increased from default 4\n",
    "params.perspectiveRemoveIgnoredMarginPerCell = 0.15 # Increased from default 0.13\n",
    "\n",
    "# Keep other relevant parameters (optional, defaults are often okay)\n",
    "# params.adaptiveThreshWinSizeMin = 3\n",
    "# params.adaptiveThreshWinSizeMax = 23\n",
    "# params.adaptiveThreshWinSizeStep = 10\n",
    "params.minMarkerPerimeterRate = 0.02\n",
    "# params.maxMarkerPerimeterRate = 4.0\n",
    "# params.polygonalApproxAccuracyRate = 0.03\n",
    "# params.minCornerDistanceRate = 0.05\n",
    "# params.minDistanceToBorder = 3\n",
    "# params.minMarkerDistanceRate = 0.05\n",
    "params.markerBorderBits = 1\n",
    "\n",
    "detector = cv.aruco.ArucoDetector(dictionary, params)\n",
    "\n",
    "# --- Image Loading ---\n",
    "frame = cv.imread(image_path)\n",
    "if frame is None:\n",
    "    print(f\"Error: Could not load image: {image_path}\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Image '{image_path}' loaded successfully. Shape: {frame.shape}\")\n",
    "\n",
    "# --- Processing ---\n",
    "frame_copy = frame.copy()\n",
    "frame_rejected_vis = frame.copy() # Create a separate copy for rejected visualization\n",
    "gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1. Detect ArUco markers (using the grayscale image)\n",
    "print(\"\\nDetecting ArUco markers...\")\n",
    "markerCorners, markerIds, rejectedCandidates = detector.detectMarkers(gray_frame) # Use gray_frame here\n",
    "\n",
    "# *** Visualize Rejected Candidates ***\n",
    "if rejectedCandidates is not None and len(rejectedCandidates) > 0:\n",
    "    print(f\"INFO: Found {len(rejectedCandidates)} rejected candidates. Visualizing them in a separate window.\")\n",
    "    # Pass None for ids and the color tuple as the 4th positional argument\n",
    "    cv.aruco.drawDetectedMarkers(frame_rejected_vis, rejectedCandidates, None, (255, 0, 255)) # Draw rejected in magenta\n",
    "    cv.imshow(\"Rejected Candidates\", frame_rejected_vis)\n",
    "else:\n",
    "    print(\"INFO: No rejected candidates found.\")\n",
    "\n",
    "\n",
    "# Check if markers were found\n",
    "if markerIds is not None and len(markerIds) > 0:\n",
    "    print(f\"SUCCESS: Detected {len(markerIds)} ArUco markers.\")\n",
    "    print(f\"Marker IDs found: {markerIds.flatten()}\")\n",
    "    # Draw detected ArUco markers (on the main copy)\n",
    "    cv.aruco.drawDetectedMarkers(frame_copy, markerCorners, markerIds, border_color=(0, 255, 0)) # Draw detected in green\n",
    "\n",
    "    # --- Proceed with Diamond Detection and Pose Estimation (only if markers found) ---\n",
    "    # ... (rest of the diamond detection/pose estimation code as before) ...\n",
    "    # 2. Detect ChArUco Diamonds\n",
    "    print(f\"\\nDetecting ChArUco diamonds with square/marker ratio: {ratio}...\")\n",
    "    try:\n",
    "        diamondCorners, diamondIds = cv.aruco.detectCharucoDiamond(\n",
    "            frame, markerCorners, markerIds, ratio\n",
    "        )\n",
    "    except cv.error as e:\n",
    "         print(f\"Error during detectCharucoDiamond: {e}\")\n",
    "         diamondIds = None\n",
    "\n",
    "    if diamondIds is not None and len(diamondIds) > 0:\n",
    "        print(f\"SUCCESS: Detected {len(diamondIds)} ChArUco diamonds.\")\n",
    "        print(f\"Diamond IDs found: {diamondIds.flatten()}\")\n",
    "        cv.aruco.drawDetectedDiamonds(frame_copy, diamondCorners, diamondIds)\n",
    "\n",
    "        # 3. Estimate Pose for Diamonds\n",
    "        print(\"\\nEstimating pose for detected diamonds...\")\n",
    "        try:\n",
    "            rvecs, tvecs, _objPoints = cv.aruco.estimatePoseSingleMarkers(\n",
    "                diamondCorners, squareLength, cameraMatrix, distCoeffs\n",
    "            )\n",
    "            print(f\"SUCCESS: Estimated pose for {len(rvecs)} diamonds.\")\n",
    "\n",
    "            # 4. Draw Pose Axes\n",
    "            print(\"Drawing axes...\")\n",
    "            for i in range(len(diamondIds)):\n",
    "                cv.drawFrameAxes(frame_copy, cameraMatrix, distCoeffs, rvecs[i], tvecs[i], squareLength * 0.5)\n",
    "            print(\"SUCCESS: Drawn axes.\")\n",
    "\n",
    "        except cv.error as e:\n",
    "            print(f\"Error during pose estimation or drawing axes: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"INFO: No ChArUco diamonds detected from the found ArUco markers.\")\n",
    "\n",
    "else:\n",
    "    print(\"INFO: No ArUco markers detected in the image.\")\n",
    "    # No need to proceed if no markers found\n",
    "\n",
    "\n",
    "# --- Display ---\n",
    "print(\"\\nDisplaying result. Press any key to exit.\")\n",
    "#cv.imshow(\"ChArUco Diamond Detection\", frame_copy) # Show main result (might be original if no markers found)\n",
    "cv.waitKey(0) # Wait indefinitely until a key is pressed\n",
    "\n",
    "# --- Cleanup ---\n",
    "cv.destroyAllWindows()\n",
    "print(\"Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
